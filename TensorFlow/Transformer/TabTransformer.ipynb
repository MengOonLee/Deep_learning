{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow/Transformer/TabTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZlChVm4f9GR"
      },
      "source": [
        "# Structured data learning with TabTransformer\n",
        "\n",
        "**Author:** [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)<br>\n",
        "**Date created:** 2022/01/18<br>\n",
        "**Last modified:** 2022/01/18<br>\n",
        "**Description:** Using contextual embeddings for structured data classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSR0cItgf9GV"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example demonstrates how to do structured data classification using\n",
        "[TabTransformer](https://arxiv.org/abs/2012.06678), a deep tabular data modeling\n",
        "architecture for supervised and semi-supervised learning.\n",
        "The TabTransformer is built upon self-attention based Transformers.\n",
        "The Transformer layers transform the embeddings of categorical features\n",
        "into robust contextual embeddings to achieve higher predictive accuracy.\n",
        "\n",
        "\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju4jwq0sf9GX"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import data as tf_data\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKf-2daCf9GY"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "This example uses the\n",
        "[United States Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/census+income)\n",
        "provided by the\n",
        "[UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php).\n",
        "The task is binary classification\n",
        "to predict whether a person is likely to be making over USD 50,000 a year.\n",
        "\n",
        "The dataset includes 48,842 instances with 14 input features: 5 numerical features and 9 categorical features.\n",
        "\n",
        "First, let's load the dataset from the UCI Machine Learning Repository into a Pandas\n",
        "DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UWvCIUKIf9GZ",
        "outputId": "85f61d62-cabf-41ed-f433-8d8c7e0b3d3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: (32561, 15)\n",
            "Test dataset shape: (16282, 15)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "CSV_HEADER = [\n",
        "    \"age\",\n",
        "    \"workclass\",\n",
        "    \"fnlwgt\",\n",
        "    \"education\",\n",
        "    \"education_num\",\n",
        "    \"marital_status\",\n",
        "    \"occupation\",\n",
        "    \"relationship\",\n",
        "    \"race\",\n",
        "    \"gender\",\n",
        "    \"capital_gain\",\n",
        "    \"capital_loss\",\n",
        "    \"hours_per_week\",\n",
        "    \"native_country\",\n",
        "    \"income_bracket\",\n",
        "]\n",
        "\n",
        "train_data_url = (\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        ")\n",
        "train_data = pd.read_csv(train_data_url, header=None, names=CSV_HEADER)\n",
        "\n",
        "test_data_url = (\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n",
        ")\n",
        "test_data = pd.read_csv(test_data_url, header=None, names=CSV_HEADER)\n",
        "\n",
        "print(f\"Train dataset shape: {train_data.shape}\")\n",
        "print(f\"Test dataset shape: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCwFV4U5f9Ga"
      },
      "source": [
        "Remove the first record (because it is not a valid data example) and a trailing 'dot' in the class labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xHNEmzwHf9Gb",
        "outputId": "f1e507bc-52c0-4912-a403-26671452a699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  age   workclass    fnlwgt      education  education_num  \\\n",
              "2  38     Private   89814.0        HS-grad            9.0   \n",
              "3  28   Local-gov  336951.0     Assoc-acdm           12.0   \n",
              "4  44     Private  160323.0   Some-college           10.0   \n",
              "5  18           ?  103497.0   Some-college           10.0   \n",
              "6  34     Private  198693.0           10th            6.0   \n",
              "\n",
              "        marital_status          occupation    relationship    race   gender  \\\n",
              "2   Married-civ-spouse     Farming-fishing         Husband   White     Male   \n",
              "3   Married-civ-spouse     Protective-serv         Husband   White     Male   \n",
              "4   Married-civ-spouse   Machine-op-inspct         Husband   Black     Male   \n",
              "5        Never-married                   ?       Own-child   White   Female   \n",
              "6        Never-married       Other-service   Not-in-family   White     Male   \n",
              "\n",
              "   capital_gain  capital_loss  hours_per_week  native_country income_bracket  \n",
              "2           0.0           0.0            50.0   United-States          <=50K  \n",
              "3           0.0           0.0            40.0   United-States           >50K  \n",
              "4        7688.0           0.0            40.0   United-States           >50K  \n",
              "5           0.0           0.0            30.0   United-States          <=50K  \n",
              "6           0.0           0.0            30.0   United-States          <=50K  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7acd325b-2923-4e65-89c2-2b0a6ce20df8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814.0</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951.0</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323.0</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18</td>\n",
              "      <td>?</td>\n",
              "      <td>103497.0</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>34</td>\n",
              "      <td>Private</td>\n",
              "      <td>198693.0</td>\n",
              "      <td>10th</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7acd325b-2923-4e65-89c2-2b0a6ce20df8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7acd325b-2923-4e65-89c2-2b0a6ce20df8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7acd325b-2923-4e65-89c2-2b0a6ce20df8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a294e729-0a05-490d-aa55-caa15314aec4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a294e729-0a05-490d-aa55-caa15314aec4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a294e729-0a05-490d-aa55-caa15314aec4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 16280,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 73,\n        \"samples\": [\n          \"34\",\n          \"74\",\n          \"72\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \" Without-pay\",\n          \" Local-gov\",\n          \" State-gov\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105717.74891525942,\n        \"min\": 13492.0,\n        \"max\": 1490400.0,\n        \"num_unique_values\": 12786,\n        \"samples\": [\n          230919.0,\n          120753.0,\n          55377.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \" HS-grad\",\n          \" Assoc-acdm\",\n          \" 7th-8th\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.567511152590223,\n        \"min\": 1.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          9.0,\n          12.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital_status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \" Married-civ-spouse\",\n          \" Never-married\",\n          \" Married-spouse-absent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \" Tech-support\",\n          \" Priv-house-serv\",\n          \" Farming-fishing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \" Husband\",\n          \" Own-child\",\n          \" Other-relative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \" Black\",\n          \" Amer-Indian-Eskimo\",\n          \" Asian-Pac-Islander\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Female\",\n          \" Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7584.164159816526,\n        \"min\": 0.0,\n        \"max\": 99999.0,\n        \"num_unique_values\": 113,\n        \"samples\": [\n          34095.0,\n          7298.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 403.1170778642484,\n        \"min\": 0.0,\n        \"max\": 3770.0,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          1258.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours_per_week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.479715157975747,\n        \"min\": 1.0,\n        \"max\": 99.0,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          17.0,\n          23.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native_country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \" Italy\",\n          \" Vietnam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income_bracket\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" >50K\",\n          \" <=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "test_data = test_data[1:].copy()\n",
        "test_data.income_bracket = test_data.income_bracket.apply(\n",
        "    lambda value: value.replace(\".\", \"\")\n",
        ")\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UMXmOurf9Gc"
      },
      "source": [
        "Now we store the training and test data in separate CSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fnIymR6gf9Gc"
      },
      "outputs": [],
      "source": [
        "train_data_file = \"train_data.csv\"\n",
        "test_data_file = \"test_data.csv\"\n",
        "\n",
        "train_data.to_csv(train_data_file, index=False, header=False)\n",
        "test_data.to_csv(test_data_file, index=False, header=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2pyAMt9f9Gd"
      },
      "source": [
        "## Define dataset metadata\n",
        "\n",
        "Here, we define the metadata of the dataset that will be useful for reading and parsing\n",
        "the data into input features, and encoding the input features with respect to their types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VsO0aB9Gf9Gd"
      },
      "outputs": [],
      "source": [
        "# A list of the numerical feature names.\n",
        "NUMERIC_FEATURE_NAMES = [\n",
        "    \"age\",\n",
        "    \"education_num\",\n",
        "    \"capital_gain\",\n",
        "    \"capital_loss\",\n",
        "    \"hours_per_week\",\n",
        "]\n",
        "# A dictionary of the categorical features and their vocabulary.\n",
        "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
        "    \"workclass\": sorted(list(train_data[\"workclass\"].unique())),\n",
        "    \"education\": sorted(list(train_data[\"education\"].unique())),\n",
        "    \"marital_status\": sorted(list(train_data[\"marital_status\"].unique())),\n",
        "    \"occupation\": sorted(list(train_data[\"occupation\"].unique())),\n",
        "    \"relationship\": sorted(list(train_data[\"relationship\"].unique())),\n",
        "    \"race\": sorted(list(train_data[\"race\"].unique())),\n",
        "    \"gender\": sorted(list(train_data[\"gender\"].unique())),\n",
        "    \"native_country\": sorted(list(train_data[\"native_country\"].unique())),\n",
        "}\n",
        "# Name of the column to be used as instances weight.\n",
        "WEIGHT_COLUMN_NAME = \"fnlwgt\"\n",
        "# A list of the categorical feature names.\n",
        "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
        "# A list of all the input features.\n",
        "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
        "# A list of column default values for each feature.\n",
        "COLUMN_DEFAULTS = [\n",
        "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES + [WEIGHT_COLUMN_NAME] else [\"NA\"]\n",
        "    for feature_name in CSV_HEADER\n",
        "]\n",
        "# The name of the target feature.\n",
        "TARGET_FEATURE_NAME = \"income_bracket\"\n",
        "# A list of the labels of the target features.\n",
        "TARGET_LABELS = [\" <=50K\", \" >50K\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKbnjtRef9Ge"
      },
      "source": [
        "## Configure the hyperparameters\n",
        "\n",
        "The hyperparameters includes model architecture and training configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZhuZ4Domf9Ge"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.0001\n",
        "DROPOUT_RATE = 0.2\n",
        "BATCH_SIZE = 265\n",
        "NUM_EPOCHS = 15\n",
        "\n",
        "NUM_TRANSFORMER_BLOCKS = 3  # Number of transformer blocks.\n",
        "NUM_HEADS = 4  # Number of attention heads.\n",
        "EMBEDDING_DIMS = 16  # Embedding dimensions of the categorical features.\n",
        "MLP_HIDDEN_UNITS_FACTORS = [2, 1]  # MLP hidden layer units, as factors of the number of inputs.\n",
        "NUM_MLP_BLOCKS = 2  # Number of MLP blocks in the baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cyRMVPxf9Ge"
      },
      "source": [
        "## Implement data reading pipeline\n",
        "\n",
        "We define an input function that reads and parses the file, then converts features\n",
        "and labels into a[`tf.data.Dataset`](https://www.tensorflow.org/guide/datasets)\n",
        "for training or evaluation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "lookup_dict = {}\n",
        "for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "    vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
        "    lookup = tf.keras.layers.StringLookup(\n",
        "        vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
        "    )\n",
        "    lookup_dict[feature_name] = lookup\n",
        "\n",
        "lookup_dict"
      ],
      "metadata": {
        "id": "vI1I5H53DG1_",
        "outputId": "2b63bca4-191b-4604-deb2-ac9681f377fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'workclass': <StringLookup name=string_lookup_1, built=False>,\n",
              " 'education': <StringLookup name=string_lookup_2, built=False>,\n",
              " 'marital_status': <StringLookup name=string_lookup_3, built=False>,\n",
              " 'occupation': <StringLookup name=string_lookup_4, built=False>,\n",
              " 'relationship': <StringLookup name=string_lookup_5, built=False>,\n",
              " 'race': <StringLookup name=string_lookup_6, built=False>,\n",
              " 'gender': <StringLookup name=string_lookup_7, built=False>,\n",
              " 'native_country': <StringLookup name=string_lookup_8, built=False>}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mi6jOcpZf9Gf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "target_label_lookup = tf.keras.layers.StringLookup(\n",
        "    vocabulary=TARGET_LABELS, mask_token=None, num_oov_indices=0\n",
        ")\n",
        "\n",
        "def prepare_example(features, target):\n",
        "    target_index = target_label_lookup(target)\n",
        "    weights = features.pop(WEIGHT_COLUMN_NAME)\n",
        "    return features, target_index, weights\n",
        "\n",
        "lookup_dict = {}\n",
        "for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "    vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
        "    # Create a lookup to convert a string values to an integer indices.\n",
        "    # Since we are not using a mask token, nor expecting any out of vocabulary\n",
        "    # (oov) token, we set mask_token to None and num_oov_indices to 0.\n",
        "    lookup = tf.keras.layers.StringLookup(\n",
        "        vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
        "    )\n",
        "    lookup_dict[feature_name] = lookup\n",
        "\n",
        "def encode_categorical(batch_x, batch_y, weights):\n",
        "    for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "        batch_x[feature_name] = lookup_dict[feature_name](batch_x[feature_name])\n",
        "\n",
        "    return batch_x, batch_y, weights\n",
        "\n",
        "def get_dataset_from_csv(csv_file_path, batch_size=128, shuffle=False):\n",
        "    dataset = (\n",
        "        tf.data.experimental.make_csv_dataset(\n",
        "            file_pattern=csv_file_path,\n",
        "            batch_size=batch_size,\n",
        "            column_names=CSV_HEADER,\n",
        "            column_defaults=COLUMN_DEFAULTS,\n",
        "            label_name=TARGET_FEATURE_NAME,\n",
        "            num_epochs=1,\n",
        "            header=False,\n",
        "            na_value=\"?\",\n",
        "            shuffle=shuffle\n",
        "        )\n",
        "        .map(prepare_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
        "        .map(encode_categorical)\n",
        "    )\n",
        "    return dataset.cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbS_jaXIf9Gf"
      },
      "source": [
        "## Implement a training and evaluation procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CqFr4Cgmf9Gf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def run_experiment(\n",
        "    model,\n",
        "    train_data_file,\n",
        "    test_data_file,\n",
        "    num_epochs,\n",
        "    learning_rate,\n",
        "    weight_decay,\n",
        "    batch_size,\n",
        "):\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n",
        "    )\n",
        "\n",
        "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
        "    validation_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
        "\n",
        "    print(\"Start training the model...\")\n",
        "    history = model.fit(\n",
        "        train_dataset, epochs=num_epochs, validation_data=validation_dataset\n",
        "    )\n",
        "    print(\"Model training finished\")\n",
        "\n",
        "    _, accuracy = model.evaluate(validation_dataset, verbose=0)\n",
        "\n",
        "    print(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd1hQMwEf9Gf"
      },
      "source": [
        "## Create model inputs\n",
        "\n",
        "Now, define the inputs for the models as a dictionary, where the key is the feature name,\n",
        "and the value is a `keras.layers.Input` tensor with the corresponding feature shape\n",
        "and data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Dt2hOe6if9Gg"
      },
      "outputs": [],
      "source": [
        "def create_model_inputs():\n",
        "    inputs = {}\n",
        "    for feature_name in FEATURE_NAMES:\n",
        "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
        "            inputs[feature_name] = tf.keras.Input(\n",
        "                name=feature_name, shape=(), dtype=\"float32\"\n",
        "            )\n",
        "        else:\n",
        "            inputs[feature_name] = tf.keras.Input(\n",
        "                name=feature_name, shape=(), dtype=\"int32\"\n",
        "            )\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp9K75Imf9Gg"
      },
      "source": [
        "## Encode features\n",
        "\n",
        "The `encode_inputs` method returns `encoded_categorical_feature_list` and `numerical_feature_list`.\n",
        "We encode the categorical features as embeddings, using a fixed `embedding_dims` for all the features,\n",
        "regardless their vocabulary sizes. This is required for the Transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7m03aF_Of9Gg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def encode_inputs(inputs, embedding_dims):\n",
        "    encoded_categorical_feature_list = []\n",
        "    numerical_feature_list = []\n",
        "\n",
        "    for feature_name in inputs:\n",
        "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
        "            # Create a lookup to convert a string values to an integer indices.\n",
        "            # Since we are not using a mask token, nor expecting any out of vocabulary\n",
        "            # (oov) token, we set mask_token to None and num_oov_indices to 0.\n",
        "\n",
        "            # Convert the string input values into integer indices.\n",
        "\n",
        "            # Create an embedding layer with the specified dimensions.\n",
        "            embedding = tf.keras.layers.Embedding(\n",
        "                input_dim=len(vocabulary), output_dim=embedding_dims\n",
        "            )\n",
        "\n",
        "            # Convert the index values to embedding representations.\n",
        "            encoded_categorical_feature = embedding(inputs[feature_name])\n",
        "            encoded_categorical_feature_list.append(encoded_categorical_feature)\n",
        "\n",
        "        else:\n",
        "            # Use the numerical features as-is.\n",
        "            numerical_feature = tf.expand_dims(input=inputs[feature_name], axis=-1)\n",
        "            numerical_feature_list.append(numerical_feature)\n",
        "\n",
        "    return encoded_categorical_feature_list, numerical_feature_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ2xexgvf9Gh"
      },
      "source": [
        "## Implement an MLP block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kuzRCC_mf9Gh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
        "    mlp_layers = []\n",
        "    for units in hidden_units:\n",
        "        mlp_layers.append(normalization_layer())\n",
        "        mlp_layers.append(tf.keras.layers.Dense(units=units, activation=activation))\n",
        "        mlp_layers.append(tf.keras.layers.Dropout(rate=dropout_rate))\n",
        "\n",
        "    return tf.keras.Sequential(mlp_layers, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqT14UXTf9Gh"
      },
      "source": [
        "## Experiment 1: a baseline model\n",
        "\n",
        "In the first experiment, we create a simple multi-layer feed-forward network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7QZ4yy2f9Gh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_baseline_model(\n",
        "    embedding_dims, num_mlp_blocks, mlp_hidden_units_factors, dropout_rate\n",
        "):\n",
        "    # Create model inputs.\n",
        "    inputs = create_model_inputs()\n",
        "    # encode features.\n",
        "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
        "        inputs, embedding_dims\n",
        "    )\n",
        "    # Concatenate all features.\n",
        "    features = layers.concatenate(\n",
        "        encoded_categorical_feature_list + numerical_feature_list\n",
        "    )\n",
        "    # Compute Feedforward layer units.\n",
        "    feedforward_units = [features.shape[-1]]\n",
        "\n",
        "    # Create several feedforwad layers with skip connections.\n",
        "    for layer_idx in range(num_mlp_blocks):\n",
        "        features = create_mlp(\n",
        "            hidden_units=feedforward_units,\n",
        "            dropout_rate=dropout_rate,\n",
        "            activation=keras.activations.gelu,\n",
        "            normalization_layer=layers.LayerNormalization,\n",
        "            name=f\"feedforward_{layer_idx}\",\n",
        "        )(features)\n",
        "\n",
        "    # Compute MLP hidden_units.\n",
        "    mlp_hidden_units = [\n",
        "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
        "    ]\n",
        "    # Create final MLP.\n",
        "    features = create_mlp(\n",
        "        hidden_units=mlp_hidden_units,\n",
        "        dropout_rate=dropout_rate,\n",
        "        activation=keras.activations.selu,\n",
        "        normalization_layer=layers.BatchNormalization,\n",
        "        name=\"MLP\",\n",
        "    )(features)\n",
        "\n",
        "    # Add a sigmoid as a binary classifer.\n",
        "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "baseline_model = create_baseline_model(\n",
        "    embedding_dims=EMBEDDING_DIMS,\n",
        "    num_mlp_blocks=NUM_MLP_BLOCKS,\n",
        "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        ")\n",
        "\n",
        "print(\"Total model weights:\", baseline_model.count_params())\n",
        "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLvRV-Mzf9Gh"
      },
      "source": [
        "Let's train and evaluate the baseline model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv7nT0mAf9Gi"
      },
      "outputs": [],
      "source": [
        "history = run_experiment(\n",
        "    model=baseline_model,\n",
        "    train_data_file=train_data_file,\n",
        "    test_data_file=test_data_file,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DxRjgUNf9Gi"
      },
      "source": [
        "The baseline linear model achieves ~81% validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol3eNILDf9Gi"
      },
      "source": [
        "## Experiment 2: TabTransformer\n",
        "\n",
        "The TabTransformer architecture works as follows:\n",
        "\n",
        "1. All the categorical features are encoded as embeddings, using the same `embedding_dims`.\n",
        "This means that each value in each categorical feature will have its own embedding vector.\n",
        "2. A column embedding, one embedding vector for each categorical feature, is added (point-wise) to the categorical feature embedding.\n",
        "3. The embedded categorical features are fed into a stack of Transformer blocks.\n",
        "Each Transformer block consists of a multi-head self-attention layer followed by a feed-forward layer.\n",
        "3. The outputs of the final Transformer layer, which are the *contextual embeddings* of the categorical features,\n",
        "are concatenated with the input numerical features, and fed into a final MLP block.\n",
        "4. A `softmax` classifer is applied at the end of the model.\n",
        "\n",
        "The [paper](https://arxiv.org/abs/2012.06678) discusses both addition and concatenation of the column embedding in the\n",
        "*Appendix: Experiment and Model Details* section.\n",
        "The architecture of TabTransformer is shown below, as presented in the paper.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/keras-team/keras-io/master/examples/structured_data/img/tabtransformer/tabtransformer.png\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMYiXdN5f9Gi"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_tabtransformer_classifier(\n",
        "    num_transformer_blocks,\n",
        "    num_heads,\n",
        "    embedding_dims,\n",
        "    mlp_hidden_units_factors,\n",
        "    dropout_rate,\n",
        "    use_column_embedding=False,\n",
        "):\n",
        "    # Create model inputs.\n",
        "    inputs = create_model_inputs()\n",
        "    # encode features.\n",
        "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
        "        inputs, embedding_dims\n",
        "    )\n",
        "    # Stack categorical feature embeddings for the Tansformer.\n",
        "    encoded_categorical_features = ops.stack(encoded_categorical_feature_list, axis=1)\n",
        "    # Concatenate numerical features.\n",
        "    numerical_features = layers.concatenate(numerical_feature_list)\n",
        "\n",
        "    # Add column embedding to categorical feature embeddings.\n",
        "    if use_column_embedding:\n",
        "        num_columns = encoded_categorical_features.shape[1]\n",
        "        column_embedding = layers.Embedding(\n",
        "            input_dim=num_columns, output_dim=embedding_dims\n",
        "        )\n",
        "        column_indices = ops.arange(start=0, stop=num_columns, step=1)\n",
        "        encoded_categorical_features = encoded_categorical_features + column_embedding(\n",
        "            column_indices\n",
        "        )\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for block_idx in range(num_transformer_blocks):\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=embedding_dims,\n",
        "            dropout=dropout_rate,\n",
        "            name=f\"multihead_attention_{block_idx}\",\n",
        "        )(encoded_categorical_features, encoded_categorical_features)\n",
        "        # Skip connection 1.\n",
        "        x = layers.Add(name=f\"skip_connection1_{block_idx}\")(\n",
        "            [attention_output, encoded_categorical_features]\n",
        "        )\n",
        "        # Layer normalization 1.\n",
        "        x = layers.LayerNormalization(name=f\"layer_norm1_{block_idx}\", epsilon=1e-6)(x)\n",
        "        # Feedforward.\n",
        "        feedforward_output = create_mlp(\n",
        "            hidden_units=[embedding_dims],\n",
        "            dropout_rate=dropout_rate,\n",
        "            activation=keras.activations.gelu,\n",
        "            normalization_layer=partial(\n",
        "                layers.LayerNormalization, epsilon=1e-6\n",
        "            ),  # using partial to provide keyword arguments before initialization\n",
        "            name=f\"feedforward_{block_idx}\",\n",
        "        )(x)\n",
        "        # Skip connection 2.\n",
        "        x = layers.Add(name=f\"skip_connection2_{block_idx}\")([feedforward_output, x])\n",
        "        # Layer normalization 2.\n",
        "        encoded_categorical_features = layers.LayerNormalization(\n",
        "            name=f\"layer_norm2_{block_idx}\", epsilon=1e-6\n",
        "        )(x)\n",
        "\n",
        "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
        "    categorical_features = layers.Flatten()(encoded_categorical_features)\n",
        "    # Apply layer normalization to the numerical features.\n",
        "    numerical_features = layers.LayerNormalization(epsilon=1e-6)(numerical_features)\n",
        "    # Prepare the input for the final MLP block.\n",
        "    features = layers.concatenate([categorical_features, numerical_features])\n",
        "\n",
        "    # Compute MLP hidden_units.\n",
        "    mlp_hidden_units = [\n",
        "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
        "    ]\n",
        "    # Create final MLP.\n",
        "    features = create_mlp(\n",
        "        hidden_units=mlp_hidden_units,\n",
        "        dropout_rate=dropout_rate,\n",
        "        activation=keras.activations.selu,\n",
        "        normalization_layer=layers.BatchNormalization,\n",
        "        name=\"MLP\",\n",
        "    )(features)\n",
        "\n",
        "    # Add a sigmoid as a binary classifer.\n",
        "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "tabtransformer_model = create_tabtransformer_classifier(\n",
        "    num_transformer_blocks=NUM_TRANSFORMER_BLOCKS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    embedding_dims=EMBEDDING_DIMS,\n",
        "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        ")\n",
        "\n",
        "print(\"Total model weights:\", tabtransformer_model.count_params())\n",
        "keras.utils.plot_model(tabtransformer_model, show_shapes=True, rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeIMVjHef9Gj"
      },
      "source": [
        "Let's train and evaluate the TabTransformer model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf5kVLFRf9Gj"
      },
      "outputs": [],
      "source": [
        "history = run_experiment(\n",
        "    model=tabtransformer_model,\n",
        "    train_data_file=train_data_file,\n",
        "    test_data_file=test_data_file,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9bpdPsEf9Gj"
      },
      "source": [
        "The TabTransformer model achieves ~85% validation accuracy.\n",
        "Note that, with the default parameter configurations, both the baseline and the TabTransformer\n",
        "have similar number of trainable weights: 109,895 and 87,745 respectively, and both use the same training hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB5pqg5nf9Gk"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "TabTransformer significantly outperforms MLP and recent\n",
        "deep networks for tabular data while matching the performance of tree-based ensemble models.\n",
        "TabTransformer can be learned in end-to-end supervised training using labeled examples.\n",
        "For a scenario where there are a few labeled examples and a large number of unlabeled\n",
        "examples, a pre-training procedure can be employed to train the Transformer layers using unlabeled data.\n",
        "This is followed by fine-tuning of the pre-trained Transformer layers along with\n",
        "the top MLP layer using the labeled data.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tabtransformer",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}