{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow2/Start/SequentialAPI/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juxNknyiLVQH"
   },
   "source": [
    "# Introduction to TensorFlow 2\n",
    "\n",
    "\n",
    "## Coding tutorials\n",
    "\n",
    "#### [1. Hello TensorFlow!](#coding_tutorial_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0w1kiXGLVQK"
   },
   "source": [
    "<a id='coding_tutorial_1'></a>\n",
    "## Hello TensorFlow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(tensors=(x_train, y_train))\n",
    "ds_train = ds_train.map(map_func=lambda x, y:\n",
    "    (tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_train = ds_train.map(map_func=lambda x, y:\n",
    "    (x[..., tf.newaxis], y))\n",
    "print(\"Train element spec:\", ds_train.element_spec)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(tensors=(x_test, y_test))\n",
    "ds_test = ds_test.map(map_func=lambda x, y:\n",
    "    (tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_test = ds_test.map(map_func=lambda x, y: (\n",
    "    x[..., tf.newaxis], y))\n",
    "print(\"Test element spec:\", ds_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mnist_model (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MnistModel</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">105,338</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mnist_model (\u001b[38;5;33mMnistModel\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │       \u001b[38;5;34m105,338\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,338</span> (411.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,338\u001b[0m (411.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,322</span> (411.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,322\u001b[0m (411.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> (64.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m16\u001b[0m (64.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "class MnistModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features_extractor = FeaturesExtractor()\n",
    "        self.classifier = Classifier(num_classes=num_classes)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.features_extractor(inputs=inputs,\n",
    "            training=training)\n",
    "        h = self.flatten(inputs=h)\n",
    "        return self.classifier(inputs=h)\n",
    "\n",
    "class FeaturesExtractor(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3),\n",
    "            padding=\"same\", activation=None)\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.conv(inputs=inputs)\n",
    "        h = self.batchnorm(inputs=h, training=training)\n",
    "        h = tf.nn.relu(features=h)\n",
    "        return self.maxpool(inputs=h)\n",
    "\n",
    "class Classifier(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense1 = tf.keras.layers.Dense(\n",
    "            units=64, activation=tf.keras.activations.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(\n",
    "            units=64, activation=tf.keras.activations.relu)\n",
    "        self.dense3 = tf.keras.layers.Dense(\n",
    "            units=num_classes, activation=tf.keras.activations.softmax)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.dense1(inputs=inputs)\n",
    "        h = self.dense2(inputs=h)\n",
    "        return self.dense3(inputs=h)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "outputs = MnistModel(num_classes=10)(inputs)\n",
    "mnist_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_curve=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKTz7LqHLVQg",
    "outputId": "808488ef-8035-458c-ca47-4d0ffb58cdae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed=42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "print(\"Loading train data...\\n\")\n",
    "data = np.loadtxt(fname=\"data/mnist.csv\", delimiter=\",\")\n",
    "print(\"MNIST dataset loaded.\\n\")\n",
    "\n",
    "x_train = data[:, 1:]\n",
    "x_train = x_train / 255.\n",
    "y_train = data[:, 0]\n",
    "\n",
    "print(\"x train data size: {}\".format(x_train.shape))\n",
    "print(\"y train data size: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "w9EqmxYNLVQn",
    "outputId": "032bf9e5-5da0-4098-d96f-7e8d2eaa59ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Tensorflow\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "# Check its version & devices\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Train a feedforward neural network for image classification\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=16, activation=tf.keras.activations.relu\n",
    "))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=10, activation=tf.keras.activations.softmax\n",
    "))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "print(\"Training model...\\n\")\n",
    "history = model.fit(\n",
    "    x=x_train, y=y_train, validation_split=0.1,\n",
    "    epochs=10, batch_size=32, verbose=0\n",
    ")\n",
    "print(\"Model trained successfully\")\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_history = pd.DataFrame(data=history.history, index=history.epoch)\n",
    "metrics = [\"loss\", \"sparse_categorical_accuracy\"]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    sns.lineplot(ax=ax, data=df_history, label=\"train\",\n",
    "        x=df_history.index+1, y=metric\n",
    "    )\n",
    "    try:\n",
    "        sns.lineplot(ax=ax, data=df_history, label=\"valid\",\n",
    "            x=df_history.index+1, y=f\"val_{metric}\"\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel(xlabel=\"epoch\")\n",
    "    ax.set_ylabel(ylabel=f\"{metric}\")\n",
    "    ax.set_title(label=f\"{metric} vs. epoch\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
