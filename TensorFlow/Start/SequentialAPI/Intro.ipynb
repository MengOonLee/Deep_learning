{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow2/Start/SequentialAPI/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juxNknyiLVQH"
   },
   "source": [
    "# Introduction to TensorFlow 2\n",
    "\n",
    "\n",
    "## Coding tutorials\n",
    "\n",
    "#### [1. Hello TensorFlow!](#coding_tutorial_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0w1kiXGLVQK"
   },
   "source": [
    "<a id='coding_tutorial_1'></a>\n",
    "## Hello TensorFlow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Train element spec: (TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))\n",
      "Test element spec: (TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.uint8, name=None))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(tensors=(x_train, y_train))\n",
    "ds_train = ds_train.map(map_func=lambda x, y:\n",
    "    (tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_train = ds_train.map(map_func=lambda x, y:\n",
    "    (x[..., tf.newaxis], y))\n",
    "print(\"Train element spec:\", ds_train.element_spec)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(tensors=(x_test, y_test))\n",
    "ds_test = ds_test.map(map_func=lambda x, y:\n",
    "    (tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_test = ds_test.map(map_func=lambda x, y: (\n",
    "    x[..., tf.newaxis], y))\n",
    "print(\"Test element spec:\", ds_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "class MnistModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features_extractor = FeaturesExtractor()\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.features_extractor(\n",
    "            inputs=inputs, training=training)\n",
    "        return h\n",
    "\n",
    "class FeaturesExtractor(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3),\n",
    "            padding=\"same\", activation=None, input_shape=input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.conv(inputs=inputs)\n",
    "        h = self.batchnorm(inputs=h, training=training)\n",
    "        h = tf.nn.relu(features=h)\n",
    "        h = self.flatten(inputs=h)\n",
    "        return h\n",
    "\n",
    "class Classifier(tf.keras.layers.Layer):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKTz7LqHLVQg",
    "outputId": "808488ef-8035-458c-ca47-4d0ffb58cdae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed=42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "print(\"Loading train data...\\n\")\n",
    "data = np.loadtxt(fname=\"data/mnist.csv\", delimiter=\",\")\n",
    "print(\"MNIST dataset loaded.\\n\")\n",
    "\n",
    "x_train = data[:, 1:]\n",
    "x_train = x_train / 255.\n",
    "y_train = data[:, 0]\n",
    "\n",
    "print(\"x train data size: {}\".format(x_train.shape))\n",
    "print(\"y train data size: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "w9EqmxYNLVQn",
    "outputId": "032bf9e5-5da0-4098-d96f-7e8d2eaa59ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Tensorflow\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "# Check its version & devices\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Train a feedforward neural network for image classification\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=16, activation=tf.keras.activations.relu\n",
    "))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=10, activation=tf.keras.activations.softmax\n",
    "))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "print(\"Training model...\\n\")\n",
    "history = model.fit(\n",
    "    x=x_train, y=y_train, validation_split=0.1,\n",
    "    epochs=10, batch_size=32, verbose=0\n",
    ")\n",
    "print(\"Model trained successfully\")\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_history = pd.DataFrame(data=history.history, index=history.epoch)\n",
    "metrics = [\"loss\", \"sparse_categorical_accuracy\"]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    sns.lineplot(ax=ax, data=df_history, label=\"train\",\n",
    "        x=df_history.index+1, y=metric\n",
    "    )\n",
    "    try:\n",
    "        sns.lineplot(ax=ax, data=df_history, label=\"valid\",\n",
    "            x=df_history.index+1, y=f\"val_{metric}\"\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel(xlabel=\"epoch\")\n",
    "    ax.set_ylabel(ylabel=f\"{metric}\")\n",
    "    ax.set_title(label=f\"{metric} vs. epoch\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
