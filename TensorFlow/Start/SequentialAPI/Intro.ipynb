{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow2/Start/SequentialAPI/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juxNknyiLVQH"
   },
   "source": [
    "# Introduction to TensorFlow 2\n",
    "\n",
    "\n",
    "## Coding tutorials\n",
    "\n",
    "#### [1. Hello TensorFlow!](#coding_tutorial_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0w1kiXGLVQK"
   },
   "source": [
    "<a id='coding_tutorial_1'></a>\n",
    "## Hello TensorFlow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "batch_size = 64 * strategy.num_replicas_in_sync\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(tensors=(x_train, y_train))\n",
    "ds_train = ds_train.map(map_func=lambda x, y: (\n",
    "    tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_train = ds_train.map(map_func=lambda x, y: (\n",
    "    x[..., tf.newaxis], y))\n",
    "ds_train = ds_train.shuffle(buffer_size=len(ds_train))\\\n",
    "    .batch(batch_size=batch_size)\n",
    "print(\"Train element spec:\", ds_train.element_spec)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(tensors=(x_test, y_test))\n",
    "ds_test = ds_test.map(map_func=lambda x, y:\n",
    "    (tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_test = ds_test.map(map_func=lambda x, y: (\n",
    "    x[..., tf.newaxis], y))\n",
    "ds_test = ds_test.batch(batch_size=batch_size)\n",
    "print(\"Test element spec:\", ds_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "class MNISTClassifier(tf.keras.Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features_extractor = FeaturesExtractor()\n",
    "        self.classifier = Classifier(num_classes=num_classes)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.features_extractor(inputs, training=training)\n",
    "        return self.classifier(h)\n",
    "\n",
    "class FeaturesExtractor(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=8,\n",
    "            kernel_size=(3, 3), padding=\"same\", activation=None,\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(l2=1e-5))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.conv(inputs)\n",
    "        h = self.batchnorm(h, training=training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.maxpool(h)\n",
    "        return self.flatten(h)\n",
    "\n",
    "class Classifier(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense1 = tf.keras.layers.Dense(units=64,\n",
    "            activation=tf.keras.activations.relu,\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(l2=1e-5))\n",
    "        self.dense2 = tf.keras.layers.Dense(units=64,\n",
    "            activation=tf.keras.activations.relu,\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(l2=1e-5))\n",
    "        self.dense3 = tf.keras.layers.Dense(units=num_classes,\n",
    "            activation=tf.keras.activations.softmax,\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(l2=1e-5))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.dense1(inputs)\n",
    "        h = self.dense2(h)\n",
    "        return self.dense3(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "with strategy.scope():\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(y_true, y_pred, model_losses):\n",
    "        per_example_loss = loss_fn(y_true=y_true, y_pred=y_pred)\n",
    "        loss = tf.nn.compute_average_loss(per_example_loss)\n",
    "        if model_losses:\n",
    "            loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
    "        return loss\n",
    "    \n",
    "    model = MNISTClassifier(num_classes=10)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "    train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_acc\")\n",
    "    \n",
    "    test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "    test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs):\n",
    "    x_train, y_train = inputs\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs=x_train, training=True)\n",
    "        loss = compute_loss(y_train, y_pred, model.losses)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss.update_state(loss_fn(y_true=y_train, y_pred=y_pred))\n",
    "    train_acc.update_state(y_true=y_train, y_pred=y_pred)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(ds_inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(ds_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "for epoach in range(2):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for ds in ds_train:\n",
    "        total_loss += distributed_train_step(ds)\n",
    "        num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKTz7LqHLVQg",
    "outputId": "808488ef-8035-458c-ca47-4d0ffb58cdae",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "w9EqmxYNLVQn",
    "outputId": "032bf9e5-5da0-4098-d96f-7e8d2eaa59ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Tensorflow\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "# Check its version & devices\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Train a feedforward neural network for image classification\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=16, activation=tf.keras.activations.relu\n",
    "))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=10, activation=tf.keras.activations.softmax\n",
    "))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "print(\"Training model...\\n\")\n",
    "history = model.fit(\n",
    "    x=x_train, y=y_train, validation_split=0.1,\n",
    "    epochs=10, batch_size=32, verbose=0\n",
    ")\n",
    "print(\"Model trained successfully\")\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_history = pd.DataFrame(data=history.history, index=history.epoch)\n",
    "metrics = [\"loss\", \"sparse_categorical_accuracy\"]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    sns.lineplot(ax=ax, data=df_history, label=\"train\",\n",
    "        x=df_history.index+1, y=metric\n",
    "    )\n",
    "    try:\n",
    "        sns.lineplot(ax=ax, data=df_history, label=\"valid\",\n",
    "            x=df_history.index+1, y=f\"val_{metric}\"\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel(xlabel=\"epoch\")\n",
    "    ax.set_ylabel(ylabel=f\"{metric}\")\n",
    "    ax.set_title(label=f\"{metric} vs. epoch\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
