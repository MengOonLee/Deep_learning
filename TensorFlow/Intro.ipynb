{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juxNknyiLVQH"
   },
   "source": [
    "# Introduction to TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZeFZkX3q0_1T"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "sPGUEw-f9bRl",
    "outputId": "c105d3a0-1fc5-41ef-b09a-4d1b286d5f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'type': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'size': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'weight': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)},\n",
       " {'pred': TensorSpec(shape=(None,), dtype=tf.int32, name=None)})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = {\n",
    "    \"type\": [0, 1, 1],\n",
    "    \"size\": [\"small\", \"small\", \"medium\"],\n",
    "    \"weight\": [2.7, 1.8, 1.6]\n",
    "}\n",
    "y_train = {\n",
    "    \"pred\": [1, 1, 0]\n",
    "}\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(tensors=(x_train, y_train))\n",
    "ds_train = ds_train.batch(batch_size=32)\n",
    "\n",
    "inputs = {}\n",
    "inputs[\"type\"] = tf.keras.Input(name=\"type\", shape=(), dtype=tf.int64)\n",
    "inputs[\"size\"] = tf.keras.Input(name=\"size\", shape=(), dtype=tf.string)\n",
    "inputs[\"weight\"] = tf.keras.Input(name=\"weight\", shape=(1,), dtype=tf.float32)\n",
    "\n",
    "outputs = {}\n",
    "outputs[\"type\"] = tf.keras.layers.CategoryEncoding(\n",
    "    num_tokens=3, output_mode=\"one_hot\")(inputs[\"type\"])\n",
    "outputs[\"size\"] = tf.keras.layers.StringLookup(\n",
    "    vocabulary=[\"small\", \"medium\", \"large\"])(inputs[\"size\"])\n",
    "normalizer = tf.keras.layers.Normalization(axis=None)\n",
    "normalizer.adapt(ds_train.map(lambda x, y: x[\"weight\"]))\n",
    "outputs[\"weight\"] =  normalizer(inputs[\"weight\"])\n",
    "\n",
    "preprocessing_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "ds_train = ds_train.map(lambda x, y: (preprocessing_model(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "ds_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718807681.523112    3308 service.cc:145] XLA service 0x77ceac03f7b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718807681.523185    3308 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1660, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - binary_accuracy: 0.6667 - loss: 0.5964\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6667 - loss: 0.5917\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6667 - loss: 0.5884\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6667 - loss: 0.5856\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.6667 - loss: 0.5832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718807682.022164    3308 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x77cf6f366090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "inputs[\"type\"] = tf.keras.Input(name=\"type\", shape=(3,), dtype=tf.float32)\n",
    "inputs[\"size\"] = tf.keras.Input(name=\"size\", shape=(), dtype=tf.int64)\n",
    "inputs[\"weight\"] = tf.keras.Input(name=\"weight\", shape=(1,), dtype=tf.float32)\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=3, output_dim=4)\n",
    "\n",
    "h = tf.keras.layers.Concatenate()([\n",
    "    inputs[\"type\"],\n",
    "    embedding(inputs[\"size\"]),\n",
    "    inputs[\"weight\"]\n",
    "])\n",
    "\n",
    "outputs = {}\n",
    "outputs[\"pred\"] = tf.keras.layers.Dense(name=\"pred\", units=1)(h)\n",
    "\n",
    "training_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "training_model.compile(\n",
    "    loss={\"pred\": tf.keras.losses.BinaryCrossentropy(from_logits=True)},\n",
    "    metrics={\"pred\": [tf.keras.metrics.BinaryAccuracy()]}\n",
    ")\n",
    "training_model.fit(x=ds_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': array([[0.51435804]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = preprocessing_model.input\n",
    "outputs = training_model(preprocessing_model(inputs))\n",
    "inference_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "inference_model.save(\"model.keras\")\n",
    "\n",
    "x_test = {\n",
    "    \"type\": [0],\n",
    "    \"size\": [\"foo\"],\n",
    "    \"weight\": [-0.7]\n",
    "}\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(tensors=x_test)\\\n",
    "    .batch(batch_size=32)\n",
    "\n",
    "inference_model = tf.keras.models.load_model(\"model.keras\")\n",
    "inference_model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acute Inflammations\n",
    "\n",
    "The `acute inflammations` was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two diseases of the urinary system. You can find out more about the dataset [here](https://archive.ics.uci.edu/ml/datasets/Acute+Inflammations).\n",
    "\n",
    "Attribute information:\n",
    "\n",
    "Inputs:\n",
    "- Temperature of patient : 35C-42C\n",
    "- Occurrence of nausea : yes/no\n",
    "- Lumbar pain : yes/no\n",
    "- Urine pushing (continuous need for urination) : yes/no\n",
    "- Micturition pains : yes/no\n",
    "- Burning of urethra, itch, swelling of urethra outlet : yes/no\n",
    "\n",
    "Outputs:\n",
    "- decision 1: Inflammation of urinary bladder : yes/no\n",
    "- decision 2: Nephritis of renal pelvis origin : yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zm1zoEEX0_1Y",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   temp    120 non-null    float32\n",
      " 1   nocc    120 non-null    object \n",
      " 2   lumbp   120 non-null    object \n",
      " 3   up      120 non-null    object \n",
      " 4   mict    120 non-null    object \n",
      " 5   bis     120 non-null    object \n",
      " 6   inflam  120 non-null    object \n",
      " 7   nephr   120 non-null    object \n",
      "dtypes: float32(1), object(7)\n",
      "memory usage: 7.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>nocc</th>\n",
       "      <th>lumbp</th>\n",
       "      <th>up</th>\n",
       "      <th>mict</th>\n",
       "      <th>bis</th>\n",
       "      <th>inflam</th>\n",
       "      <th>nephr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.900002</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.900002</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temp nocc lumbp   up mict  bis inflam nephr\n",
       "0  35.500000   no   yes   no   no   no     no    no\n",
       "1  35.900002   no    no  yes  yes  yes    yes    no\n",
       "2  35.900002   no   yes   no   no   no     no    no\n",
       "3  36.000000   no    no  yes  yes  yes    yes    no\n",
       "4  36.000000   no   yes   no   no   no     no    no"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "dataset_url = 'https://archive.ics.uci.edu/static/public/184/acute+inflammations.zip'\n",
    "csv_file = 'datasets/diagnosis.data'\n",
    "\n",
    "tf.keras.utils.get_file(fname='acute+inflammations.zip',\n",
    "    origin=dataset_url, extract=True, cache_dir=\".\")\n",
    "df_raw = pd.read_csv(csv_file, encoding='utf-16', sep='\\t', header=None,\n",
    " names=['temp', 'nocc', 'lumbp', 'up', 'mict', 'bis', 'inflam', 'nephr'])\n",
    "df_raw['temp'] = df_raw['temp'].str.replace(',', '.').astype(np.float32)\n",
    "df_raw.info()\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "inputs, outputs = {}, {}\n",
    "\n",
    "inputs['temp'] = tf.keras.Input(name='temp', shape=(), dtype=tf.float32)\n",
    "outputs['temp'] = tf.keras.layers.Discretization(\n",
    "    bin_boundaries=[35, 36, 37, 38, 39, 40, 41, 42])(inputs['temp'])\n",
    "outputs['temp'] = tf.keras.layers.CategoryEncoding(\n",
    "    num_tokens=9, output_mode='one_hot')(outputs['temp'])\n",
    "\n",
    "for h in df.select_dtypes(include=object).columns:\n",
    "    inputs[h] = tf.keras.Input(name=h, shape=(), dtype=tf.string)\n",
    "    outputs[h] = tf.keras.layers.StringLookup(max_tokens=2,\n",
    "        vocabulary=df[h].unique(), num_oov_indices=0)(inputs[h])\n",
    "\n",
    "preprocessing_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def features_labels(r):\n",
    "    x = {k: v for k, v in r.items() if k not in ['inflam', 'nephr']}\n",
    "    y = {k: v for k, v in r.items() if k in ['inflam', 'nephr']}\n",
    "    return (x, y)\n",
    "\n",
    "def df_to_ds(df, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(tensors=dict(df))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size=4)\n",
    "    ds = ds.map(lambda x: preprocessing_model(x),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(map_func=features_labels).cache()\\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LWqM6UHr0_1a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'temp': TensorSpec(shape=(None, 9), dtype=tf.float32, name=None),\n",
       "  'nocc': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'lumbp': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'up': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'mict': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'bis': TensorSpec(shape=(None,), dtype=tf.int64, name=None)},\n",
       " {'inflam': TensorSpec(shape=(None,), dtype=tf.int64, name=None),\n",
       "  'nephr': TensorSpec(shape=(None,), dtype=tf.int64, name=None)})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "df_train, df_test = model_selection.train_test_split(\n",
    "    df_raw, test_size=0.1, random_state=42)\n",
    "\n",
    "ds_train = df_to_ds(df=df_train, shuffle=True)\n",
    "ds_test = df_to_ds(df=df_test)\n",
    "ds_test.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FCXBANLt0_1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'temp': <tf.Tensor: shape=(4, 9), dtype=float32, numpy=\n",
       "  array([[0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)>,\n",
       "  'nocc': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 0, 0, 1])>,\n",
       "  'lumbp': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 1, 0])>,\n",
       "  'up': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 1, 1])>,\n",
       "  'mict': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 1, 0, 1])>,\n",
       "  'bis': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 0, 0])>},\n",
       " {'inflam': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 1, 1])>,\n",
       "  'nephr': <tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 0, 0, 1])>})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds_train.take(count=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9Mlx1kE0_1a",
    "outputId": "2f668e63-e032-44a0-cc7c-ebba70d38535"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(tensors=(x_train, y_train))\n",
    "ds_train = ds_train.map(map_func=lambda x, y: (\n",
    "    tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_train = ds_train.map(map_func=lambda x, y: (\n",
    "    tf.reshape(x, (784,)), y))\n",
    "ds_train = ds_train.shuffle(buffer_size=len(ds_train))\\\n",
    "    .batch(batch_size=batch_size)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(tensors=(x_test, y_test))\n",
    "ds_test = ds_test.map(map_func=lambda x, y:\n",
    "    (tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_test = ds_test.map(map_func=lambda x, y: (\n",
    "    tf.reshape(x, (784,)), y))\n",
    "ds_test = ds_test.batch(batch_size=batch_size)\n",
    "print(\"Element spec:\", ds_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZTQGBG_0_1a",
    "outputId": "6330c0be-b61e-40c8-9d45-b7ec52ec5945",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    h = tf.keras.layers.Dense(units=64,\n",
    "        activation=tf.keras.activations.relu,\n",
    "        kernel_regularizer=tf.keras.regularizers.L2(l2=1e-5))(inputs)\n",
    "    h = tf.keras.layers.Dropout(rate=0.2)(h)\n",
    "    outputs = tf.keras.layers.Dense(units=num_classes,\n",
    "        activation=tf.keras.activations.softmax)(h)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model(input_shape=(784,), num_classes=10)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    logs = {}\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs=x, training=True)\n",
    "        loss = model.compute_loss(y=y, y_pred=y_pred)\n",
    "\n",
    "    trainable_vars = model.trainable_variables\n",
    "    grads = tape.gradient(target=loss,\n",
    "        sources=trainable_vars)\n",
    "    model.optimizer.apply_gradients(grads_and_vars=zip(\n",
    "        grads, trainable_vars))\n",
    "\n",
    "    for metric in model.metrics:\n",
    "        if metric.name==\"loss\":\n",
    "            metric.update_state(values=loss)\n",
    "        else:\n",
    "            metric.update_state(y_true=y, y_pred=y_pred)\n",
    "\n",
    "    metrics = [m.result() for m in model.metrics]\n",
    "    logs = {f\"train_{k}\": v for k, v in metrics[1].items()}\n",
    "    logs[\"train_loss\"] = metrics[0]\n",
    "\n",
    "    return logs\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    y_pred = model(inputs=x, training=False)\n",
    "    loss = model.compute_loss(y=y, y_pred=y_pred)\n",
    "\n",
    "    for metric in model.metrics:\n",
    "        if metric.name==\"loss\":\n",
    "            metric.update_state(values=loss)\n",
    "        else:\n",
    "            metric.update_state(y_true=y, y_pred=y_pred)\n",
    "\n",
    "    metrics = [m.result() for m in model.metrics]\n",
    "    logs = {f\"test_{k}\": v for k, v in metrics[1].items()}\n",
    "    logs[\"test_loss\"] = metrics[0]\n",
    "\n",
    "    return logs\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"test_loss\",\n",
    "    patience=1)\n",
    "callbacks = tf.keras.callbacks.CallbackList(model=model,\n",
    "    callbacks=[reduce_lr], add_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKTz7LqHLVQg",
    "outputId": "808488ef-8035-458c-ca47-4d0ffb58cdae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "start_time = time.time()\n",
    "history = {\n",
    "    \"train_loss\": [], \"test_loss\": [],\n",
    "    \"train_accuracy\": [], \"test_accuracy\": []\n",
    "}\n",
    "\n",
    "logs = {}\n",
    "callbacks.on_train_begin(logs=logs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    callbacks.on_epoch_begin(epoch=epoch, logs=logs)\n",
    "\n",
    "    for x, y in ds_train:\n",
    "        logs = train_step(x, y)\n",
    "    history[\"train_loss\"].append(logs[\"train_loss\"].numpy())\n",
    "    history[\"train_accuracy\"].append(logs[\"train_accuracy\"].numpy())\n",
    "\n",
    "    for x, y in ds_test:\n",
    "        logs = test_step(x, y)\n",
    "    history[\"test_loss\"].append(logs[\"test_loss\"].numpy())\n",
    "    history[\"test_accuracy\"].append(logs[\"test_accuracy\"].numpy())\n",
    "\n",
    "    callbacks.on_epoch_end(epoch=epoch, logs=logs)\n",
    "\n",
    "callbacks.on_train_end(logs=logs)\n",
    "print(\"Time taken: %.2fs\"%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whW74r9O0_1b",
    "outputId": "fe714263-75b0-4805-cbc2-e355227ea21b"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "for ax, m in zip(axes, [\"loss\", \"accuracy\"]):\n",
    "    for l in [\"train\", \"test\"]:\n",
    "        g = sns.lineplot(ax=ax, label=l, x=range(num_epochs), y=history[f\"{l}_{m}\"])\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel(xlabel=\"epoch\")\n",
    "    ax.set_ylabel(ylabel=f\"{m}\")\n",
    "    ax.set_title(label=f\"{m} vs. epoch\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
