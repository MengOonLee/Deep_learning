{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juxNknyiLVQH"
   },
   "source": [
    "# Introduction to TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cNXDPvgqMEi",
    "outputId": "a9a45694-24b3-48f8-bc25-901cb7d2aaa2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.uint8, name=None))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed=42)\n",
    "\n",
    "x = tf.keras.Input(shape=(28, 28), dtype=tf.float32)\n",
    "h = tf.keras.layers.Rescaling(scale=1./255)(inputs=x)\n",
    "y = tf.keras.layers.Reshape(target_shape=(784,))(inputs=h)\n",
    "preprocessing_model = tf.keras.Model(inputs=x, outputs=y)\n",
    "\n",
    "def get_ds(x, y, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(tensors=(x, y)).cache()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(y))\n",
    "    ds = ds.batch(batch_size=64)\n",
    "    ds = ds.map(map_func=lambda x, y: (preprocessing_model(x), y),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "ds_train = get_ds(x=x_train, y=y_train, shuffle=True)\n",
    "ds_test = get_ds(x=x_test, y=y_test)\n",
    "ds_test.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.41241825>, 'train_acc': <tf.Tensor: shape=(), dtype=float32, numpy=0.88058335>}\n",
      "1 {'train_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3141935>, 'train_acc': <tf.Tensor: shape=(), dtype=float32, numpy=0.9091>}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed=42)\n",
    "\n",
    "x = tf.keras.Input(shape=(784,))\n",
    "h = tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu,\n",
    "    kernel_regularizer=tf.keras.regularizers.L2(l2=1e-5))(inputs=x)\n",
    "h = tf.keras.layers.Dropout(rate=0.2)(inputs=h)\n",
    "y = tf.keras.layers.Dense(units=10,\n",
    "    activation=tf.keras.activations.softmax)(inputs=h)\n",
    "training_model = tf.keras.Model(inputs=x, outputs=y)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [\n",
    "    tf.keras.metrics.Mean(name=\"loss\"),\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
    "]\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    logs = {}\n",
    "    trainable_vars = training_model.trainable_variables\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = training_model(inputs=x, training=True)\n",
    "        loss = loss_fn(y_true=y, y_pred=y_pred)\n",
    "        grads = tape.gradient(target=loss,\n",
    "            sources=trainable_vars)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(\n",
    "        grads, trainable_vars))\n",
    "\n",
    "    for metric in metrics:\n",
    "        if metric.name==\"loss\":\n",
    "            metric.update_state(values=loss)\n",
    "        else:\n",
    "            metric.update_state(y_true=y, y_pred=y_pred)\n",
    "        logs[f\"train_{metric.name}\"] = metric.result()\n",
    "        # metric.reset_state()\n",
    "\n",
    "    return logs\n",
    "\n",
    "for epoch in range(2):\n",
    "    for x, y in ds_train:\n",
    "        logs = train_step(x=x, y=y)\n",
    "    print(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeOo67-iNhSB"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class DenseModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense01 = tf.keras.layers.Dense(units=64,\n",
    "            activation=tf.keras.activations.relu,\n",
    "            kernel_regularizer=tf.keras.regularizers.L2(l2=1e-5))\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=0.2)\n",
    "        self.dense02 =  tf.keras.layers.Dense(units=10,\n",
    "            activation=tf.keras.activations.softmax)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense01(inputs=inputs)\n",
    "        x = self.dropout(inputs=x, training=training)\n",
    "        y = self.dense02(inputs=x)\n",
    "        return y\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(inputs=x, training=True)\n",
    "            loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "        grads = tape.gradient(target=loss,\n",
    "            sources=self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(grads_and_vars=zip(\n",
    "            grads, self.trainable_variables))\n",
    "\n",
    "        for m in self.metrics:\n",
    "            if m.name==\"loss\":\n",
    "                m.update_state(values=loss)\n",
    "            else:\n",
    "                m.update_state(y_true=y, y_pred=y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(inputs=x)\n",
    "        loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "\n",
    "        for m in self.metrics:\n",
    "            if m.name==\"loss\":\n",
    "                m.update_state(values=loss)\n",
    "            else:\n",
    "                m.update_state(y_true=y, y_pred=y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "training_model = DenseModel()\n",
    "training_model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "NO3Iu2bCr6IB",
    "outputId": "b076127e-e356-47af-8085-e25371d753bb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "ckpt_path = \"models/training.weights.h5\"\n",
    "ckptModel = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_acc\",\n",
    "    mode=\"max\", save_best_only=True, save_weights_only=True,\n",
    "    filepath=ckpt_path)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "    mode=\"min\", patience=1, factor=0.9)\n",
    "\n",
    "start_time = time.time()\n",
    "history = training_model.fit(x=ds_train, validation_data=ds_test,\n",
    "    callbacks=[ckptModel, reduceLR], epochs=10, verbose=0)\n",
    "print(\"Training duration: %2.fs\"%(time.time() - start_time))\n",
    "\n",
    "df_history = pd.DataFrame(history.history)\n",
    "df_history[\"epoch\"] = df_history.index + 1\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle(t=\"Training Metrics\")\n",
    "axes[1].set_xlabel(xlabel=\"epoch\")\n",
    "for ax, m in zip(axes, [\"loss\", \"acc\"]):\n",
    "    g = sns.lineplot(ax=ax, data=df_history, label=\"train\",\n",
    "        x=\"epoch\", y=f\"{m}\")\n",
    "    g = sns.lineplot(ax=ax, data=df_history, label=\"val\",\n",
    "        x=\"epoch\", y=f\"val_{m}\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_ylabel(ylabel=f\"{m}\")\n",
    "    ax.set_title(label=f\"{m} vs. epoch\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "training_model.load_weights(ckpt_path)\n",
    "loss, acc = training_model.evaluate(x=ds_test, verbose=0)\n",
    "print(f\"Test: loss={loss:.2f}, acc={acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyIIe6iWNhSC",
    "outputId": "54fa2616-909e-4fd3-a97d-0f9e55193179"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "import numpy as np\n",
    "\n",
    "inputs = preprocessing_model.input\n",
    "outputs = training_model(preprocessing_model(inputs))\n",
    "inference_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_path = \"models/inference.keras\"\n",
    "inference_model.save(filepath=model_path)\n",
    "\n",
    "inference_model = tf.keras.models.load_model(filepath=model_path)\n",
    "\n",
    "idx = 79\n",
    "x_pred = np.reshape(a=x_test[idx], newshape=(1, 28, 28))\n",
    "y_pred = inference_model(x_pred)\n",
    "print(\"y_true:\", y_test[idx], \"y_pred:\", np.argmax(y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
