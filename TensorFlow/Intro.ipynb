{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow/Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juxNknyiLVQH"
   },
   "source": [
    "# Introduction to TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZeFZkX3q0_1T"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(seed=42)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "sPGUEw-f9bRl",
    "outputId": "c105d3a0-1fc5-41ef-b09a-4d1b286d5f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'type': <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "  array([[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]], dtype=float32)>,\n",
       "  'size': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 1, 2])>,\n",
       "  'weight': <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[ 1.3934661 , -0.48771313, -0.9057528 ]], dtype=float32)>},\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 1, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = {\n",
    "    \"type\": [0, 1, 1],\n",
    "    \"size\": [\"small\", \"small\", \"medium\"],\n",
    "    \"weight\": [2.7, 1.8, 1.6]\n",
    "}\n",
    "y_train = [1, 1, 0]\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(tensors=(x_train, y_train))\n",
    "ds_train = ds_train.map(lambda x, y: (\n",
    "    {k: tf.expand_dims(input=v, axis=-1) for k, v in x.items()}, y))\n",
    "ds_train = ds_train.batch(batch_size=3)\n",
    "\n",
    "inputs = {}\n",
    "inputs[\"type\"] = tf.keras.Input(name=\"type\", shape=(), dtype=tf.int64)\n",
    "inputs[\"size\"] = tf.keras.Input(name=\"size\", shape=(), dtype=tf.string)\n",
    "inputs[\"weight\"] = tf.keras.Input(name=\"weight\", shape=(), dtype=tf.float32)\n",
    "\n",
    "outputs = {}\n",
    "outputs[\"type\"] = tf.keras.layers.CategoryEncoding(\n",
    "    num_tokens=3, output_mode=\"one_hot\")(inputs[\"type\"])\n",
    "outputs[\"size\"] = tf.keras.layers.StringLookup(\n",
    "    vocabulary=[\"small\", \"medium\", \"large\"])(inputs[\"size\"])\n",
    "normalizer = tf.keras.layers.Normalization()\n",
    "normalizer.adapt(ds_train.map(lambda x, y: x[\"weight\"]))\n",
    "outputs[\"weight\"] =  normalizer(inputs[\"weight\"])\n",
    "\n",
    "preprocessing_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "ds_train = ds_train.map(lambda x, y: (preprocessing_model(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "    .cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "next(iter(ds_train.take(count=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_15_1/concatenate_3_1/concat defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Work/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Work/venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1381/628130405.py\", line 21, in <module>\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/models/functional.py\", line 202, in call\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/ops/function.py\", line 155, in _run_through_graph\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/models/functional.py\", line 592, in call\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/layers/merging/base_merge.py\", line 189, in call\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/layers/merging/concatenate.py\", line 101, in _merge_function\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 1352, in concatenate\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 883, in concatenate\n\nConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [3,3] vs. shape[2] = [1,3]\n\t [[{{node functional_15_1/concatenate_3_1/concat}}]] [Op:__inference_one_step_on_iterator_4716]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m training_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs)\n\u001b[1;32m     17\u001b[0m training_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     19\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy()]\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtraining_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Work/venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_15_1/concatenate_3_1/concat defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Work/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Work/venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Work/venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/Work/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1381/628130405.py\", line 21, in <module>\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/models/functional.py\", line 202, in call\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/ops/function.py\", line 155, in _run_through_graph\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/models/functional.py\", line 592, in call\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/layers/merging/base_merge.py\", line 189, in call\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/layers/merging/concatenate.py\", line 101, in _merge_function\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 1352, in concatenate\n\n  File \"/Work/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 883, in concatenate\n\nConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [3,3] vs. shape[2] = [1,3]\n\t [[{{node functional_15_1/concatenate_3_1/concat}}]] [Op:__inference_one_step_on_iterator_4716]"
     ]
    }
   ],
   "source": [
    "inputs = {}\n",
    "inputs[\"type\"] = tf.keras.Input(name=\"type\", shape=(3,), dtype=tf.float32)\n",
    "inputs[\"size\"] = tf.keras.Input(name=\"size\", shape=(), dtype=tf.int64)\n",
    "inputs[\"weight\"] = tf.keras.Input(name=\"weight\", shape=(1,), dtype=tf.float32)\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=3, output_dim=4)\n",
    "\n",
    "h = tf.keras.layers.Concatenate()([\n",
    "    inputs[\"type\"],\n",
    "    embedding(inputs[\"size\"]),\n",
    "    inputs[\"weight\"]\n",
    "])\n",
    "\n",
    "outputs = tf.keras.layers.Dense(units=1)(h)\n",
    "\n",
    "training_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "training_model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")\n",
    "training_model.fit(x=ds_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5399132]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = preprocessing_model.input\n",
    "outputs = training_model(preprocessing_model(inputs))\n",
    "inference_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "inference_model.save(\"model.keras\")\n",
    "\n",
    "x_test = {\n",
    "    \"type\": [0],\n",
    "    \"size\": [\"foo\"],\n",
    "    \"weight\": [-0.7]\n",
    "}\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(tensors=x_test)\n",
    "ds_test = ds_test.map(map_func=lambda x:\n",
    "    {k: tf.expand_dims(input=v, axis=-1) for k, v in x.items()})\\\n",
    "    .batch(batch_size=1)\n",
    "\n",
    "inference_model = tf.keras.models.load_model(\"model.keras\")\n",
    "inference_model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "t0JC8sUA0_1U",
    "outputId": "e0cb3683-67a9-49cf-f8f1-36376e6d7598",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11537 entries, 0 to 11536\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Type           11537 non-null  object\n",
      " 1   Age            11537 non-null  int64 \n",
      " 2   Breed1         11537 non-null  object\n",
      " 3   Gender         11537 non-null  object\n",
      " 4   Color1         11537 non-null  object\n",
      " 5   Color2         11537 non-null  object\n",
      " 6   MaturitySize   11537 non-null  object\n",
      " 7   FurLength      11537 non-null  object\n",
      " 8   Vaccinated     11537 non-null  object\n",
      " 9   Sterilized     11537 non-null  object\n",
      " 10  Health         11537 non-null  object\n",
      " 11  Fee            11537 non-null  int64 \n",
      " 12  PhotoAmt       11537 non-null  int64 \n",
      " 13  AdoptionSpeed  11537 non-null  int64 \n",
      "dtypes: int64(4), object(10)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  PhotoAmt  AdoptionSpeed  \n",
       "0     Short         No         No  Healthy  100         1              2  \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0         2              0  \n",
       "2    Medium        Yes         No  Healthy    0         7              3  \n",
       "3     Short        Yes         No  Healthy  150         8              2  \n",
       "4     Short         No         No  Healthy    0         3              2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_url = \"http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip\"\n",
    "csv_file = \"datasets/petfinder-mini/petfinder-mini.csv\"\n",
    "\n",
    "tf.keras.utils.get_file(fname=\"petfinder_mini.zip\",\n",
    "    origin=dataset_url, extract=True, cache_dir=\".\")\n",
    "df = pd.read_csv(csv_file)\n",
    "df.drop(inplace=True, columns=[\"Description\"])\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2Z3DydUf0_1W",
    "outputId": "efb24952-aaf6-4ee8-f8ea-90c2e505ebfd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Type': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'Age': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None),\n",
       "  'Breed1': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'Gender': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'Color1': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'Color2': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'MaturitySize': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'FurLength': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'Vaccinated': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'Sterilized': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'Health': TensorSpec(shape=(None, 1), dtype=tf.string, name=None),\n",
       "  'Fee': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None),\n",
       "  'PhotoAmt': TensorSpec(shape=(None, 1), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_ds(dataframe, batch_size, shuffle=False):\n",
    "    df = dataframe.copy()\n",
    "    y = df.pop(\"AdoptionSpeed\")\n",
    "    y = np.where(y==4, 0, 1)\n",
    "    x = {k: v.values[:, tf.newaxis] for k, v in df.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices(tensors=(x, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size=batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "df_train, df_test = model_selection.train_test_split(\n",
    "    df, test_size=0.1, random_state=42)\n",
    "\n",
    "ds_train = df_to_ds(dataframe=df_train, batch_size=256, shuffle=True)\n",
    "ds_test = df_to_ds(dataframe=df_test, batch_size=32)\n",
    "ds_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-klK3EV0_1W"
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "features = []\n",
    "\n",
    "for h in [\"Fee\", \"PhotoAmt\"]:\n",
    "    col = tf.keras.Input(shape=(), name=h, dtype=tf.int64)\n",
    "    inputs.append(col)\n",
    "    x = ds_train.map(map_func=lambda x, y: x[h])\n",
    "    normalizer = tf.keras.layers.Normalization(axis=None)\n",
    "    normalizer.adapt(x)\n",
    "    feature = normalizer(col)\n",
    "    features.append(feature)\n",
    "\n",
    "for h in [\"Type\", \"Breed1\", \"Gender\", \"Color1\", \"Color2\", \"MaturitySize\", \"FurLength\",\n",
    "        \"Vaccinated\", \"Sterilized\", \"Health\"]:\n",
    "    col = tf.keras.Input(shape=(), name=h, dtype=tf.string)\n",
    "    inputs.append(col)\n",
    "    x = ds_train.map(map_func=lambda x, y: x[h])\n",
    "    index = tf.keras.layers.StringLookup(max_tokens=5)\n",
    "    index.adapt(x)\n",
    "    feature = tf.keras.layers.CategoryEncoding(\n",
    "        num_tokens=index.vocabulary_size())\n",
    "    features.append(feature)\n",
    "\n",
    "for h in [\"Age\"]:\n",
    "    col = tf.keras.Input(shape=(), name=h, dtype=tf.int64)\n",
    "    inputs.append(col)\n",
    "    x = ds_train.map(map_func=lambda x, y: x[h])\n",
    "    index = tf.keras.layers.IntegerLookup(max_tokens=5)\n",
    "    index.adapt(x)\n",
    "    feature = tf.keras.layers.CategoryEncoding(\n",
    "        num_tokens=index.vocabulary_size())\n",
    "    features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4HJpV_10_1X",
    "outputId": "3e20b349-c60d-4acc-8061-17a9e6af938a"
   },
   "outputs": [],
   "source": [
    "outputs = tf.keras.layers.concatenate(features)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QAhEqt10_1X"
   },
   "source": [
    "### UCI Bank Marketing Dataset\n",
    "\n",
    "The `Bank Marketing` dataset is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. [here](https://archive.ics.uci.edu/dataset/222/bank+marketing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm1zoEEX0_1Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ve9RWaOz0_1Y",
    "outputId": "23cc27a0-181f-45dc-b0f8-93434a97b963"
   },
   "outputs": [],
   "source": [
    "df_bank = pd.read_csv(\"data/bank/bank-full.csv\", delimiter=\";\")\n",
    "df_bank.info()\n",
    "df_bank.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMRNzeeI0_1Y",
    "outputId": "7ded5b42-3556-41fc-c6d7-514134ab0256",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_bank = tf.data.Dataset.from_tensor_slices(tensors=dict(df_bank))\n",
    "ds_bank.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBXIslfl0_1Z"
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'age': tf.keras.Input(shape=(1,), dtype=tf.int64, name='age')\n",
    "}\n",
    "\n",
    "age = tf.keras.layers.Discretization(\n",
    "    bin_boundaries=[10, 20, 30, 40, 50, 60, 70, 80, 90])(inputs['age'])\n",
    "age = tf.keras.layers.CategoryEncoding(num_tokens=10, output_mode='one_hot')(age)\n",
    "\n",
    "outputs = {\n",
    "    'age': age\n",
    "}\n",
    "\n",
    "preprocessing_model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehDt85Th0_1Z",
    "outputId": "7f3ed132-5dfc-40c1-cb39-9150a5ef1881",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds01 = ds_bank.batch(1)\n",
    "ds01 = ds01.map(lambda x: preprocessing_model(x))\n",
    "next(iter(ds01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWqM6UHr0_1a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = model_selection.train_test_split(\n",
    "    df_bank, test_size=0.1, random_state=42)\n",
    "\n",
    "dict_train = dict(df_train)\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(tensors={\n",
    "    k: dict_train[k] for k in dict_train})\n",
    "\n",
    "dict_test = dict(df_test)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(tensors={\n",
    "    k: dict_test[k] for k in dict_test})\n",
    "ds_test.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCXBANLt0_1a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9Mlx1kE0_1a",
    "outputId": "2f668e63-e032-44a0-cc7c-ebba70d38535"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(tensors=(x_train, y_train))\n",
    "ds_train = ds_train.map(map_func=lambda x, y: (\n",
    "    tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_train = ds_train.map(map_func=lambda x, y: (\n",
    "    tf.reshape(x, (784,)), y))\n",
    "ds_train = ds_train.shuffle(buffer_size=len(ds_train))\\\n",
    "    .batch(batch_size=batch_size)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(tensors=(x_test, y_test))\n",
    "ds_test = ds_test.map(map_func=lambda x, y:\n",
    "    (tf.cast(x=x, dtype=tf.float32)/255., y))\n",
    "ds_test = ds_test.map(map_func=lambda x, y: (\n",
    "    tf.reshape(x, (784,)), y))\n",
    "ds_test = ds_test.batch(batch_size=batch_size)\n",
    "print(\"Element spec:\", ds_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZTQGBG_0_1a",
    "outputId": "6330c0be-b61e-40c8-9d45-b7ec52ec5945",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    h = tf.keras.layers.Dense(units=64,\n",
    "        activation=tf.keras.activations.relu,\n",
    "        kernel_regularizer=tf.keras.regularizers.L2(l2=1e-5))(inputs)\n",
    "    h = tf.keras.layers.Dropout(rate=0.2)(h)\n",
    "    outputs = tf.keras.layers.Dense(units=num_classes,\n",
    "        activation=tf.keras.activations.softmax)(h)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model(input_shape=(784,), num_classes=10)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    logs = {}\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs=x, training=True)\n",
    "        loss = model.compute_loss(y=y, y_pred=y_pred)\n",
    "\n",
    "    trainable_vars = model.trainable_variables\n",
    "    grads = tape.gradient(target=loss,\n",
    "        sources=trainable_vars)\n",
    "    model.optimizer.apply_gradients(grads_and_vars=zip(\n",
    "        grads, trainable_vars))\n",
    "\n",
    "    for metric in model.metrics:\n",
    "        if metric.name==\"loss\":\n",
    "            metric.update_state(values=loss)\n",
    "        else:\n",
    "            metric.update_state(y_true=y, y_pred=y_pred)\n",
    "\n",
    "    metrics = [m.result() for m in model.metrics]\n",
    "    logs = {f\"train_{k}\": v for k, v in metrics[1].items()}\n",
    "    logs[\"train_loss\"] = metrics[0]\n",
    "\n",
    "    return logs\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    y_pred = model(inputs=x, training=False)\n",
    "    loss = model.compute_loss(y=y, y_pred=y_pred)\n",
    "\n",
    "    for metric in model.metrics:\n",
    "        if metric.name==\"loss\":\n",
    "            metric.update_state(values=loss)\n",
    "        else:\n",
    "            metric.update_state(y_true=y, y_pred=y_pred)\n",
    "\n",
    "    metrics = [m.result() for m in model.metrics]\n",
    "    logs = {f\"test_{k}\": v for k, v in metrics[1].items()}\n",
    "    logs[\"test_loss\"] = metrics[0]\n",
    "\n",
    "    return logs\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"test_loss\",\n",
    "    patience=1)\n",
    "callbacks = tf.keras.callbacks.CallbackList(model=model,\n",
    "    callbacks=[reduce_lr], add_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKTz7LqHLVQg",
    "outputId": "808488ef-8035-458c-ca47-4d0ffb58cdae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "start_time = time.time()\n",
    "history = {\n",
    "    \"train_loss\": [], \"test_loss\": [],\n",
    "    \"train_accuracy\": [], \"test_accuracy\": []\n",
    "}\n",
    "\n",
    "logs = {}\n",
    "callbacks.on_train_begin(logs=logs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    callbacks.on_epoch_begin(epoch=epoch, logs=logs)\n",
    "\n",
    "    for x, y in ds_train:\n",
    "        logs = train_step(x, y)\n",
    "    history[\"train_loss\"].append(logs[\"train_loss\"].numpy())\n",
    "    history[\"train_accuracy\"].append(logs[\"train_accuracy\"].numpy())\n",
    "\n",
    "    for x, y in ds_test:\n",
    "        logs = test_step(x, y)\n",
    "    history[\"test_loss\"].append(logs[\"test_loss\"].numpy())\n",
    "    history[\"test_accuracy\"].append(logs[\"test_accuracy\"].numpy())\n",
    "\n",
    "    callbacks.on_epoch_end(epoch=epoch, logs=logs)\n",
    "\n",
    "callbacks.on_train_end(logs=logs)\n",
    "print(\"Time taken: %.2fs\"%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whW74r9O0_1b",
    "outputId": "fe714263-75b0-4805-cbc2-e355227ea21b"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "for ax, m in zip(axes, [\"loss\", \"accuracy\"]):\n",
    "    for l in [\"train\", \"test\"]:\n",
    "        g = sns.lineplot(ax=ax, label=l, x=range(num_epochs), y=history[f\"{l}_{m}\"])\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel(xlabel=\"epoch\")\n",
    "    ax.set_ylabel(ylabel=f\"{m}\")\n",
    "    ax.set_title(label=f\"{m} vs. epoch\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
