{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading models, with application to the EuroSat dataset\n",
    "\n",
    "### Instructions\n",
    "\n",
    "In this notebook, you will create a neural network that classifies land uses and land covers from satellite imagery. You will save your model using Tensorflow's callbacks and reload it later. You will also load in a pre-trained neural network classifier and compare performance with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "#### PACKAGE IMPORTS ####\n",
    "\n",
    "# Run this cell first to import all required packages. \n",
    "# Do not make any imports elsewhere in the notebook.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![EuroSAT overview image](https://raw.githubusercontent.com/phelber/EuroSAT/master/eurosat_overview_small.jpg)\n",
    "\n",
    "#### The EuroSAT dataset\n",
    "\n",
    "In this assignment, you will use the [EuroSAT dataset](https://github.com/phelber/EuroSAT). It consists of 27000 labelled Sentinel-2 satellite images of different land uses: residential, industrial, highway, river, forest, pasture, herbaceous vegetation, annual crop, permanent crop and sea/lake. For a reference, see the following papers:\n",
    "- Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019.\n",
    "- Introducing EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification. Patrick Helber, Benjamin Bischke, Andreas Dengel. 2018 IEEE International Geoscience and Remote Sensing Symposium, 2018.\n",
    "\n",
    "Your goal is to construct a neural network that classifies a satellite image into one of these 10 classes, as well as applying some of the saving and loading techniques you have learned in the previous sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data\n",
    "\n",
    "The dataset you will train your model on is a subset of the total data, with 4000 training images and 1000 testing images, with roughly equal numbers of each class. The train and test datasets required for this project can be downloaded from the following links:\n",
    "\n",
    "`x_train`: https://drive.google.com/open?id=1cUaIEd9-MLJHFGjLz5QziNvfBtYygplX\n",
    "\n",
    "`y_train`: https://drive.google.com/open?id=1hv24Ufiio9rBeSqgnNoM3dr5sVGwOmBy\n",
    "\n",
    "`x_test`: https://drive.google.com/open?id=1AH9lKHT5P2oQLz8SGMRPWs_M9wIM2ZRH\n",
    "\n",
    "`y_test`: https://drive.google.com/open?id=1i4_azocSDuU3TcDf3OSHO1vF0D5-xMU6\n",
    "\n",
    "The code to import the data is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r",
      "100   408    0   408    0     0    129      0 --:--:--  0:00:03 --:--:--   129\r",
      "100   408    0   408    0     0    129      0 --:--:--  0:00:03 --:--:--   129\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\n",
      "\r",
      "100  186k    0  186k    0     0  40229      0 --:--:--  0:00:04 --:--:-- 40229\r",
      "100 2635k    0 2635k    0     0   457k      0 --:--:--  0:00:05 --:--:-- 2436k\r",
      "100 4971k    0 4971k    0     0   735k      0 --:--:--  0:00:06 --:--:-- 2393k\r",
      "100 6747k    0 6747k    0     0   870k      0 --:--:--  0:00:07 --:--:-- 2188k\r",
      "100 9803k    0 9803k    0     0  1119k      0 --:--:--  0:00:08 --:--:-- 2405k\r",
      "100 12.6M    0 12.6M    0     0  1325k      0 --:--:--  0:00:09 --:--:-- 2550k\r",
      "100 15.5M    0 15.5M    0     0  1484k      0 --:--:--  0:00:10 --:--:-- 2669k\r",
      "100 16.5M    0 16.5M    0     0  1436k      0 --:--:--  0:00:11 --:--:-- 2375k\r",
      "100 17.4M    0 17.4M    0     0  1396k      0 --:--:--  0:00:12 --:--:-- 2214k\r",
      "100 18.3M    0 18.3M    0     0  1366k      0 --:--:--  0:00:13 --:--:-- 1798k\r",
      "100 18.7M    0 18.7M    0     0  1295k      0 --:--:--  0:00:14 --:--:-- 1237k\r",
      "100 19.2M    0 19.2M    0     0  1190k      0 --:--:--  0:00:16 --:--:--  650k\r",
      "100 19.2M    0 19.2M    0     0  1160k      0 --:--:--  0:00:17 --:--:--  539k\r",
      "100 20.7M    0 20.7M    0     0  1197k      0 --:--:--  0:00:17 --:--:--  689k\r",
      "100 22.2M    0 22.2M    0     0  1212k      0 --:--:--  0:00:18 --:--:--  791k\r",
      "100 23.4M    0 23.4M    0     0  1214k      0 --:--:--  0:00:19 --:--:--  971k\r",
      "100 23.9M    0 23.9M    0     0  1175k      0 --:--:--  0:00:20 --:--:-- 1117k\r",
      "100 24.8M    0 24.8M    0     0  1168k      0 --:--:--  0:00:21 --:--:-- 1194k\r",
      "100 25.8M    0 25.8M    0     0  1144k      0 --:--:--  0:00:23 --:--:--  968k\r",
      "100 26.8M    0 26.8M    0     0  1156k      0 --:--:--  0:00:23 --:--:--  943k\r",
      "100 27.5M    0 27.5M    0     0  1140k      0 --:--:--  0:00:24 --:--:--  845k\r",
      "100 28.6M    0 28.6M    0     0  1137k      0 --:--:--  0:00:25 --:--:--  975k\r",
      "100 28.8M    0 28.8M    0     0  1102k      0 --:--:--  0:00:26 --:--:--  821k\r",
      "100 29.1M    0 29.1M    0     0  1072k      0 --:--:--  0:00:27 --:--:--  715k\r",
      "100 29.2M    0 29.2M    0     0  1039k      0 --:--:--  0:00:28 --:--:--  486k\r",
      "100 29.4M    0 29.4M    0     0  1013k      0 --:--:--  0:00:29 --:--:--  388k\r",
      "100 29.8M    0 29.8M    0     0   983k      0 --:--:--  0:00:31 --:--:--  231k\r",
      "100 31.0M    0 31.0M    0     0  1000k      0 --:--:--  0:00:31 --:--:--  441k\r",
      "100 31.8M    0 31.8M    0     0   996k      0 --:--:--  0:00:32 --:--:--  574k\r",
      "100 32.0M    0 32.0M    0     0   964k      0 --:--:--  0:00:34 --:--:--  553k\r",
      "100 33.7M    0 33.7M    0     0   994k      0 --:--:--  0:00:34 --:--:--  879k\r",
      "100 34.6M    0 34.6M    0     0   992k      0 --:--:--  0:00:35 --:--:-- 1052k\r",
      "100 34.9M    0 34.9M    0     0   972k      0 --:--:--  0:00:36 --:--:--  795k\r",
      "100 35.1M    0 35.1M    0     0   954k      0 --:--:--  0:00:37 --:--:--  675k\r",
      "100 35.5M    0 35.5M    0     0   939k      0 --:--:--  0:00:38 --:--:--  759k\r",
      "100 36.1M    0 36.1M    0     0   931k      0 --:--:--  0:00:39 --:--:--  494k\r",
      "100 37.1M    0 37.1M    0     0   932k      0 --:--:--  0:00:40 --:--:--  509k\r",
      "100 38.3M    0 38.3M    0     0   941k      0 --:--:--  0:00:41 --:--:--  715k\r",
      "100 39.7M    0 39.7M    0     0   951k      0 --:--:--  0:00:42 --:--:--  926k\r",
      "100 41.4M    0 41.4M    0     0   969k      0 --:--:--  0:00:43 --:--:-- 1202k\r",
      "100 43.0M    0 43.0M    0     0   984k      0 --:--:--  0:00:44 --:--:-- 1402k\r",
      "100 43.9M    0 43.9M    0     0   984k      0 --:--:--  0:00:45 --:--:-- 1402k\r",
      "100 44.4M    0 44.4M    0     0   972k      0 --:--:--  0:00:46 --:--:-- 1234k\r",
      "100 46.6M    0 46.6M    0     0  1000k      0 --:--:--  0:00:47 --:--:-- 1420k\r",
      "100 49.2M    0 49.2M    0     0  1034k      0 --:--:--  0:00:48 --:--:-- 1606k\r",
      "100 51.4M    0 51.4M    0     0  1059k      0 --:--:--  0:00:49 --:--:-- 1733k\r",
      "100 52.3M    0 52.3M    0     0  1056k      0 --:--:--  0:00:50 --:--:-- 1716k\r",
      "100 53.4M    0 53.4M    0     0  1056k      0 --:--:--  0:00:51 --:--:-- 1840k\r",
      "100 54.4M    0 54.4M    0     0  1056k      0 --:--:--  0:00:52 --:--:-- 1589k\r",
      "100 54.6M    0 54.6M    0     0  1035k      0 --:--:--  0:00:54 --:--:-- 1045k\r",
      "100 54.9M    0 54.9M    0     0  1026k      0 --:--:--  0:00:54 --:--:--  702k\r",
      "100 56.8M    0 56.8M    0     0  1044k      0 --:--:--  0:00:55 --:--:--  924k\r",
      "100 57.3M    0 57.3M    0     0  1035k      0 --:--:--  0:00:56 --:--:--  810k\r",
      "100 58.1M    0 58.1M    0     0  1029k      0 --:--:--  0:00:57 --:--:--  752k\r",
      "100 59.4M    0 59.4M    0     0  1035k      0 --:--:--  0:00:58 --:--:-- 1029k\r",
      "100 61.9M    0 61.9M    0     0  1060k      0 --:--:--  0:00:59 --:--:-- 1434k\r",
      "100 63.8M    0 63.8M    0     0  1075k      0 --:--:--  0:01:00 --:--:-- 1423k\r",
      "100 66.1M    0 66.1M    0     0  1097k      0 --:--:--  0:01:01 --:--:-- 1803k\r",
      "100 68.7M    0 68.7M    0     0  1122k      0 --:--:--  0:01:02 --:--:-- 2207k\r",
      "100 72.2M    0 72.2M    0     0  1159k      0 --:--:--  0:01:03 --:--:-- 2624k\r",
      "100 75.7M    0 75.7M    0     0  1198k      0 --:--:--  0:01:04 --:--:-- 2844k\r",
      "100 79.5M    0 79.5M    0     0  1236k      0 --:--:--  0:01:05 --:--:-- 3138k\r",
      "100 82.5M    0 82.5M    0     0  1264k      0 --:--:--  0:01:06 --:--:-- 3309k\r",
      "100 85.7M    0 85.7M    0     0  1285k      0 --:--:--  0:01:08 --:--:-- 3130k\r",
      "100 87.6M    0 87.6M    0     0  1304k      0 --:--:--  0:01:08 --:--:-- 3142k\r",
      "100 89.5M    0 89.5M    0     0  1313k      0 --:--:--  0:01:09 --:--:-- 2798k\r",
      "100 92.4M    0 92.4M    0     0  1337k      0 --:--:--  0:01:10 --:--:-- 2710k\r",
      "100 96.2M    0 96.2M    0     0  1370k      0 --:--:--  0:01:11 --:--:-- 2745k\r",
      "100 99.7M    0 99.7M    0     0  1403k      0 --:--:--  0:01:12 --:--:-- 3211k\r",
      "100  103M    0  103M    0     0  1430k      0 --:--:--  0:01:13 --:--:-- 3166k\r",
      "100  106M    0  106M    0     0  1455k      0 --:--:--  0:01:14 --:--:-- 3446k\r",
      "100  108M    0  108M    0     0  1466k      0 --:--:--  0:01:15 --:--:-- 3285k\r",
      "100  110M    0  110M    0     0  1479k      0 --:--:--  0:01:16 --:--:-- 3103k\r",
      "100  114M    0  114M    0     0  1502k      0 --:--:--  0:01:17 --:--:-- 2947k\r",
      "100  116M    0  116M    0     0  1520k      0 --:--:--  0:01:18 --:--:-- 2854k\r",
      "100  120M    0  120M    0     0  1543k      0 --:--:--  0:01:19 --:--:-- 2857k\r",
      "100  123M    0  123M    0     0  1561k      0 --:--:--  0:01:20 --:--:-- 2985k\r",
      "100  126M    0  126M    0     0  1585k      0 --:--:--  0:01:21 --:--:-- 3221k\r",
      "100  129M    0  129M    0     0  1597k      0 --:--:--  0:01:22 --:--:-- 3063k\r",
      "100  129M    0  129M    0     0  1586k      0 --:--:--  0:01:23 --:--:-- 2627k\r",
      "100  130M    0  130M    0     0  1582k      0 --:--:--  0:01:24 --:--:-- 2197k\r",
      "100  131M    0  131M    0     0  1572k      0 --:--:--  0:01:25 --:--:-- 1753k\r",
      "100  132M    0  132M    0     0  1559k      0 --:--:--  0:01:26 --:--:-- 1124k\r",
      "100  132M    0  132M    0     0  1548k      0 --:--:--  0:01:27 --:--:--  736k\r",
      "100  133M    0  133M    0     0  1542k      0 --:--:--  0:01:28 --:--:--  792k\r",
      "100  135M    0  135M    0     0  1539k      0 --:--:--  0:01:29 --:--:--  823k\r",
      "100  135M    0  135M    0     0  1533k      0 --:--:--  0:01:30 --:--:--  872k\r",
      "100  136M    0  136M    0     0  1522k      0 --:--:--  0:01:31 --:--:--  881k\r",
      "100  137M    0  137M    0     0  1513k      0 --:--:--  0:01:32 --:--:--  901k\r",
      "100  138M    0  138M    0     0  1507k      0 --:--:--  0:01:33 --:--:--  898k\r",
      "100  139M    0  139M    0     0  1506k      0 --:--:--  0:01:34 --:--:--  906k\r",
      "100  140M    0  140M    0     0  1498k      0 --:--:--  0:01:35 --:--:--  853k\r",
      "100  141M    0  141M    0     0  1492k      0 --:--:--  0:01:36 --:--:--  940k\r",
      "100  142M    0  142M    0     0  1489k      0 --:--:--  0:01:37 --:--:-- 1036k\r",
      "100  142M    0  142M    0     0  1473k      0 --:--:--  0:01:39 --:--:--  867k\r",
      "100  143M    0  143M    0     0  1470k      0 --:--:--  0:01:39 --:--:--  791k\r",
      "100  144M    0  144M    0     0  1467k      0 --:--:--  0:01:40 --:--:--  884k\r",
      "100  145M    0  145M    0     0  1463k      0 --:--:--  0:01:41 --:--:--  902k\r",
      "100  146M    0  146M    0     0  1453k      0 --:--:--  0:01:42 --:--:--  788k\r",
      "100  146M    0  146M    0     0  1450k      0 --:--:--  0:01:43 --:--:--  970k\r",
      "100  148M    0  148M    0     0  1453k      0 --:--:--  0:01:44 --:--:-- 1117k\r",
      "100  150M    0  150M    0     0  1457k      0 --:--:--  0:01:45 --:--:-- 1245k\r",
      "100  151M    0  151M    0     0  1444k      0 --:--:--  0:01:47 --:--:-- 1086k\r",
      "100  152M    0  152M    0     0  1445k      0 --:--:--  0:01:47 --:--:-- 1273k\r",
      "100  153M    0  153M    0     0  1443k      0 --:--:--  0:01:48 --:--:-- 1299k\r",
      "100  154M    0  154M    0     0  1441k      0 --:--:--  0:01:49 --:--:-- 1179k\r",
      "100  155M    0  155M    0     0  1434k      0 --:--:--  0:01:50 --:--:--  947k\r",
      "100  156M    0  156M    0     0  1430k      0 --:--:--  0:01:51 --:--:-- 1102k\r",
      "100  156M    0  156M    0     0  1425k      0 --:--:--  0:01:52 --:--:--  996k\r",
      "100  157M    0  157M    0     0  1415k      0 --:--:--  0:01:53 --:--:--  831k\r",
      "100  157M    0  157M    0     0  1405k      0 --:--:--  0:01:55 --:--:--  652k\r",
      "100  158M    0  158M    0     0  1398k      0 --:--:--  0:01:55 --:--:--  609k\r",
      "100  159M    0  159M    0     0  1399k      0 --:--:--  0:01:56 --:--:--  699k\r",
      "100  160M    0  160M    0     0  1399k      0 --:--:--  0:01:57 --:--:--  803k\r",
      "100  162M    0  162M    0     0  1400k      0 --:--:--  0:01:58 --:--:-- 1033k\r",
      "100  163M    0  163M    0     0  1398k      0 --:--:--  0:01:59 --:--:-- 1248k\r",
      "100  164M    0  164M    0     0  1393k      0 --:--:--  0:02:00 --:--:-- 1279k\r",
      "100  165M    0  165M    0     0  1389k      0 --:--:--  0:02:01 --:--:-- 1167k\r",
      "100  165M    0  165M    0     0  1381k      0 --:--:--  0:02:02 --:--:--  961k\r",
      "100  166M    0  166M    0     0  1375k      0 --:--:--  0:02:03 --:--:--  789k\r",
      "100  167M    0  167M    0     0  1377k      0 --:--:--  0:02:04 --:--:--  861k\r",
      "100  169M    0  169M    0     0  1379k      0 --:--:--  0:02:05 --:--:-- 1044k\r",
      "100  170M    0  170M    0     0  1379k      0 --:--:--  0:02:06 --:--:-- 1138k\r",
      "100  172M    0  172M    0     0  1379k      0 --:--:--  0:02:07 --:--:-- 1324k\r",
      "100  172M    0  172M    0     0  1371k      0 --:--:--  0:02:08 --:--:-- 1274k\r",
      "100  172M    0  172M    0     0  1364k      0 --:--:--  0:02:09 --:--:-- 1032k\r",
      "100  173M    0  173M    0     0  1358k      0 --:--:--  0:02:10 --:--:--  821k\r",
      "100  174M    0  174M    0     0  1354k      0 --:--:--  0:02:11 --:--:--  704k\r",
      "100  174M    0  174M    0     0  1344k      0 --:--:--  0:02:12 --:--:--  486k\r",
      "100  174M    0  174M    0     0  1336k      0 --:--:--  0:02:13 --:--:--  420k\r",
      "100  175M    0  175M    0     0  1333k      0 --:--:--  0:02:14 --:--:--  545k\r",
      "100  176M    0  176M    0     0  1333k      0 --:--:--  0:02:15 --:--:--  659k\r",
      "100  177M    0  177M    0     0  1331k      0 --:--:--  0:02:16 --:--:--  731k\r",
      "100  179M    0  179M    0     0  1336k      0 --:--:--  0:02:17 --:--:-- 1117k\r",
      "100  180M    0  180M    0     0  1334k      0 --:--:--  0:02:18 --:--:-- 1288k\r",
      "100  181M    0  181M    0     0  1329k      0 --:--:--  0:02:19 --:--:-- 1227k\r",
      "100  182M    0  182M    0     0  1326k      0 --:--:--  0:02:20 --:--:-- 1135k\r",
      "100  182M    0  182M    0     0  1319k      0 --:--:--  0:02:21 --:--:-- 1002k\r",
      "100  183M    0  183M    0     0  1316k      0 --:--:--  0:02:22 --:--:--  751k\r",
      "100  184M    0  184M    0     0  1312k      0 --:--:--  0:02:23 --:--:--  693k\r",
      "100  184M    0  184M    0     0  1304k      0 --:--:--  0:02:24 --:--:--  605k\r",
      "100  184M    0  184M    0     0  1298k      0 --:--:--  0:02:25 --:--:--  522k\r",
      "100  186M    0  186M    0     0  1298k      0 --:--:--  0:02:26 --:--:--  702k\r",
      "100  187M    0  187M    0     0  1300k      0 --:--:--  0:02:27 --:--:--  864k\r",
      "100  189M    0  189M    0     0  1303k      0 --:--:--  0:02:28 --:--:-- 1047k\r",
      "100  190M    0  190M    0     0  1304k      0 --:--:--  0:02:29 --:--:-- 1304k\r",
      "100  191M    0  191M    0     0  1303k      0 --:--:--  0:02:30 --:--:-- 1439k\r",
      "100  192M    0  192M    0     0  1298k      0 --:--:--  0:02:31 --:--:-- 1289k\r",
      "100  192M    0  192M    0     0  1292k      0 --:--:--  0:02:32 --:--:-- 1035k\r",
      "100  193M    0  193M    0     0  1288k      0 --:--:--  0:02:33 --:--:--  858k\r",
      "100  194M    0  194M    0     0  1287k      0 --:--:--  0:02:34 --:--:--  771k\r",
      "100  195M    0  195M    0     0  1285k      0 --:--:--  0:02:35 --:--:--  763k\r",
      "100  196M    0  196M    0     0  1281k      0 --:--:--  0:02:36 --:--:--  750k\r",
      "100  197M    0  197M    0     0  1279k      0 --:--:--  0:02:37 --:--:--  894k\r",
      "100  198M    0  198M    0     0  1277k      0 --:--:--  0:02:38 --:--:--  940k\r",
      "100  198M    0  198M    0     0  1272k      0 --:--:--  0:02:39 --:--:--  810k\r",
      "100  198M    0  198M    0     0  1266k      0 --:--:--  0:02:40 --:--:--  662k\r",
      "100  199M    0  199M    0     0  1261k      0 --:--:--  0:02:41 --:--:--  648k\r",
      "100  199M    0  199M    0     0  1257k      0 --:--:--  0:02:42 --:--:--  548k\r",
      "100  200M    0  200M    0     0  1253k      0 --:--:--  0:02:43 --:--:--  486k\r",
      "100  200M    0  200M    0     0  1248k      0 --:--:--  0:02:44 --:--:--  481k\r",
      "100  201M    0  201M    0     0  1244k      0 --:--:--  0:02:45 --:--:--  543k\r",
      "100  201M    0  201M    0     0  1239k      0 --:--:--  0:02:46 --:--:--  536k\r",
      "100  202M    0  202M    0     0  1235k      0 --:--:--  0:02:47 --:--:--  521k\r",
      "100  202M    0  202M    0     0  1230k      0 --:--:--  0:02:48 --:--:--  474k\r",
      "100  203M    0  203M    0     0  1225k      0 --:--:--  0:02:49 --:--:--  472k\r",
      "100  204M    0  204M    0     0  1223k      0 --:--:--  0:02:50 --:--:--  529k\r",
      "100  205M    0  205M    0     0  1223k      0 --:--:--  0:02:51 --:--:--  665k\r",
      "100  205M    0  205M    0     0  1220k      0 --:--:--  0:02:52 --:--:--  728k\r",
      "100  207M    0  207M    0     0  1221k      0 --:--:--  0:02:53 --:--:--  905k\r",
      "100  207M    0  207M    0     0  1218k      0 --:--:--  0:02:54 --:--:--  972k\r",
      "100  208M    0  208M    0     0  1215k      0 --:--:--  0:02:55 --:--:--  917k\r",
      "100  209M    0  209M    0     0  1213k      0 --:--:--  0:02:56 --:--:--  899k\r",
      "100  210M    0  210M    0     0  1214k      0 --:--:--  0:02:57 --:--:--  990k\r",
      "100  212M    0  212M    0     0  1214k      0 --:--:--  0:02:58 --:--:--  981k\r",
      "100  213M    0  213M    0     0  1214k      0 --:--:--  0:02:59 --:--:-- 1091k\r",
      "100  214M    0  214M    0     0  1216k      0 --:--:--  0:03:00 --:--:-- 1266k\r",
      "100  216M    0  216M    0     0  1216k      0 --:--:--  0:03:01 --:--:-- 1322k\r",
      "100  216M    0  216M    0     0  1215k      0 --:--:--  0:03:02 --:--:-- 1253k\r",
      "100  217M    0  217M    0     0  1211k      0 --:--:--  0:03:03 --:--:-- 1115k\r",
      "100  217M    0  217M    0     0  1206k      0 --:--:--  0:03:04 --:--:--  913k\r",
      "100  218M    0  218M    0     0  1201k      0 --:--:--  0:03:05 --:--:--  667k\r",
      "100  218M    0  218M    0     0  1196k      0 --:--:--  0:03:06 --:--:--  440k\r",
      "100  218M    0  218M    0     0  1190k      0 --:--:--  0:03:07 --:--:--  287k\r",
      "100  218M    0  218M    0     0  1184k      0 --:--:--  0:03:08 --:--:--  183k\r",
      "100  218M    0  218M    0     0  1178k      0 --:--:--  0:03:09 --:--:--  142k\r",
      "100  218M    0  218M    0     0  1172k      0 --:--:--  0:03:10 --:--:-- 98917\r",
      "100  218M    0  218M    0     0  1166k      0 --:--:--  0:03:11 --:--:-- 79416\r",
      "100  218M    0  218M    0     0  1160k      0 --:--:--  0:03:12 --:--:-- 67981\r",
      "100  219M    0  219M    0     0  1157k      0 --:--:--  0:03:13 --:--:--  135k\r",
      "100  220M    0  220M    0     0  1159k      0 --:--:--  0:03:14 --:--:--  434k\r",
      "100  223M    0  223M    0     0  1168k      0 --:--:--  0:03:15 --:--:--  999k\r",
      "100  225M    0  225M    0     0  1175k      0 --:--:--  0:03:16 --:--:-- 1522k\r",
      "100  227M    0  227M    0     0  1172k      0 --:--:--  0:03:18 --:--:-- 1582k\r",
      "100  229M    0  229M    0     0  1181k      0 --:--:--  0:03:18 --:--:-- 2108k\r",
      "100  232M    0  232M    0     0  1190k      0 --:--:--  0:03:19 --:--:-- 2408k\r",
      "100  235M    0  235M    0     0  1202k      0 --:--:--  0:03:20 --:--:-- 2539k\r",
      "100  239M    0  239M    0     0  1214k      0 --:--:--  0:03:21 --:--:-- 2713k\r",
      "100  242M    0  242M    0     0  1222k      0 --:--:--  0:03:22 --:--:-- 3472k\r",
      "100  245M    0  245M    0     0  1233k      0 --:--:--  0:03:23 --:--:-- 3309k\r",
      "100  247M    0  247M    0     0  1236k      0 --:--:--  0:03:24 --:--:-- 3058k\r",
      "100  250M    0  250M    0     0  1245k      0 --:--:--  0:03:25 --:--:-- 2988k\r",
      "100  252M    0  252M    0     0  1252k      0 --:--:--  0:03:26 --:--:-- 2803k\r",
      "100  255M    0  255M    0     0  1256k      0 --:--:--  0:03:27 --:--:-- 2627k\r",
      "100  257M    0  257M    0     0  1262k      0 --:--:--  0:03:28 --:--:-- 2418k\r",
      "100  258M    0  258M    0     0  1260k      0 --:--:--  0:03:29 --:--:-- 2217k\r",
      "100  259M    0  259M    0     0  1261k      0 --:--:--  0:03:30 --:--:-- 1891k\r",
      "100  261M    0  261M    0     0  1262k      0 --:--:--  0:03:31 --:--:-- 1683k\r",
      "100  262M    0  262M    0     0  1261k      0 --:--:--  0:03:32 --:--:-- 1476k\r",
      "100  263M    0  263M    0     0  1263k      0 --:--:--  0:03:33 --:--:-- 1321k\r",
      "100  265M    0  265M    0     0  1264k      0 --:--:--  0:03:34 --:--:-- 1470k\r",
      "100  266M    0  266M    0     0  1264k      0 --:--:--  0:03:35 --:--:-- 1407k\r",
      "100  267M    0  267M    0     0  1264k      0 --:--:--  0:03:36 --:--:-- 1320k\r",
      "100  268M    0  268M    0     0  1263k      0 --:--:--  0:03:37 --:--:-- 1324k\r",
      "100  269M    0  269M    0     0  1263k      0 --:--:--  0:03:38 --:--:-- 1261k\r",
      "100  270M    0  270M    0     0  1261k      0 --:--:--  0:03:39 --:--:-- 1130k\r",
      "100  271M    0  271M    0     0  1259k      0 --:--:--  0:03:40 --:--:-- 1035k\r",
      "100  272M    0  272M    0     0  1256k      0 --:--:--  0:03:41 --:--:--  933k\r",
      "100  273M    0  273M    0     0  1255k      0 --:--:--  0:03:42 --:--:--  931k\r",
      "100  274M    0  274M    0     0  1255k      0 --:--:--  0:03:43 --:--:--  926k\r",
      "100  275M    0  275M    0     0  1256k      0 --:--:--  0:03:44 --:--:-- 1001k\r",
      "100  276M    0  276M    0     0  1255k      0 --:--:--  0:03:45 --:--:-- 1070k\r",
      "100  277M    0  277M    0     0  1251k      0 --:--:--  0:03:46 --:--:-- 1045k\r",
      "100  277M    0  277M    0     0  1247k      0 --:--:--  0:03:47 --:--:--  857k\r",
      "100  278M    0  278M    0     0  1246k      0 --:--:--  0:03:48 --:--:--  831k\r",
      "100  279M    0  279M    0     0  1246k      0 --:--:--  0:03:49 --:--:--  794k\r",
      "100  280M    0  280M    0     0  1246k      0 --:--:--  0:03:50 --:--:--  854k\r",
      "100  282M    0  282M    0     0  1246k      0 --:--:--  0:03:51 --:--:-- 1023k\r",
      "100  283M    0  283M    0     0  1247k      0 --:--:--  0:03:52 --:--:-- 1238k\r",
      "100  284M    0  284M    0     0  1247k      0 --:--:--  0:03:53 --:--:-- 1291k\r",
      "100  286M    0  286M    0     0  1248k      0 --:--:--  0:03:54 --:--:-- 1378k\r",
      "100  288M    0  288M    0     0  1253k      0 --:--:--  0:03:55 --:--:-- 1556k\r",
      "100  289M    0  289M    0     0  1252k      0 --:--:--  0:03:56 --:--:-- 1523k\r",
      "100  290M    0  290M    0     0  1245k      0 --:--:--  0:03:58 --:--:-- 1196k\r",
      "100  290M    0  290M    0     0  1242k      0 --:--:--  0:03:59 --:--:-- 1019k\r",
      "100  291M    0  291M    0     0  1246k      0 --:--:--  0:03:59 --:--:-- 1131k\r",
      "100  293M    0  293M    0     0  1247k      0 --:--:--  0:04:00 --:--:-- 1004k\r",
      "100  295M    0  295M    0     0  1250k      0 --:--:--  0:04:01 --:--:-- 1141k\r",
      "100  297M    0  297M    0     0  1255k      0 --:--:--  0:04:02 --:--:-- 1822k\r",
      "100  299M    0  299M    0     0  1259k      0 --:--:--  0:04:03 --:--:-- 2201k\r",
      "100  302M    0  302M    0     0  1264k      0 --:--:--  0:04:04 --:--:-- 2128k\r",
      "100  304M    0  304M    0     0  1267k      0 --:--:--  0:04:05 --:--:-- 2229k\r",
      "100  305M    0  305M    0     0  1266k      0 --:--:--  0:04:06 --:--:-- 2058k\r",
      "100  305M    0  305M    0     0  1263k      0 --:--:--  0:04:07 --:--:-- 1662k\r",
      "100  307M    0  307M    0     0  1264k      0 --:--:--  0:04:08 --:--:-- 1514k\r",
      "100  308M    0  308M    0     0  1266k      0 --:--:--  0:04:09 --:--:-- 1373k\r",
      "100  311M    0  311M    0     0  1271k      0 --:--:--  0:04:10 --:--:-- 1464k\r",
      "100  313M    0  313M    0     0  1273k      0 --:--:--  0:04:11 --:--:-- 1585k\r",
      "100  314M    0  314M    0     0  1272k      0 --:--:--  0:04:12 --:--:-- 1709k\r",
      "100  316M    0  316M    0     0  1278k      0 --:--:--  0:04:13 --:--:-- 1972k\r",
      "100  319M    0  319M    0     0  1283k      0 --:--:--  0:04:14 --:--:-- 2140k\r",
      "100  321M    0  321M    0     0  1287k      0 --:--:--  0:04:15 --:--:-- 2056k\r",
      "100  322M    0  322M    0     0  1287k      0 --:--:--  0:04:16 --:--:-- 1994k\r",
      "100  324M    0  324M    0     0  1290k      0 --:--:--  0:04:17 --:--:-- 2203k\r",
      "100  327M    0  327M    0     0  1294k      0 --:--:--  0:04:18 --:--:-- 2087k\r",
      "100  329M    0  329M    0     0  1297k      0 --:--:--  0:04:19 --:--:-- 2006k\r",
      "100  332M    0  332M    0     0  1305k      0 --:--:--  0:04:20 --:--:-- 2235k\r",
      "100  334M    0  334M    0     0  1308k      0 --:--:--  0:04:21 --:--:-- 2388k\r",
      "100  335M    0  335M    0     0  1306k      0 --:--:--  0:04:22 --:--:-- 2151k\r",
      "100  336M    0  336M    0     0  1306k      0 --:--:--  0:04:23 --:--:-- 1974k\r",
      "100  338M    0  338M    0     0  1307k      0 --:--:--  0:04:24 --:--:-- 1817k\r",
      "100  339M    0  339M    0     0  1308k      0 --:--:--  0:04:25 --:--:-- 1451k\r",
      "100  340M    0  340M    0     0  1307k      0 --:--:--  0:04:26 --:--:-- 1287k\r",
      "100  341M    0  341M    0     0  1305k      0 --:--:--  0:04:27 --:--:-- 1235k\r",
      "100  342M    0  342M    0     0  1303k      0 --:--:--  0:04:28 --:--:-- 1140k\r",
      "100  343M    0  343M    0     0  1303k      0 --:--:--  0:04:29 --:--:-- 1091k\r",
      "100  344M    0  344M    0     0  1303k      0 --:--:--  0:04:30 --:--:-- 1035k\r",
      "100  345M    0  345M    0     0  1302k      0 --:--:--  0:04:31 --:--:-- 1012k\r",
      "100  346M    0  346M    0     0  1301k      0 --:--:--  0:04:32 --:--:-- 1060k\r",
      "100  347M    0  347M    0     0  1300k      0 --:--:--  0:04:33 --:--:-- 1123k\r",
      "100  349M    0  349M    0     0  1300k      0 --:--:--  0:04:34 --:--:-- 1158k\r",
      "100  350M    0  350M    0     0  1300k      0 --:--:--  0:04:35 --:--:-- 1158k\r",
      "100  351M    0  351M    0     0  1301k      0 --:--:--  0:04:36 --:--:-- 1227k\r",
      "100  353M    0  353M    0     0  1304k      0 --:--:--  0:04:37 --:--:-- 1482k\r",
      "100  355M    0  355M    0     0  1305k      0 --:--:--  0:04:38 --:--:-- 1588k\r",
      "100  356M    0  356M    0     0  1305k      0 --:--:--  0:04:39 --:--:-- 1555k\r",
      "100  357M    0  357M    0     0  1305k      0 --:--:--  0:04:40 --:--:-- 1576k\r",
      "100  359M    0  359M    0     0  1305k      0 --:--:--  0:04:41 --:--:-- 1523k\r",
      "100  360M    0  360M    0     0  1305k      0 --:--:--  0:04:42 --:--:-- 1369k\r",
      "100  361M    0  361M    0     0  1305k      0 --:--:--  0:04:43 --:--:-- 1318k\r",
      "100  363M    0  363M    0     0  1306k      0 --:--:--  0:04:44 --:--:-- 1371k\r",
      "100  364M    0  364M    0     0  1306k      0 --:--:--  0:04:45 --:--:-- 1376k\r",
      "100  365M    0  365M    0     0  1306k      0 --:--:--  0:04:46 --:--:-- 1386k\r",
      "100  366M    0  366M    0     0  1305k      0 --:--:--  0:04:47 --:--:-- 1302k\r",
      "100  367M    0  367M    0     0  1303k      0 --:--:--  0:04:48 --:--:-- 1141k\r",
      "100  368M    0  368M    0     0  1300k      0 --:--:--  0:04:49 --:--:--  973k\r",
      "100  368M    0  368M    0     0  1299k      0 --:--:--  0:04:50 --:--:--  887k\r",
      "100  370M    0  370M    0     0  1299k      0 --:--:--  0:04:51 --:--:--  913k\r",
      "100  371M    0  371M    0     0  1299k      0 --:--:--  0:04:52 --:--:--  932k\r",
      "100  372M    0  372M    0     0  1297k      0 --:--:--  0:04:53 --:--:--  988k\r",
      "100  373M    0  373M    0     0  1297k      0 --:--:--  0:04:54 --:--:-- 1084k\r",
      "100  374M    0  374M    0     0  1296k      0 --:--:--  0:04:55 --:--:-- 1125k\r",
      "100  375M    0  375M    0     0  1296k      0 --:--:--  0:04:56 --:--:-- 1072k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   408    0   408    0     0    399      0 --:--:--  0:00:01 --:--:--   399\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\r",
      "100 16128  100 16128    0     0   6845      0  0:00:02  0:00:02 --:--:--  6845\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "100   408    0   408    0     0    222      0 --:--:--  0:00:01 --:--:--   222\r",
      "100   408    0   408    0     0    222      0 --:--:--  0:00:01 --:--:--   222\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "\r",
      "100 60396    0 60396    0     0  17948      0 --:--:--  0:00:03 --:--:-- 17948\r",
      "100 1963k    0 1963k    0     0   448k      0 --:--:--  0:00:04 --:--:-- 1878k\r",
      "100 5435k    0 5435k    0     0  1013k      0 --:--:--  0:00:05 --:--:-- 2692k\r",
      "100 9227k    0 9227k    0     0  1440k      0 --:--:--  0:00:06 --:--:-- 3013k\r",
      "100 12.4M    0 12.4M    0     0  1728k      0 --:--:--  0:00:07 --:--:-- 3168k\r",
      "100 14.5M    0 14.5M    0     0  1776k      0 --:--:--  0:00:08 --:--:-- 2960k\r",
      "100 16.8M    0 16.8M    0     0  1841k      0 --:--:--  0:00:09 --:--:-- 3065k\r",
      "100 19.5M    0 19.5M    0     0  1928k      0 --:--:--  0:00:10 --:--:-- 2903k\r",
      "100 21.9M    0 21.9M    0     0  1972k      0 --:--:--  0:00:11 --:--:-- 2659k\r",
      "100 22.8M    0 22.8M    0     0  1895k      0 --:--:--  0:00:12 --:--:-- 2141k\r",
      "100 25.0M    0 25.0M    0     0  1919k      0 --:--:--  0:00:13 --:--:-- 2157k\r",
      "100 27.3M    0 27.3M    0     0  1946k      0 --:--:--  0:00:14 --:--:-- 2143k\r",
      "100 29.5M    0 29.5M    0     0  1964k      0 --:--:--  0:00:15 --:--:-- 2039k\r",
      "100 30.7M    0 30.7M    0     0  1922k      0 --:--:--  0:00:16 --:--:-- 1807k\r",
      "100 32.9M    0 32.9M    0     0  1941k      0 --:--:--  0:00:17 --:--:-- 2053k\r",
      "100 35.5M    0 35.5M    0     0  1980k      0 --:--:--  0:00:18 --:--:-- 2144k\r",
      "100 36.9M    0 36.9M    0     0  1954k      0 --:--:--  0:00:19 --:--:-- 1978k\r",
      "100 38.7M    0 38.7M    0     0  1948k      0 --:--:--  0:00:20 --:--:-- 1898k\r",
      "100 40.9M    0 40.9M    0     0  1964k      0 --:--:--  0:00:21 --:--:-- 2101k\r",
      "100 43.1M    0 43.1M    0     0  1974k      0 --:--:--  0:00:22 --:--:-- 2090k\r",
      "100 44.9M    0 44.9M    0     0  1969k      0 --:--:--  0:00:23 --:--:-- 1929k\r",
      "100 46.9M    0 46.9M    0     0  1972k      0 --:--:--  0:00:24 --:--:-- 2042k\r",
      "100 49.2M    0 49.2M    0     0  1988k      0 --:--:--  0:00:25 --:--:-- 2153k\r",
      "100 51.2M    0 51.2M    0     0  1991k      0 --:--:--  0:00:26 --:--:-- 2105k\r",
      "100 52.7M    0 52.7M    0     0  1972k      0 --:--:--  0:00:27 --:--:-- 1964k\r",
      "100 54.6M    0 54.6M    0     0  1973k      0 --:--:--  0:00:28 --:--:-- 1993k\r",
      "100 56.8M    0 56.8M    0     0  1981k      0 --:--:--  0:00:29 --:--:-- 2024k\r",
      "100 58.5M    0 58.5M    0     0  1975k      0 --:--:--  0:00:30 --:--:-- 1909k\r",
      "100 60.4M    0 60.4M    0     0  1973k      0 --:--:--  0:00:31 --:--:-- 1878k\r",
      "100 62.6M    0 62.6M    0     0  1982k      0 --:--:--  0:00:32 --:--:-- 2036k\r",
      "100 65.5M    0 65.5M    0     0  2011k      0 --:--:--  0:00:33 --:--:-- 2227k\r",
      "100 68.5M    0 68.5M    0     0  2043k      0 --:--:--  0:00:34 --:--:-- 2406k\r",
      "100 70.6M    0 70.6M    0     0  2047k      0 --:--:--  0:00:35 --:--:-- 2480k\r",
      "100 74.0M    0 74.0M    0     0  2085k      0 --:--:--  0:00:36 --:--:-- 2790k\r",
      "100 77.5M    0 77.5M    0     0  2126k      0 --:--:--  0:00:37 --:--:-- 3057k\r",
      "100 80.8M    0 80.8M    0     0  2156k      0 --:--:--  0:00:38 --:--:-- 3119k\r",
      "100 84.0M    0 84.0M    0     0  2187k      0 --:--:--  0:00:39 --:--:-- 3174k\r",
      "100 87.3M    0 87.3M    0     0  2217k      0 --:--:--  0:00:40 --:--:-- 3417k\r",
      "100 89.5M    0 89.5M    0     0  2216k      0 --:--:--  0:00:41 --:--:-- 3167k\r",
      "100 90.8M    0 90.8M    0     0  2196k      0 --:--:--  0:00:42 --:--:-- 2721k\r",
      "100 92.6M    0 92.6M    0     0  2188k      0 --:--:--  0:00:43 --:--:-- 2436k\r",
      "100 93.7M    0 93.7M    0     0  2191k      0 --:--:--  0:00:43 --:--:-- 2234k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   408    0   408    0     0    545      0 --:--:-- --:--:-- --:--:--   544\r",
      "100   408    0   408    0     0    545      0 --:--:-- --:--:-- --:--:--   544\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "\r",
      "100  4128  100  4128    0     0   2169      0  0:00:01  0:00:01 --:--:--  2169\r",
      "100  4128  100  4128    0     0   2169      0  0:00:01  0:00:01 --:--:--     0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "fileid=\"1cUaIEd9-MLJHFGjLz5QziNvfBtYygplX\"\n",
    "filename=\"./data/x_train.npy\"\n",
    "curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=${fileid}\" > /dev/null\n",
    "curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${fileid}\" -o ${filename}\n",
    "\n",
    "fileid=\"1hv24Ufiio9rBeSqgnNoM3dr5sVGwOmBy\"\n",
    "filename=\"./data/y_train.npy\"\n",
    "curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=${fileid}\" > /dev/null\n",
    "curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${fileid}\" -o ${filename}\n",
    "\n",
    "fileid=\"1AH9lKHT5P2oQLz8SGMRPWs_M9wIM2ZRH\"\n",
    "filename=\"./data/x_test.npy\"\n",
    "curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=${fileid}\" > /dev/null\n",
    "curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${fileid}\" -o ${filename}\n",
    "\n",
    "fileid=\"1i4_azocSDuU3TcDf3OSHO1vF0D5-xMU6\"\n",
    "filename=\"./data/y_test.npy\"\n",
    "curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=${fileid}\" > /dev/null\n",
    "curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${fileid}\" -o ${filename}\n",
    "\n",
    "rm ./cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (4000, 64, 64, 3)\n",
      "y_train shape:  (4000, 1)\n",
      "x_test shape:  (1000, 64, 64, 3)\n",
      "y_test shape:  (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to import the Eurosat data\n",
    "def load_eurosat_data():\n",
    "    data_dir = 'data/'\n",
    "    x_train = np.load(os.path.join(data_dir, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(data_dir, 'y_train.npy'))\n",
    "    x_test  = np.load(os.path.join(data_dir, 'x_test.npy'))\n",
    "    y_test  = np.load(os.path.join(data_dir, 'y_test.npy'))\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_eurosat_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now construct a model to fit to the data. Using the Sequential API, build your model according to the following specifications:\n",
    "\n",
    "* The model should use the input_shape in the function argument to set the input size in the first layer.\n",
    "* The first layer should be a Conv2D layer with 16 filters, a 3x3 kernel size, a ReLU activation function and 'SAME' padding. Name this layer 'conv_1'.\n",
    "* The second layer should also be a Conv2D layer with 8 filters, a 3x3 kernel size, a ReLU activation function and 'SAME' padding. Name this layer 'conv_2'.\n",
    "* The third layer should be a MaxPooling2D layer with a pooling window size of 8x8. Name this layer 'pool_1'.\n",
    "* The fourth layer should be a Flatten layer, named 'flatten'.\n",
    "* The fifth layer should be a Dense layer with 32 units, a ReLU activation. Name this layer 'dense_1'.\n",
    "* The sixth and final layer should be a Dense layer with 10 units and softmax activation. Name this layer 'dense_2'.\n",
    "\n",
    "In total, the network should have 6 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, \\\n",
    "    MaxPooling2D\n",
    "\n",
    "def get_new_model(input_shape):\n",
    "    \"\"\"\n",
    "    This function should build a Sequential model according to the above specification. Ensure the \n",
    "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
    "    function argument.\n",
    "    Your function should also compile the model with the Adam optimiser, sparse categorical cross\n",
    "    entropy loss function, and a single accuracy metric.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential([\n",
    "      Conv2D(16, kernel_size=(3, 3), activation='relu', padding='SAME', \n",
    "             input_shape=input_shape, name='conv_1'),\n",
    "      Conv2D(8, kernel_size=(3, 3), activation='relu', padding='SAME', \n",
    "             name='conv_2'),\n",
    "      MaxPooling2D(pool_size=(8, 8), name='pool_1'),\n",
    "      Flatten(name='flatten'),\n",
    "      Dense(units=32, activation='relu', name='dense_1'),\n",
    "      Dense(units=10, activation='softmax', name='dense_2')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to create the model\n",
    "\n",
    "model = get_new_model(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to define a function to evaluate a model's test accuracy\n",
    "\n",
    "def get_test_accuracy(model, x_test, y_test):\n",
    "    \"\"\"Test model classification accuracy\"\"\"\n",
    "    test_loss, test_acc = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "    print('accuracy: {acc:0.3f}'.format(acc=test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 64, 64, 8)         1160      \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 18,354\n",
      "Trainable params: 18,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 0.096\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary and calculate its initialised test accuracy\n",
    "\n",
    "model.summary()\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create checkpoints to save model during training, with a criterion\n",
    "\n",
    "You will now create three callbacks:\n",
    "- `checkpoint_every_epoch`: checkpoint that saves the model weights every epoch during training\n",
    "- `checkpoint_best_only`: checkpoint that saves only the weights with the highest validation accuracy. Use the testing data as the validation data.\n",
    "- `early_stopping`: early stopping object that ends training if the validation accuracy has not improved in 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def get_checkpoint_every_epoch():\n",
    "    \"\"\"\n",
    "    This function should return a ModelCheckpoint object that:\n",
    "    - saves the weights only at the end of every epoch\n",
    "    - saves into a directory called 'checkpoints_every_epoch' inside the current working directory\n",
    "    - generates filenames in that directory like 'checkpoint_XXX' where\n",
    "      XXX is the epoch number formatted to have three digits, e.g. 001, 002, 003, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    checkpoint_every_epoch_path = \\\n",
    "        \"checkpoints_every_epoch/checkpoint_{epoch:03d}\"\n",
    "\n",
    "    return ModelCheckpoint(filepath=checkpoint_every_epoch_path, \n",
    "        frequency='epoch', save_weights_only=True, verbose=1)\n",
    "\n",
    "def get_checkpoint_best_only():\n",
    "    \"\"\"\n",
    "    This function should return a ModelCheckpoint object that:\n",
    "    - saves only the weights that generate the highest validation (testing) accuracy\n",
    "    - saves into a directory called 'checkpoints_best_only' inside the current working directory\n",
    "    - generates a file called 'checkpoints_best_only/checkpoint' \n",
    "    \"\"\"\n",
    "    \n",
    "    checkpoint_best_path = \"checkpoints_best_only/checkpoint\"\n",
    "\n",
    "    return ModelCheckpoint(filepath=checkpoint_best_path, \n",
    "        save_weights_only=True, save_freq='epoch', \n",
    "        monitor='val_accuracy', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def get_early_stopping():\n",
    "    \"\"\"\n",
    "    This function should return an EarlyStopping callback that stops training when\n",
    "    the validation (testing) accuracy has not improved in the last 3 epochs.\n",
    "    HINT: use the EarlyStopping callback with the correct 'monitor' and 'patience'\n",
    "    \"\"\"\n",
    "    \n",
    "    return EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to create the callbacks\n",
    "\n",
    "checkpoint_every_epoch = get_checkpoint_every_epoch()\n",
    "checkpoint_best_only = get_checkpoint_best_only()\n",
    "early_stopping = get_early_stopping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model using the callbacks\n",
    "\n",
    "Now, you will train the model using the three callbacks you created. If you created the callbacks correctly, three things should happen:\n",
    "- At the end of every epoch, the model weights are saved into a directory called `checkpoints_every_epoch`\n",
    "- At the end of every epoch, the model weights are saved into a directory called `checkpoints_best_only` **only** if those weights lead to the highest test accuracy\n",
    "- Training stops when the testing accuracy has not improved in three epochs.\n",
    "\n",
    "You should then have two directories:\n",
    "- A directory called `checkpoints_every_epoch` containing filenames that include `checkpoint_001`, `checkpoint_002`, etc with the `001`, `002` corresponding to the epoch\n",
    "- A directory called `checkpoints_best_only` containing filenames that include `checkpoint`, which contain only the weights leading to the highest testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/125 [===========================>..] - ETA: 0s - loss: 2.0166 - accuracy: 0.2278\n",
      "Epoch 00001: saving model to checkpoints_every_epoch/checkpoint_001\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.36100, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.9920 - accuracy: 0.2375 - val_loss: 1.6965 - val_accuracy: 0.3610\n",
      "Epoch 2/50\n",
      "120/125 [===========================>..] - ETA: 0s - loss: 1.5134 - accuracy: 0.4255\n",
      "Epoch 00002: saving model to checkpoints_every_epoch/checkpoint_002\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.36100 to 0.42600, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.5128 - accuracy: 0.4252 - val_loss: 1.4261 - val_accuracy: 0.4260\n",
      "Epoch 3/50\n",
      "119/125 [===========================>..] - ETA: 0s - loss: 1.3327 - accuracy: 0.4987\n",
      "Epoch 00003: saving model to checkpoints_every_epoch/checkpoint_003\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.42600 to 0.46000, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.3339 - accuracy: 0.4983 - val_loss: 1.4207 - val_accuracy: 0.4600\n",
      "Epoch 4/50\n",
      "120/125 [===========================>..] - ETA: 0s - loss: 1.2788 - accuracy: 0.5070\n",
      "Epoch 00004: saving model to checkpoints_every_epoch/checkpoint_004\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.46000 to 0.47700, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.2756 - accuracy: 0.5058 - val_loss: 1.3094 - val_accuracy: 0.4770\n",
      "Epoch 5/50\n",
      "123/125 [============================>.] - ETA: 0s - loss: 1.1994 - accuracy: 0.5429\n",
      "Epoch 00005: saving model to checkpoints_every_epoch/checkpoint_005\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.47700 to 0.52200, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.2014 - accuracy: 0.5420 - val_loss: 1.2327 - val_accuracy: 0.5220\n",
      "Epoch 6/50\n",
      "123/125 [============================>.] - ETA: 0s - loss: 1.1301 - accuracy: 0.5783\n",
      "Epoch 00006: saving model to checkpoints_every_epoch/checkpoint_006\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.52200 to 0.54700, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.1280 - accuracy: 0.5785 - val_loss: 1.1790 - val_accuracy: 0.5470\n",
      "Epoch 7/50\n",
      "122/125 [============================>.] - ETA: 0s - loss: 1.1021 - accuracy: 0.5809\n",
      "Epoch 00007: saving model to checkpoints_every_epoch/checkpoint_007\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.54700\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.1015 - accuracy: 0.5800 - val_loss: 1.3596 - val_accuracy: 0.4760\n",
      "Epoch 8/50\n",
      "120/125 [===========================>..] - ETA: 0s - loss: 1.0478 - accuracy: 0.6112\n",
      "Epoch 00008: saving model to checkpoints_every_epoch/checkpoint_008\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.54700 to 0.57500, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.0440 - accuracy: 0.6112 - val_loss: 1.1435 - val_accuracy: 0.5750\n",
      "Epoch 9/50\n",
      "124/125 [============================>.] - ETA: 0s - loss: 0.9895 - accuracy: 0.6464\n",
      "Epoch 00009: saving model to checkpoints_every_epoch/checkpoint_009\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.57500 to 0.62300, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9880 - accuracy: 0.6470 - val_loss: 1.0692 - val_accuracy: 0.6230\n",
      "Epoch 10/50\n",
      "121/125 [============================>.] - ETA: 0s - loss: 0.9513 - accuracy: 0.6568\n",
      "Epoch 00010: saving model to checkpoints_every_epoch/checkpoint_010\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.62300\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9476 - accuracy: 0.6593 - val_loss: 1.1489 - val_accuracy: 0.5570\n",
      "Epoch 11/50\n",
      "122/125 [============================>.] - ETA: 0s - loss: 0.9189 - accuracy: 0.6634\n",
      "Epoch 00011: saving model to checkpoints_every_epoch/checkpoint_011\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.62300 to 0.62700, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9174 - accuracy: 0.6647 - val_loss: 1.0417 - val_accuracy: 0.6270\n",
      "Epoch 12/50\n",
      "117/125 [===========================>..] - ETA: 0s - loss: 0.8941 - accuracy: 0.6736\n",
      "Epoch 00012: saving model to checkpoints_every_epoch/checkpoint_012\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.62700\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8881 - accuracy: 0.6765 - val_loss: 1.0211 - val_accuracy: 0.6080\n",
      "Epoch 13/50\n",
      "119/125 [===========================>..] - ETA: 0s - loss: 0.8694 - accuracy: 0.6828\n",
      "Epoch 00013: saving model to checkpoints_every_epoch/checkpoint_013\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.62700 to 0.66400, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8703 - accuracy: 0.6827 - val_loss: 0.9317 - val_accuracy: 0.6640\n",
      "Epoch 14/50\n",
      "121/125 [============================>.] - ETA: 0s - loss: 0.8332 - accuracy: 0.6921\n",
      "Epoch 00014: saving model to checkpoints_every_epoch/checkpoint_014\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66400\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8332 - accuracy: 0.6925 - val_loss: 0.9617 - val_accuracy: 0.6580\n",
      "Epoch 15/50\n",
      "122/125 [============================>.] - ETA: 0s - loss: 0.8040 - accuracy: 0.7108\n",
      "Epoch 00015: saving model to checkpoints_every_epoch/checkpoint_015\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.66400 to 0.68900, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8047 - accuracy: 0.7105 - val_loss: 0.8852 - val_accuracy: 0.6890\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.7820 - accuracy: 0.7168\n",
      "Epoch 00016: saving model to checkpoints_every_epoch/checkpoint_016\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.68900 to 0.69600, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7820 - accuracy: 0.7168 - val_loss: 0.8885 - val_accuracy: 0.6960\n",
      "Epoch 17/50\n",
      "121/125 [============================>.] - ETA: 0s - loss: 0.7603 - accuracy: 0.7296\n",
      "Epoch 00017: saving model to checkpoints_every_epoch/checkpoint_017\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.69600 to 0.69800, saving model to checkpoints_best_only/checkpoint\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7650 - accuracy: 0.7295 - val_loss: 0.8625 - val_accuracy: 0.6980\n",
      "Epoch 18/50\n",
      "123/125 [============================>.] - ETA: 0s - loss: 0.7608 - accuracy: 0.7213\n",
      "Epoch 00018: saving model to checkpoints_every_epoch/checkpoint_018\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.69800\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7612 - accuracy: 0.7218 - val_loss: 0.8751 - val_accuracy: 0.6810\n",
      "Epoch 19/50\n",
      "122/125 [============================>.] - ETA: 0s - loss: 0.7529 - accuracy: 0.7218\n",
      "Epoch 00019: saving model to checkpoints_every_epoch/checkpoint_019\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.69800\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7569 - accuracy: 0.7203 - val_loss: 0.9500 - val_accuracy: 0.6580\n",
      "Epoch 20/50\n",
      "121/125 [============================>.] - ETA: 0s - loss: 0.7625 - accuracy: 0.7224\n",
      "Epoch 00020: saving model to checkpoints_every_epoch/checkpoint_020\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.69800\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7588 - accuracy: 0.7243 - val_loss: 0.8589 - val_accuracy: 0.6780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f543077a520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model using the callbacks you just created\n",
    "\n",
    "callbacks = [checkpoint_every_epoch, checkpoint_best_only, \n",
    "    early_stopping]\n",
    "model.fit(x_train, y_train, epochs=50, \n",
    "    validation_data=(x_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new instance of model and load on both sets of weights\n",
    "\n",
    "Now you will use the weights you just saved in a fresh model. You should create two functions, both of which take a freshly instantiated model instance:\n",
    "- `model_last_epoch` should contain the weights from the latest saved epoch\n",
    "- `model_best_epoch` should contain the weights from the saved epoch with the highest testing accuracy\n",
    "\n",
    "_Hint: use the_ `tf.train.latest_checkpoint` _function to get the filename of the latest saved checkpoint file. Check the docs_ [_here_](https://www.tensorflow.org/api_docs/python/tf/train/latest_checkpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import latest_checkpoint\n",
    "\n",
    "def get_model_last_epoch(model):\n",
    "    \"\"\"\n",
    "    This function should create a new instance of the CNN you created earlier,\n",
    "    load on the weights from the last training epoch, and return this model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.load_weights(latest_checkpoint(\"./checkpoints_every_epoch\"))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def get_model_best_epoch(model):\n",
    "    \"\"\"\n",
    "    This function should create a new instance of the CNN you created earlier, load \n",
    "    on the weights leading to the highest validation accuracy, and return this model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.load_weights(latest_checkpoint(\"./checkpoints_best_only\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with last epoch weights:\n",
      "accuracy: 0.678\n",
      "\n",
      "Model with best epoch weights:\n",
      "accuracy: 0.698\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to create two models: one with the weights from the last training\n",
    "# epoch, and one with the weights leading to the highest validation (testing) accuracy.\n",
    "# Verify that the second has a higher validation (testing) accuarcy.\n",
    "\n",
    "model_last_epoch = get_model_last_epoch(get_new_model(x_train[0].shape))\n",
    "model_best_epoch = get_model_best_epoch(get_new_model(x_train[0].shape))\n",
    "print('Model with last epoch weights:')\n",
    "get_test_accuracy(model_last_epoch, x_test, y_test)\n",
    "print('')\n",
    "print('Model with best epoch weights:')\n",
    "get_test_accuracy(model_best_epoch, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load, from scratch, a model trained on the EuroSat dataset.\n",
    "\n",
    "In your workspace, you will find another model trained on the `EuroSAT` dataset in `.h5` format. This model is trained on a larger subset of the EuroSAT dataset and has a more complex architecture. The path to the model is `models/EuroSatNet.h5`. See how its testing accuracy compares to your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def get_model_eurosatnet():\n",
    "    \"\"\"\n",
    "    This function should return the pretrained EuroSatNet.h5 model.\n",
    "    \"\"\"\n",
    "    model = load_model('models/EuroSatNet.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 64, 64, 16)        6416      \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 32, 32, 16)        6416      \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 16, 16, 16)        6416      \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 8, 8, 16)          6416      \n",
      "_________________________________________________________________\n",
      "pool_4 (MaxPooling2D)        (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 41,626\n",
      "Trainable params: 41,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 0.810\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to print a summary of the EuroSatNet model, \n",
    "# along with its validation accuracy.\n",
    "\n",
    "model_eurosatnet = get_model_eurosatnet()\n",
    "model_eurosatnet.summary()\n",
    "get_test_accuracy(model_eurosatnet, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear directory\n",
    "\n",
    "! rm -rf checkpoints_every_epoch checkpoints_best_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations for completing this programming assignment! You're now ready to move on to the capstone project for this course."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "tensor-flow-2-1",
   "graded_item_id": "JaRY0",
   "launcher_item_id": "mJ8fg"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
