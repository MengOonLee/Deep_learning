{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow2/Tutorial/Getting_started_TensorFlow2/Validation_regularisation_callbacks/Additional_callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pip_install.sh\n",
    "#!/bin/bash\n",
    "pip install -qU pip wheel\n",
    "pip install -qU numpy pandas matplotlib\n",
    "pip install -qU scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9DFNFxJwCH0"
   },
   "source": [
    "# Additional callbacks\n",
    "\n",
    "In this reading we'll be looking at more of the inbuilt callbacks available in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjnJnGbfwCIB"
   },
   "source": [
    "We will again be using the sklearn diabetes dataset to demonstrate these callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes_dataset = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the input and target variables\n",
    "data = diabetes_dataset['data']\n",
    "targets = diabetes_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "03DwAe5kwCIG"
   },
   "outputs": [],
   "source": [
    "# Split the data set into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(\n",
    "    data, targets, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZtbeQqjwCIN"
   },
   "source": [
    "Let's also build a simple model to fit the data with our callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y4MhPW5SwCIO",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 128)               1408      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,049\n",
      "Trainable params: 18,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_data.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='mse', \n",
    "    optimizer='adam', \n",
    "    metrics=['mse', 'mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now onto the callbacks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfAFcKFnwCIc"
   },
   "source": [
    "## Learning rate scheduler\n",
    "\n",
    "**usage:** `tf.keras.callbacks.LearningRateScheduler(schedule, verbose=0)`\n",
    "\n",
    "The learning rate scheduler that we implemented in the previous reading as a custom callback is also available as a built in callback.\n",
    "\n",
    "As in our custom callback, the `LearningRateScheduler` in Keras takes a function `schedule` as an argument.\n",
    "\n",
    "This function `schedule` should take two arguments:\n",
    "* The current epoch (as an integer), and\n",
    "* The current learning rate,\n",
    "\n",
    "and return new learning rate for that epoch.\n",
    "\n",
    "The `LearningRateScheduler` also has an optional `verbose` argument, which prints information about the learning rate if it is set to 1.\n",
    "\n",
    "Let's see a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fyXegaJXwCId"
   },
   "outputs": [],
   "source": [
    "# Define the learning rate schedule function\n",
    "def lr_function(epoch, lr):\n",
    "    if epoch%2==0:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr + epoch/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "kvYEirzBwCIl",
    "outputId": "97a3b64f-4ad6-4516-8ee7-2acee02ec33a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0020000000474974513.\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0020000000949949026.\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.005000000094994903.\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999888241292.\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.01699999977648258.\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.016999999061226845.\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.025999999061226846.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_function, \n",
    "    verbose=1)], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycWqpHW7wCIq"
   },
   "source": [
    "You can also use lambda functions to define your schedule given an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "y6hcazbDwCIr",
    "outputId": "41986aa7-b18e-4bfc-b3b6-3c434c4945d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.3333333333333333.\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.125.\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.07692307692307693.\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.05555555555555555.\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.043478260869565216.\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.03571428571428571.\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.030303030303030304.\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.02631578947368421.\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.023255813953488372.\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020833333333333332.\n"
     ]
    }
   ],
   "source": [
    "# Train the model with a difference schedule\n",
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.LearningRateScheduler(\n",
    "        lambda x:1/(3+5*x), verbose=1)], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tahfUFdzwCIw"
   },
   "source": [
    "## CSV logger\n",
    "**Usage** `tf.keras.callbacks.CSVLogger(filename, separator=',', append=False)`\n",
    "\n",
    "This callback streams the results from each epoch into a CSV file. The first line of the CSV file will be the name of pieces of information recorded on each subsequent line, begining with the epoch and loss value. The values of metrics at the end of each epoch will also be recorded.\n",
    "\n",
    "The only compulsory argument is the `filename` for the log to be streamed to. This could also be a filepath.\n",
    "\n",
    "You can also specify the `separator` to be used between entries on each line.\n",
    "\n",
    "The `append` argument allows you the option to append your results to an existing file with the same name. This can be particularly useful if you are continuing training.\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "V--11Bz2wCIx",
    "outputId": "dce9d6c3-6d33-4ca7-ef43-beb03b58a308"
   },
   "outputs": [],
   "source": [
    "# Train the model with a CSV logger\n",
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(\"results.csv\")], \n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the information in the CSV file we have created using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29458.884766</td>\n",
       "      <td>152.967911</td>\n",
       "      <td>29458.884766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29221.042969</td>\n",
       "      <td>152.201889</td>\n",
       "      <td>29221.042969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28222.654297</td>\n",
       "      <td>148.932053</td>\n",
       "      <td>28222.654297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24383.640625</td>\n",
       "      <td>135.874237</td>\n",
       "      <td>24383.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14581.215820</td>\n",
       "      <td>96.422249</td>\n",
       "      <td>14581.215820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5343.618164</td>\n",
       "      <td>60.887852</td>\n",
       "      <td>5343.618164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4209.692383</td>\n",
       "      <td>55.968082</td>\n",
       "      <td>4209.692383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3906.019287</td>\n",
       "      <td>51.729214</td>\n",
       "      <td>3906.019287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3479.827148</td>\n",
       "      <td>49.646446</td>\n",
       "      <td>3479.827148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3447.219482</td>\n",
       "      <td>49.453140</td>\n",
       "      <td>3447.219482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               loss         mae           mse\n",
       "epoch                                        \n",
       "0      29458.884766  152.967911  29458.884766\n",
       "1      29221.042969  152.201889  29221.042969\n",
       "2      28222.654297  148.932053  28222.654297\n",
       "3      24383.640625  135.874237  24383.640625\n",
       "4      14581.215820   96.422249  14581.215820\n",
       "5       5343.618164   60.887852   5343.618164\n",
       "6       4209.692383   55.968082   4209.692383\n",
       "7       3906.019287   51.729214   3906.019287\n",
       "8       3479.827148   49.646446   3479.827148\n",
       "9       3447.219482   49.453140   3447.219482"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"results.csv\", index_col='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOGsn_NEwCI8"
   },
   "source": [
    "## Lambda callbacks\n",
    "**Usage** `tf.keras.callbacks.LambdaCallback(                \n",
    "        on_epoch_begin=None, on_epoch_end=None,                 \n",
    "        on_batch_begin=None, on_batch_end=None,                 \n",
    "        on_train_begin=None, on_train_end=None)`\n",
    "    \n",
    "Lambda callbacks are used to quickly define simple custom callbacks with the use of lambda functions.\n",
    "\n",
    "Each of the functions require some positional arguments.\n",
    "* `on_epoch_begin` and `on_epoch_end` expect two arguments: `epoch` and `logs`,\n",
    "* `on_batch_begin` and `on_batch_end` expect two arguments: `batch` and `logs` and \n",
    "* `on_train_begin` and `on_train_end` expect one argument: `logs`.\n",
    "\n",
    "Let's see an example of this in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the epoch number at the beginning of each epoch\n",
    "epoch_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch, logs: print('Starting Epoch {}!'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the loss at the end of each batch\n",
    "batch_loss_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_batch_end=lambda batch, logs: print('\\n After batch {}, the loss is {:7.2f}.'\n",
    "    .format(batch, logs['loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inform that training is finished\n",
    "train_finish_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_train_end=lambda logs: print('Training finished'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WLKprRjOwCI9",
    "outputId": "2e9027ae-3e6a-4032-e64e-d4be5bfb0402",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1!\n",
      "\n",
      " After batch 0, the loss is 31990.04.\n",
      "\n",
      " After batch 1, the loss is 29193.77.\n",
      "\n",
      " After batch 2, the loss is 28590.04.\n",
      "\n",
      " After batch 3, the loss is 29491.18.\n",
      "Starting Epoch 2!\n",
      "\n",
      " After batch 0, the loss is 26294.07.\n",
      "\n",
      " After batch 1, the loss is 28054.60.\n",
      "\n",
      " After batch 2, the loss is 27926.27.\n",
      "\n",
      " After batch 3, the loss is 29474.50.\n",
      "Starting Epoch 3!\n",
      "\n",
      " After batch 0, the loss is 26292.26.\n",
      "\n",
      " After batch 1, the loss is 26909.12.\n",
      "\n",
      " After batch 2, the loss is 28392.31.\n",
      "\n",
      " After batch 3, the loss is 29450.07.\n",
      "Starting Epoch 4!\n",
      "\n",
      " After batch 0, the loss is 32103.93.\n",
      "\n",
      " After batch 1, the loss is 30001.99.\n",
      "\n",
      " After batch 2, the loss is 28186.84.\n",
      "\n",
      " After batch 3, the loss is 29413.72.\n",
      "Starting Epoch 5!\n",
      "\n",
      " After batch 0, the loss is 29753.60.\n",
      "\n",
      " After batch 1, the loss is 28771.25.\n",
      "\n",
      " After batch 2, the loss is 29399.19.\n",
      "\n",
      " After batch 3, the loss is 29359.00.\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the lambda callbacks\n",
    "history = model.fit(train_data, train_targets, epochs=5, batch_size=100,\n",
    "    callbacks=[epoch_callback, batch_loss_callback, train_finish_callback], \n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E7YyPzhwCJD"
   },
   "source": [
    "## Reduce learning rate on plateau\n",
    "**Usage** `tf.keras.callbacks.ReduceLROnPlateau(                        \n",
    "            monitor='val_loss', factor=0.1, patience=10, verbose=0,            \n",
    "            mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)` \n",
    "    \n",
    "The `ReduceLROnPlateau` callback allows reduction of the learning rate when a metric has stopped improving.\n",
    "The arguments are similar to those used in the `EarlyStopping` callback.\n",
    "* The argument `monitor` is used to specify which metric to base the callback on.\n",
    "* The `factor` is the factor by which the learning rate decreases i.e., new_lr=factor*old_lr.\n",
    "* The `patience` is the number of epochs where there is no improvement on the monitored metric before the learning rate is reduced.\n",
    "* The `verbose` argument will produce progress messages when set to 1.\n",
    "* The `mode` determines whether the learning rate will decrease when the monitored quantity stops increasing (`max`) or decreasing (`min`). The `auto` setting causes the callback to infer the mode from the monitored quantity.\n",
    "* The `min_delta` is the smallest change in the monitored quantity to be deemed an improvement.\n",
    "* The `cooldown` is the number of epochs to wait after the learning rate is changed before the callback resumes normal operation.\n",
    "* The `min_lr` is a lower bound on the learning rate that the callback will produce.\n",
    "\n",
    "Let's examine a final example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "RdSREQ9YwCJD",
    "outputId": "51e4cc89-09d2-4826-89e3-6cc0ec0ed0a5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model with the ReduceLROnPlateau callback\n",
    "history = model.fit(train_data, train_targets, epochs=100, batch_size=100,\n",
    "    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', factor=0.2, verbose=1)], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaiFe1KowCJK"
   },
   "source": [
    "### Further reading and resources\n",
    "\n",
    "* https://keras.io/callbacks/\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CSVLogger\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LambdaCallback"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Additional_callbacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
