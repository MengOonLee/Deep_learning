{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow2/Customise/SubclassCustom/Subclassing_custom_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-63p30Tr1qo"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1vsuhMJr1qp"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygIPKcLbr1qt"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EROzuT5cr1q5"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI0B1hY4r1q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaba5bd2-0d3b-49ac-ccf7-d93df50e7ffb"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "\n",
        "# Build the model\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dense_1 = tf.keras.layers.Dense(units=64,\n",
        "            activation=tf.keras.activations.relu)\n",
        "        self.dense_2 = tf.keras.layers.Dense(units=10,\n",
        "            activation=tf.keras.activations.relu)\n",
        "        self.dense_3 = tf.keras.layers.Dense(units=num_classes,\n",
        "            activation=tf.keras.activations.softmax)\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=0.4)\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x1 = self.dense_1(inputs)\n",
        "        x2 = self.dense_2(inputs)\n",
        "        concat = tf.keras.layers.Concatenate()([x1, x2])\n",
        "        concat = self.dropout(concat, training=training)\n",
        "        return self.dense_3(concat)\n",
        "\n",
        "# Print the model summary\n",
        "my_model = MyModel(num_classes=5, name=\"my_model\")\n",
        "my_model(inputs=tf.random.normal(shape=(1, 10)))\n",
        "my_model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               multiple                  704       \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  375       \n",
            "                                                                 \n",
            " dropout (Dropout)           multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1189 (4.64 KB)\n",
            "Trainable params: 1189 (4.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9r-6CSr1rG"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIPDZjqpr1rO"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2GIDoAhr1rb",
        "outputId": "26bf535a-18e7-4367-aa73-89739aa7b947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "\n",
        "# Create a custom layer to accumulate means of output values\n",
        "class MyLayerMean(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        # Specify trainable weights\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "            initializer=tf.keras.initializers.Zeros())\n",
        "        self.sum_activation = tf.Variable(\n",
        "            initial_value=tf.zeros(shape=(units,)),\n",
        "            trainable=False)\n",
        "        self.number_call = tf.Variable(initial_value=0,\n",
        "            trainable=False)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "            initializer=tf.keras.initializers.RandomNormal())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        activations = tf.linalg.matmul(a=inputs, b=self.w) + self.b\n",
        "        self.sum_activation.assign_add(delta=tf.math.reduce_sum(\n",
        "            input_tensor=activations, axis=0))\n",
        "        self.number_call.assign_add(delta=inputs.shape[0])\n",
        "        return activations, self.sum_activation \\\n",
        "            / tf.cast(x=self.number_call, dtype=tf.float32)\n",
        "\n",
        "dense_layer = MyLayerMean(units=3)\n",
        "\n",
        "# Test the layer\n",
        "x = tf.ones(shape=(2, 5))\n",
        "y, activation_means = dense_layer(inputs=x)\n",
        "print(\"trainable weights:\", len(dense_layer.trainable_weights))\n",
        "print(\"non-trainable weights:\", len(dense_layer.non_trainable_weights))\n",
        "print(f\"activation_means: {activation_means.numpy()}\")\n",
        "print(f\"weights: {dense_layer.weights}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable weights: 2\n",
            "non-trainable weights: 2\n",
            "activation_means: [ 0.01885552 -0.07703885 -0.2915517 ]\n",
            "weights: [<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, <tf.Variable 'my_layer_mean/Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[-0.02358919, -0.01442928, -0.0221293 ],\n",
            "       [ 0.06809177, -0.09231842, -0.06502789],\n",
            "       [ 0.01064425,  0.0060349 , -0.04163619],\n",
            "       [-0.0387267 ,  0.03659106, -0.10442163],\n",
            "       [ 0.00243539, -0.01291711, -0.05833671]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([ 0.03771103, -0.1540777 , -0.5831034 ], dtype=float32)>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=2>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5s7lbEqr1rq"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwLPdbngr1rq",
        "outputId": "9c17db7d-8bde-47b8-96d5-df3371a4d460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "\n",
        "# Build the model using custom layers with the model subclassing API\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, units_1, units_2, units_3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units=units_1)\n",
        "        self.dropout_1 = MyDropout(rate=0.5)\n",
        "        self.layer_2 = MyLayer(units=units_2)\n",
        "        self.dropout_2 = MyDropout(rate=0.5)\n",
        "        self.layer_3 = MyLayer(units=units_3)\n",
        "        self.softmax = tf.keras.layers.Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs=inputs)\n",
        "        x = tf.nn.relu(features=x)\n",
        "        x = self.dropout_1(inputs=x)\n",
        "        x = self.layer_2(inputs=x)\n",
        "        x = tf.nn.relu(features=x)\n",
        "        x = self.dropout_2(inputs=x)\n",
        "        x = self.layer_3(inputs=x)\n",
        "        return tf.nn.softmax(logits=x)\n",
        "\n",
        "# Create a custom layer\n",
        "class MyLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "      super().__init__(**kwargs)\n",
        "      self.units = units\n",
        "      self.b = self.add_weight(shape=(units,),\n",
        "          initializer=tf.keras.initializers.Zeros())\n",
        "\n",
        "  def build(self, input_shape):\n",
        "      self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "          initializer=tf.keras.initializers.RandomNormal())\n",
        "\n",
        "  def call(self, inputs):\n",
        "      return tf.linalg.matmul(a=inputs, b=self.w) + self.b\n",
        "\n",
        "# Create a Dropout layer as a custom layer\n",
        "class MyDropout(tf.keras.layers.Layer):\n",
        "    def __init__(self, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(x=inputs, rate=self.rate)\n",
        "\n",
        "# Instantiate a model object\n",
        "my_model = MyModel(units_1=64, units_2=64, units_3=46, name=\"my_model\")\n",
        "print(my_model(inputs=tf.random.normal(shape=(1, 10000))))\n",
        "my_model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.03964709 0.01326959 0.02763752 0.01076229 0.00946367 0.03262108\n",
            "  0.01824417 0.00908988 0.06717899 0.0657099  0.01522712 0.01349179\n",
            "  0.02473041 0.0173228  0.01864109 0.03071251 0.01356732 0.01164669\n",
            "  0.03300928 0.00993308 0.01679035 0.01374916 0.06827163 0.02038475\n",
            "  0.00887606 0.01661217 0.01125773 0.0161174  0.02482517 0.01127255\n",
            "  0.00647558 0.01062837 0.01034763 0.00456736 0.05896313 0.00457546\n",
            "  0.00695589 0.01401419 0.02193612 0.03387663 0.02122179 0.0189374\n",
            "  0.02321724 0.03404636 0.02700518 0.01316846]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_layer (MyLayer)          multiple                  640064    \n",
            "                                                                 \n",
            " my_dropout (MyDropout)      multiple                  0         \n",
            "                                                                 \n",
            " my_layer_1 (MyLayer)        multiple                  4160      \n",
            "                                                                 \n",
            " my_dropout_1 (MyDropout)    multiple                  0         \n",
            "                                                                 \n",
            " my_layer_2 (MyLayer)        multiple                  2990      \n",
            "                                                                 \n",
            " softmax (Softmax)           multiple                  0 (unused)\n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647214 (2.47 MB)\n",
            "Trainable params: 647214 (2.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoDMC-nBr1r0"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwERUPc0uuWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0f2b9a-1e8b-4dcf-fd91-0e144f9073de"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant([0, 1, 2, 3], dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    y = tf.reduce_sum(x**2)\n",
        "    z = tf.math.sin(y)\n",
        "    dz_dy, dz_dx = tape.gradient(z, [y, x])\n",
        "\n",
        "print(dz_dy, \"\\n\", dz_dx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.13673723, shape=(), dtype=float32) \n",
            " tf.Tensor([0.         0.27347445 0.5469489  0.82042336], shape=(4,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75LxDUqLr1r2"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bQg5xCkr1r6"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pIJI0SOr1r7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "46cd5239-7f09-44e3-c972-1cb228140f07"
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caGxCoiDr1r-"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMFHCei3r1r_"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmmi5htRr1sD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aebf040-94f3-4394-bd37-8658159b0262"
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.m = self.add_weight(shape=(1, ),\n",
        "            initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(1, ),\n",
        "            initializer='zeros')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.m*inputs+self.b\n",
        "\n",
        "linear_regression = LinearLayer()\n",
        "print(linear_regression(x_train))\n",
        "print(linear_regression.weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.12323282 0.07531414 0.11656261 0.00264567 0.11461526 0.10679599\n",
            " 0.13254023 0.02995865 0.04930686 0.08388655 0.10453741 0.03422887\n",
            " 0.04383827 0.0795267  0.01734196 0.12852322 0.02318839 0.1116631\n",
            " 0.04650161 0.10129283], shape=(20,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.13454984], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1-MZ8jcr1sH"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7B8dgW8r1sI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e8aa8c-bfcc-4fac-c675-cd30e01252fa"
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 6.3086176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQi4BqY1r1sL"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBJiU2Lfr1sM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b7ffb9-b5cd-4d3d-dff9-6e1855115368"
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for i in range(steps):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = linear_regression(x_train)\n",
        "        loss = SquaredError(predictions, y_train)\n",
        "\n",
        "    gradients = tape.gradient(loss,\n",
        "        linear_regression.trainable_variables)\n",
        "\n",
        "    linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
        "    linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
        "\n",
        "    print(\"Step %d, Loss %f\" % (i, loss.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 6.308618\n",
            "Step 1, Loss 4.728327\n",
            "Step 2, Loss 3.544499\n",
            "Step 3, Loss 2.657668\n",
            "Step 4, Loss 1.993321\n",
            "Step 5, Loss 1.495641\n",
            "Step 6, Loss 1.122815\n",
            "Step 7, Loss 0.843518\n",
            "Step 8, Loss 0.634286\n",
            "Step 9, Loss 0.477540\n",
            "Step 10, Loss 0.360113\n",
            "Step 11, Loss 0.272140\n",
            "Step 12, Loss 0.206232\n",
            "Step 13, Loss 0.156853\n",
            "Step 14, Loss 0.119856\n",
            "Step 15, Loss 0.092135\n",
            "Step 16, Loss 0.071363\n",
            "Step 17, Loss 0.055797\n",
            "Step 18, Loss 0.044130\n",
            "Step 19, Loss 0.035384\n",
            "Step 20, Loss 0.028827\n",
            "Step 21, Loss 0.023910\n",
            "Step 22, Loss 0.020220\n",
            "Step 23, Loss 0.017451\n",
            "Step 24, Loss 0.015372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqGl9-nkr1sT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "83f780a1-b544-4687-a239-18697b6813d9"
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression,\n",
        "    linear_regression.m*x_linear_regression+linear_regression.b,\n",
        "    'r.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[1.2046332]\n",
            "b:2,  trained b:[1.813714]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfVr4Cg9r1sZ"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqrs9WVHva51"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "\n",
        "my_model = MyModel()\n",
        "\n",
        "# def loss(y_hat, y):\n",
        "#     return tf.reduce_mean(tf.square(y_hat - y))\n",
        "\n",
        "loss = MeanSquaredError()\n",
        "optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
        "\n",
        "epoch_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    batch_losses = []\n",
        "\n",
        "    for inputs, outputs in training_datasets:\n",
        "        with tf.GradientTape() as tape:\n",
        "            current_loss = loss(my_model(inputs), outputs)\n",
        "            grads = tape.gradient(current_loss,\n",
        "                my_model.trainable_variables)\n",
        "\n",
        "        batch_losses.append(current_loss)\n",
        "        optimizer.apply_gradients(zip(grads,\n",
        "                my_model.trainable_variables))\n",
        "\n",
        "    epoch_losses.append(np.mean(batch_losses))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cSC_6x4r1sa"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atSr-agDr1se"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6sQMvNwr1se"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGI4u73Pr1si"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "    def __init__(self, units):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "            initializer='random_normal', name='kernel')\n",
        "        self.b = self.add_weight(shape=(self.units, ),\n",
        "            initializer='zeros', name='bias')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forwared pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnvnpKBOwIgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1923cb-f740-4197-da99-bd6ce4f617ec"
      },
      "source": [
        "# Instantiate the model object\n",
        "\n",
        "model = MyModel(64, 64, 46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.01118078 0.00525199 0.01426291 0.0171649  0.08723421 0.01139885\n",
            "  0.06960411 0.02470182 0.00222714 0.01687782 0.01972567 0.01846476\n",
            "  0.00697674 0.00295534 0.00404295 0.00515138 0.00912909 0.00837477\n",
            "  0.00412501 0.0043536  0.00394924 0.00212455 0.02400699 0.01216442\n",
            "  0.00101893 0.1369465  0.04031    0.00086793 0.01442129 0.06603812\n",
            "  0.0169418  0.0387236  0.00194447 0.0075574  0.00940368 0.02568662\n",
            "  0.05426175 0.00081219 0.00996874 0.00710806 0.01574037 0.00388332\n",
            "  0.00102361 0.00258901 0.149769   0.00953453]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_8 (MyLayer)         multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout_4 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_9 (MyLayer)         multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_5 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_10 (MyLayer)        multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_3 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCz9DmHfr1sl"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwPBT8tXr1sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e1da7d-93b0-43c2-cd04-8e320691cf15"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = \\\n",
        "    reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper',\n",
        "    'housing','money-supply','coffee','sugar','trade','reserves','ship',\n",
        "    'cotton','carcass','crude','nat-gas','cpi','money-fx','interest','gnp',\n",
        "    'meal-feed','alum','oilseed','gold','tin','strategic-metal','livestock',\n",
        "    'retail','ipi','iron-steel','rubber','heat','jobs','lei','bop','zinc',\n",
        "    'orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vTNh384r1sz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb5311a2-285b-4987-ace9-18b9a0efec90"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkoNiPVxr1s3"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrvnPh8Lr1s3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65f53ac-725f-479d-f4ea-9d7dad3e6559"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value)\n",
        "    in word_to_index.items()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usc3Zk9nr1s6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d004cf-a768-4fd7-a7a0-cb757dccb61a"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?')\n",
        "    for i in train_data[0]])\n",
        "print(text_news)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD1Wq-0rr1s8"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCOXWQ3Xr1s9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4614b9-ba7e-4d5f-f189-b9176ad318b7"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (8982, 10000)\n",
            "Shape of x_test: (2246, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D8Hqo95r1tB"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyaEBVH8r1tB"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k))\n",
        "        for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbSqeUASr1tD"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY4zdAHvr1tE"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value,\n",
        "        model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsBCnNF8r1tG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdabf38b-2f1a-464a-987f-86e163be7b9f"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "# Keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "    # Training loop\n",
        "    for x, y in train_dataset:\n",
        "        # Optimize the model\n",
        "        loss_value, grads = grad(model, x, y, weight_decay)\n",
        "        optimizer.apply_gradients(zip(grads,\n",
        "            model.trainable_variables))\n",
        "\n",
        "        # Compute current loss\n",
        "        epoch_loss_avg(loss_value)\n",
        "        # Compare predicted label to actual label\n",
        "        epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "    # End epoch\n",
        "    train_loss_results.append(epoch_loss_avg.result())\n",
        "    train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(\n",
        "        epoch, epoch_loss_avg.result(), epoch_accuracy.result()))\n",
        "\n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer my_model_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "Epoch 000: Loss: 3.309, Accuracy: 48.497%\n",
            "Epoch 001: Loss: 1.911, Accuracy: 61.434%\n",
            "Epoch 002: Loss: 1.820, Accuracy: 65.809%\n",
            "Epoch 003: Loss: 1.792, Accuracy: 67.836%\n",
            "Epoch 004: Loss: 1.776, Accuracy: 68.893%\n",
            "Epoch 005: Loss: 1.751, Accuracy: 69.439%\n",
            "Epoch 006: Loss: 1.724, Accuracy: 69.684%\n",
            "Epoch 007: Loss: 1.717, Accuracy: 70.296%\n",
            "Epoch 008: Loss: 1.721, Accuracy: 70.085%\n",
            "Epoch 009: Loss: 1.712, Accuracy: 70.574%\n",
            "Duration :46.495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5hySkber1tJ"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52pcdYPSr1tL"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vIi120-r1tN"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Gg0UJTr1tR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cea6a3f-1786-4023-a435-38fc59be80fc"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)\n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)\n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.815\n",
            "Test accuracy: 67.275%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYeZct8Pr1tT"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsigZE0Vr1tV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "af069ed5-697b-489a-8d9c-00c92a085ac4"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fwfdX1or1tY"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOln-j2mr1tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c343ac4-595f-452a-dce8-afa6d533f596"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: earn\n",
            "     Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Cn-8F4r1ta"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTWqQM-0xo6N"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "my_model = MyModel()\n",
        "loss = MeanSquaredError()\n",
        "optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
        "\n",
        "@tf.function\n",
        "def get_loss_and_grads(inputs, outputs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = loss(my_model(inputs), outputs)\n",
        "        grads = tape.gradient(current_loss,\n",
        "            my_model.trainable_variables)\n",
        "    return current_loss, grads\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, outputs in training_dataset:\n",
        "        current_loss, grads = get_loss_and_grads(inputs, outputs)\n",
        "        optimizer.apply_gradients(zip(grads,\n",
        "            my_model.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_uI0tTjr1tb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UASAY4rgr1tc"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uklVa1fYyAtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe09b621-06d0-4f88-a27a-0bb8efce1f5e"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "    def __init__(self, units):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "            initializer='random_normal', name='kernel')\n",
        "        self.b = self.add_weight(shape=(self.units, ),\n",
        "            initializer='zeros', name='bias')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forwared pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)\n",
        "\n",
        "# Initialize a new model\n",
        "\n",
        "model = MyModel(64, 64, 46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.01971349 0.0128117  0.01281833 0.01806461 0.02666165 0.01890017\n",
            "  0.03147139 0.00964301 0.01691275 0.0289935  0.01865787 0.02058025\n",
            "  0.01223264 0.02273865 0.00546703 0.02286484 0.0150119  0.01376886\n",
            "  0.00987451 0.02398963 0.02541195 0.04581803 0.01048673 0.03026778\n",
            "  0.01948599 0.0414695  0.04172915 0.01312426 0.01371575 0.02741901\n",
            "  0.01029295 0.02534913 0.04003927 0.01897906 0.01478054 0.0186229\n",
            "  0.01920601 0.01592984 0.02524102 0.0527998  0.0153937  0.015901\n",
            "  0.03862935 0.03238732 0.01285238 0.01349079]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_11 (MyLayer)        multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout_6 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_12 (MyLayer)        multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_7 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_13 (MyLayer)        multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_4 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5dTotyVyI_j"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_7J8dSVyGes"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = \\\n",
        "    reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat',\n",
        "    'copper','housing','money-supply','coffee','sugar','trade',\n",
        "    'reserves','ship','cotton','carcass','crude','nat-gas','cpi',\n",
        "    'money-fx','interest','gnp','meal-feed','alum','oilseed','gold',\n",
        "    'tin','strategic-metal','livestock','retail','ipi','iron-steel',\n",
        "    'rubber','heat','jobs','lei','bop','zinc','orange','pet-chem',\n",
        "    'dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev3yXr8byTIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ecf0210-e350-4d60-c3f9-546f8ae23091"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aGUS42tyXti"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wopzgI7vyWgx"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value)\n",
        "    in word_to_index.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huB2kCnpyhsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d55f9e2-b3f9-4c22-8edb-3ed1401cf64b"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?')\n",
        "    for i in train_data[0]])\n",
        "print(text_news)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPcPqYdpylHe"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvq4ooZ2yoqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0afa64-24c4-4c76-96be-9124256ccd6d"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (8982, 10000)\n",
            "Shape of x_test: (2246, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9bbZtOUyth3"
      },
      "source": [
        "#### Define the loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBIF4-15y9RO"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k))\n",
        "        for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__RuGE21r1tf"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77hBTup9r1tg"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n",
        "@tf.function\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value,\n",
        "        model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhN1yZC8r1tj"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUMMtppxr1tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb48fc6-9ecb-4633-8dfb-9f74812f66d8"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "# Keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "    # Training loop\n",
        "    for x, y in train_dataset:\n",
        "        # Optimize the model\n",
        "        loss_value, grads = grad(model, x, y, weight_decay)\n",
        "        optimizer.apply_gradients(zip(grads,\n",
        "            model.trainable_variables))\n",
        "\n",
        "        # Compute current loss\n",
        "        epoch_loss_avg(loss_value)\n",
        "        # Compare predicted label to actual label\n",
        "        epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "    # End epoch\n",
        "    train_loss_results.append(epoch_loss_avg.result())\n",
        "    train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(\n",
        "        epoch, epoch_loss_avg.result(), epoch_accuracy.result()))\n",
        "\n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer my_model_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "Epoch 000: Loss: 3.318, Accuracy: 47.874%\n",
            "Epoch 001: Loss: 1.906, Accuracy: 61.701%\n",
            "Epoch 002: Loss: 1.816, Accuracy: 65.442%\n",
            "Epoch 003: Loss: 1.771, Accuracy: 67.491%\n",
            "Epoch 004: Loss: 1.754, Accuracy: 68.470%\n",
            "Epoch 005: Loss: 1.737, Accuracy: 69.472%\n",
            "Epoch 006: Loss: 1.730, Accuracy: 69.695%\n",
            "Epoch 007: Loss: 1.705, Accuracy: 70.196%\n",
            "Epoch 008: Loss: 1.705, Accuracy: 70.463%\n",
            "Epoch 009: Loss: 1.706, Accuracy: 70.385%\n",
            "Duration :29.538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwfclNSur1tl"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLZqDt-r1tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7206f428-a2b0-4b28-ffcf-a38a38754ca4"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n",
        "print(tf.autograph.to_code(grad.python_function))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def tf__grad(model, inputs, targets, wd):\n",
            "    with ag__.FunctionScope('grad', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        with ag__.ld(tf).GradientTape() as tape:\n",
            "            loss_value = ag__.converted_call(ag__.ld(loss), (ag__.ld(model), ag__.ld(inputs), ag__.ld(targets), ag__.ld(wd)), None, fscope)\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = (ag__.ld(loss_value), ag__.converted_call(ag__.ld(tape).gradient, (ag__.ld(loss_value), ag__.ld(model).trainable_variables), None, fscope))\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}