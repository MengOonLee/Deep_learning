{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/TensorFlow2/Customise/SubclassCustom/Subclassing_custom_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-63p30Tr1qo"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1vsuhMJr1qp"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygIPKcLbr1qt"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EROzuT5cr1q5"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI0B1hY4r1q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca8b8d5-55c3-4c8a-c345-2e464fc5a4dc"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Build the model\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dense_1 = tf.keras.layers.Dense(units=64,\n",
        "            activation=tf.keras.activations.relu)\n",
        "        self.dense_2 = tf.keras.layers.Dense(units=10,\n",
        "            activation=tf.keras.activations.relu)\n",
        "        self.dense_3 = tf.keras.layers.Dense(units=num_classes,\n",
        "            activation=tf.keras.activations.softmax)\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=0.4)\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x1 = self.dense_1(inputs=inputs)\n",
        "        x2 = self.dense_2(inputs=inputs)\n",
        "        concat = tf.keras.layers.Concatenate()([x1, x2])\n",
        "        concat = self.dropout(inputs=concat, training=training)\n",
        "        return self.dense_3(inputs=concat)\n",
        "\n",
        "# Print the model summary\n",
        "my_model = MyModel(num_classes=5, name=\"my_model\")\n",
        "my_model(inputs=tf.random.normal(shape=(1, 10)))\n",
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               multiple                  704       \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  375       \n",
            "                                                                 \n",
            " dropout (Dropout)           multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1189 (4.64 KB)\n",
            "Trainable params: 1189 (4.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9r-6CSr1rG"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIPDZjqpr1rO"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2GIDoAhr1rb",
        "outputId": "26bf535a-18e7-4367-aa73-89739aa7b947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Create a custom layer to accumulate means of output values\n",
        "class MyLayerMean(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        # Specify trainable weights\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "            initializer=tf.keras.initializers.Zeros())\n",
        "        self.sum_activation = tf.Variable(\n",
        "            initial_value=tf.zeros(shape=(units,)),\n",
        "            trainable=False)\n",
        "        self.number_call = tf.Variable(initial_value=0,\n",
        "            trainable=False)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "            initializer=tf.keras.initializers.RandomNormal())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        activations = tf.linalg.matmul(a=inputs, b=self.w) + self.b\n",
        "        self.sum_activation.assign_add(delta=tf.math.reduce_sum(\n",
        "            input_tensor=activations, axis=0))\n",
        "        self.number_call.assign_add(delta=inputs.shape[0])\n",
        "        return activations, self.sum_activation / tf.cast(\n",
        "                x=self.number_call, dtype=tf.float32)\n",
        "\n",
        "dense_layer = MyLayerMean(units=3)\n",
        "\n",
        "# Test the layer\n",
        "x = tf.ones(shape=(2, 5))\n",
        "y, activation_means = dense_layer(inputs=x)\n",
        "print(\"trainable weights:\", len(dense_layer.trainable_weights))\n",
        "print(\"non-trainable weights:\", len(dense_layer.non_trainable_weights))\n",
        "print(f\"activation_means: {activation_means.numpy()}\")\n",
        "print(f\"weights: {dense_layer.weights}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable weights: 2\n",
            "non-trainable weights: 2\n",
            "activation_means: [ 0.01885552 -0.07703885 -0.2915517 ]\n",
            "weights: [<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, <tf.Variable 'my_layer_mean/Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[-0.02358919, -0.01442928, -0.0221293 ],\n",
            "       [ 0.06809177, -0.09231842, -0.06502789],\n",
            "       [ 0.01064425,  0.0060349 , -0.04163619],\n",
            "       [-0.0387267 ,  0.03659106, -0.10442163],\n",
            "       [ 0.00243539, -0.01291711, -0.05833671]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([ 0.03771103, -0.1540777 , -0.5831034 ], dtype=float32)>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=2>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5s7lbEqr1rq"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwLPdbngr1rq",
        "outputId": "fff07307-4d9a-49c6-dbc0-010a7c0197f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Build the model using custom layers with the model subclassing API\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, units_1, units_2, units_3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units=units_1)\n",
        "        self.layer_2 = MyLayer(units=units_2)\n",
        "        self.layer_3 = MyLayer(units=units_3)\n",
        "        self.dropout = MyDropout(rate=0.5)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs=inputs)\n",
        "        x = tf.nn.relu(features=x)\n",
        "        x = self.dropout(inputs=x)\n",
        "        x = self.layer_2(inputs=x)\n",
        "        x = tf.nn.relu(features=x)\n",
        "        x = self.dropout(inputs=x)\n",
        "        x = self.layer_3(inputs=x)\n",
        "        return tf.nn.softmax(logits=x)\n",
        "\n",
        "# Create a custom layer\n",
        "class MyLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "      super().__init__(**kwargs)\n",
        "      self.units = units\n",
        "      self.b = self.add_weight(shape=(units,),\n",
        "          initializer=tf.keras.initializers.Zeros())\n",
        "\n",
        "  def build(self, input_shape):\n",
        "      self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "          initializer=tf.keras.initializers.RandomNormal())\n",
        "\n",
        "  def call(self, inputs):\n",
        "      return tf.linalg.matmul(a=inputs, b=self.w) + self.b\n",
        "\n",
        "# Create a Dropout layer as a custom layer\n",
        "class MyDropout(tf.keras.layers.Layer):\n",
        "    def __init__(self, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(x=inputs, rate=self.rate)\n",
        "\n",
        "# Instantiate a model object\n",
        "my_model = MyModel(units_1=64, units_2=64, units_3=46, name=\"my_model\")\n",
        "print(my_model(inputs=tf.random.normal(shape=(1, 10000))))\n",
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.03964711 0.01326958 0.02763753 0.01076229 0.00946367 0.03262109\n",
            "  0.01824417 0.00908988 0.06717901 0.06570987 0.01522713 0.01349179\n",
            "  0.02473041 0.01732281 0.01864108 0.03071251 0.01356731 0.01164669\n",
            "  0.03300926 0.00993308 0.01679034 0.01374915 0.06827164 0.02038475\n",
            "  0.00887607 0.01661218 0.01125773 0.01611739 0.02482517 0.01127254\n",
            "  0.00647558 0.01062837 0.01034763 0.00456736 0.05896316 0.00457546\n",
            "  0.00695589 0.01401417 0.02193612 0.03387661 0.02122178 0.0189374\n",
            "  0.02321725 0.03404637 0.02700517 0.01316846]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_layer (MyLayer)          multiple                  640064    \n",
            "                                                                 \n",
            " my_layer_1 (MyLayer)        multiple                  4160      \n",
            "                                                                 \n",
            " my_layer_2 (MyLayer)        multiple                  2990      \n",
            "                                                                 \n",
            " my_dropout (MyDropout)      multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647214 (2.47 MB)\n",
            "Trainable params: 647214 (2.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoDMC-nBr1r0"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwERUPc0uuWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55152fc-bccd-4dfc-9ac2-da58d2b2c63b"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "x = tf.constant(value=[0, 1, 2, 3], dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(tensor=x)\n",
        "    y = tf.math.reduce_sum(input_tensor=x**2)\n",
        "    z = tf.math.sin(x=y)\n",
        "    dz_dy, dz_dx = tape.gradient(target=z, sources=[y, x])\n",
        "\n",
        "print(f\"dz_dy: {dz_dy}\")\n",
        "print(f\"dz_dx: {dz_dx}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dz_dy: 0.13673722743988037\n",
            "dz_dx: [0.         0.27347445 0.5469489  0.82042336]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQi4BqY1r1sL"
      },
      "source": [
        "#### Build, train and plot the linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBJiU2Lfr1sM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "a9419441-4186-475d-9ed9-62807e8e9287"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create data from a noise contaminated linear model\n",
        "@tf.function\n",
        "def MakeNoisyData(w, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = w * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "w, b = 1, 2\n",
        "x_train, y_train = MakeNoisyData(w=w, b=b)\n",
        "\n",
        "# Build a custom layer for the linear regression model\n",
        "class LinearLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.w = self.add_weight(shape=(units,),\n",
        "            initializer=tf.keras.initializers.RandomNormal())\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "            initializer=tf.keras.initializers.Zeros())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.w*inputs + self.b\n",
        "\n",
        "linear_regression = LinearLayer(units=1)\n",
        "\n",
        "# Define the mean squared error loss function & gradients\n",
        "@tf.function\n",
        "def get_loss_and_grads(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = linear_regression(inputs=x_train)\n",
        "        loss = tf.math.reduce_mean(\n",
        "            input_tensor=tf.math.square(x=(y_pred-y)))\n",
        "        grads = tape.gradient(target=loss,\n",
        "            sources=linear_regression.trainable_variables)\n",
        "    return loss, grads\n",
        "\n",
        "# Implement a gradient descent training loop for the linear regression model\n",
        "lr = 0.05\n",
        "steps = 25\n",
        "\n",
        "losses = []\n",
        "for i in range(steps):\n",
        "    loss, grad = get_loss_and_grads(x=x_train, y=y_train)\n",
        "    losses.append(loss.numpy())\n",
        "    linear_regression.w.assign_sub(delta=lr*grad[0])\n",
        "    linear_regression.b.assign_sub(delta=lr*grad[1])\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.title(label=\"Losses\")\n",
        "plt.plot(losses)\n",
        "plt.show()\n",
        "\n",
        "# Plot the learned regression model\n",
        "print(\"w:{},  trained w:{}\".format(w, linear_regression.w.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b, linear_regression.b.numpy()))\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.title(label=\"Learned regression\")\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "x_linear_regression = np.linspace(start=min(x_train),\n",
        "    stop=max(x_train), num=50)\n",
        "y_linear_regression = linear_regression.w * x_linear_regression \\\n",
        "    + linear_regression.b\n",
        "plt.plot(x_linear_regression, y_linear_regression, 'r.')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w:1,  trained w:[0.8987737]\n",
            "b:2,  trained b:[1.9256457]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfVr4Cg9r1sZ"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCz9DmHfr1sl"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwPBT8tXr1sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfdd907b-4dbf-43cd-bee7-0c16e430d376"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Load the dataset\n",
        "(train_data, train_labels), (test_data, test_labels) = \\\n",
        "    tf.keras.datasets.reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = [\n",
        "    'cocoa', 'grain', 'veg-oil', 'earn', 'acq', 'wheat', 'copper', 'housing',\n",
        "    'money-supply', 'coffee', 'sugar', 'trade', 'reserves', 'ship', 'cotton',\n",
        "    'carcass', 'crude', 'nat-gas', 'cpi', 'money-fx', 'interest', 'gnp',\n",
        "    'meal-feed', 'alum', 'oilseed', 'gold', 'tin', 'strategic-metal',\n",
        "    'livestock', 'retail', 'ipi', 'iron-steel', 'rubber', 'heat', 'jobs',\n",
        "    'lei', 'bop', 'zinc', 'orange', 'pet-chem', 'dlr', 'gas', 'silver',\n",
        "    'wpi', 'hog', 'lead'\n",
        "]\n",
        "\n",
        "# Print the class of the first sample\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))\n",
        "print(\"Shape of train labels:\", train_labels.shape)\n",
        "\n",
        "# Get the dataset word index\n",
        "# Load the Reuters word index\n",
        "word_to_index = tf.keras.datasets.reuters.get_word_index()\n",
        "invert_word_index = dict([(value, key)\n",
        "    for (key, value) in word_to_index.items()])\n",
        "\n",
        "# Print the first data example sentence\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?')\n",
        "    for i in train_data[0]])\n",
        "print(\"First sample:\", text_news)\n",
        "\n",
        "# Preprocess the data\n",
        "# Define a function that encodes the data\n",
        "# into a 'bag of words' representation\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros(shape=(len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(text_samples=train_data)\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "# Create a Dataset object for the train set\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    tensors=(x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(batch_size=32)\n",
        "print(\"Train dataset element spec:\", train_dataset.element_spec)\n",
        "\n",
        "x_test = bag_of_words(text_samples=test_data)\n",
        "print(\"Shape of x_test:\", x_test.shape)\n",
        "# Create a Dataset object for the test set\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    tensors=(x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(batch_size=32)\n",
        "print(\"Test dataset element spec:\", test_dataset.element_spec)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: earn\n",
            "Shape of train labels: (8982,)\n",
            "First sample: ? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
            "Shape of x_train: (8982, 10000)\n",
            "Train dataset element spec: (TensorSpec(shape=(None, 10000), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
            "Shape of x_test: (2246, 10000)\n",
            "Test dataset element spec: (TensorSpec(shape=(None, 10000), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atSr-agDr1se"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGI4u73Pr1si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8d6eef-590f-4c45-c7d4-9a3a4cbb43f4"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Define the custom layers and model\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, units_1, units_2, units_3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units=units_1)\n",
        "        self.layer_2 = MyLayer(units=units_2)\n",
        "        self.layer_3 = MyLayer(units=units_3)\n",
        "        self.dropout = MyDropout(rate=0.5)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs=inputs)\n",
        "        x = tf.nn.relu(features=x)\n",
        "        x = self.dropout(inputs=x)\n",
        "        x = self.layer_2(inputs=x)\n",
        "        x = tf.nn.relu(features=x)\n",
        "        x = self.dropout(inputs=x)\n",
        "        x = self.layer_3(inputs=x)\n",
        "        return tf.nn.softmax(logits=x)\n",
        "\n",
        "class MyLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.b = self.add_weight(shape=(units,),\n",
        "            initializer=tf.keras.initializers.Zeros(),\n",
        "            name=\"bias\")\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "            initializer=tf.keras.initializers.RandomNormal(),\n",
        "            name=\"kernel\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.linalg.matmul(a=inputs, b=self.w) + self.b\n",
        "\n",
        "class MyDropout(tf.keras.layers.Layer):\n",
        "    def __init__(self, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Define forwared pass for dropout layer\n",
        "        return tf.nn.dropout(x=inputs, rate=self.rate)\n",
        "\n",
        "# Instantiate the model object\n",
        "model = MyModel(units_1=64, units_2=64, units_3=46)\n",
        "model(inputs=tf.keras.Input(shape=(1, 10000)))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_layer (MyLayer)          multiple                  640064    \n",
            "                                                                 \n",
            " my_layer_1 (MyLayer)        multiple                  4160      \n",
            "                                                                 \n",
            " my_layer_2 (MyLayer)        multiple                  2990      \n",
            "                                                                 \n",
            " my_dropout (MyDropout)      multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647214 (2.47 MB)\n",
            "Trainable params: 647214 (2.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D8Hqo95r1tB"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyaEBVH8r1tB"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Define the categorical cross entropy loss\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# Define the Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# Collect average loss and accuracy\n",
        "metric_loss = tf.keras.metrics.Mean()\n",
        "metric_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Use the @tf.function decorator\n",
        "@tf.function\n",
        "def get_loss_wd(model, y, yhat, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.math.reduce_sum([tf.math.reduce_sum(\n",
        "        tf.math.square(x=k)) for k in kernel_variables])\n",
        "    return loss_fn(y_true=y, y_pred=yhat) + wd_penalty\n",
        "\n",
        "# Define a function to compute the training and validation\n",
        "@tf.function\n",
        "def train(model, x, y, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(inputs=x, training=True)\n",
        "        metric_acc(y_true=y, y_pred=pred)\n",
        "        loss = get_loss_wd(model=model, y=y,\n",
        "            yhat=pred, wd=wd)\n",
        "        metric_loss(values=loss)\n",
        "        grads = tape.gradient(target=loss,\n",
        "            sources=model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(\n",
        "        grads, model.trainable_weights))\n",
        "    return metric_loss.result(), metric_acc.result()\n",
        "\n",
        "@tf.function\n",
        "def valid(model, x, y):\n",
        "    pred = model(inputs=x, training=False)\n",
        "    metric_acc(y_true=y, y_pred=pred)\n",
        "    loss = loss_fn(y_true=y, y_pred=pred)\n",
        "    metric_loss(values=loss)\n",
        "    return metric_loss.result(), metric_acc.result()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ],
      "metadata": {
        "id": "I21wOE-wEhZD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwfclNSur1tl"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLZqDt-r1tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfe6dd0-f42f-4ff5-eabf-9c66fc5f7f2e"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Use tf.autograph.to_code to see the generated code\n",
        "print(tf.autograph.to_code(entity=train.python_function))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def tf__train(model, x, y, wd):\n",
            "    with ag__.FunctionScope('train', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        with ag__.ld(tf).GradientTape() as tape:\n",
            "            pred = ag__.converted_call(ag__.ld(model), (), dict(inputs=ag__.ld(x), training=True), fscope)\n",
            "            ag__.converted_call(ag__.ld(metric_acc), (), dict(y_true=ag__.ld(y), y_pred=ag__.ld(pred)), fscope)\n",
            "            loss = ag__.converted_call(ag__.ld(get_loss_wd), (), dict(model=ag__.ld(model), y=ag__.ld(y), yhat=ag__.ld(pred), wd=ag__.ld(wd)), fscope)\n",
            "            ag__.converted_call(ag__.ld(metric_loss), (), dict(values=ag__.ld(loss)), fscope)\n",
            "            grads = ag__.converted_call(ag__.ld(tape).gradient, (), dict(target=ag__.ld(loss), sources=ag__.ld(model).trainable_variables), fscope)\n",
            "        ag__.converted_call(ag__.ld(optimizer).apply_gradients, (), dict(grads_and_vars=ag__.converted_call(ag__.ld(zip), (ag__.ld(grads), ag__.ld(model).trainable_weights), None, fscope)), fscope)\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = (ag__.converted_call(ag__.ld(metric_loss).result, (), None, fscope), ag__.converted_call(ag__.ld(metric_acc).result, (), None, fscope))\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbSqeUASr1tD"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsBCnNF8r1tG"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(seed=42)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Implement the training loop\n",
        "start_time = time.time()\n",
        "\n",
        "# Keep results for plotting\n",
        "history = {\n",
        "    \"train_loss\": [], \"train_accuracy\": [],\n",
        "    \"valid_loss\": [], \"valid_accuracy\": []\n",
        "}\n",
        "for _ in range(10):\n",
        "    # Training loop\n",
        "    for x, y in train_dataset:\n",
        "        # Optimize the model\n",
        "        train_loss, train_acc = train(model=model, x=x,\n",
        "            y=y, wd=0.005)\n",
        "    # Compute current loss\n",
        "    history[\"train_loss\"].append(train_loss.numpy())\n",
        "    # Compare predicted label to actual label\n",
        "    history[\"train_accuracy\"].append(train_acc.numpy())\n",
        "\n",
        "    # Evaluate the model\n",
        "    # Loop over the test set and print scores\n",
        "    for x, y in test_dataset:\n",
        "        valid_loss, valid_acc = valid(model=model, x=x, y=y)\n",
        "    # Compute current loss\n",
        "    history[\"valid_loss\"].append(valid_loss.numpy())\n",
        "    # Compare predicted label to actual label\n",
        "    history[\"valid_accuracy\"].append(valid_acc.numpy())\n",
        "\n",
        "# End epoch\n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))\n",
        "df_history = pd.DataFrame(history)\n",
        "\n",
        "# Plot the learning curves\n",
        "# Plot the training loss and accuracy\n",
        "fig, axes = plt.subplots(nrows=2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle(t=\"Training Metrics\")\n",
        "axes[1].set_xlabel(xlabel=\"epoch\")\n",
        "for ax, metric in zip(axes, [\"loss\", \"accuracy\"]):\n",
        "    sns.lineplot(ax=ax, label=\"train\", data=df_history,\n",
        "        x=df_history.index, y=f\"train_{metric}\")\n",
        "    sns.lineplot(ax=ax, label=\"valid\", data=df_history,\n",
        "        x=df_history.index, y=f\"valid_{metric}\")\n",
        "    ax.legend(loc=\"best\")\n",
        "    ax.set_ylabel(ylabel=f\"{metric}\")\n",
        "    ax.set_title(label=f\"{metric} vs. epoch\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# # Get the model prediction for an example input\n",
        "predicted_label = np.argmax(model(\n",
        "    inputs=x_train[np.newaxis, 0]), axis=1)[0]\n",
        "print(\"Prediction from the model\")\n",
        "print(\"Predict: {}\".format(class_names[predicted_label]))\n",
        "print(\"  Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}