{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/PyTorch/Experiments/VAE/T01_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install --no-cache-dir -qU pip\n",
        "pip install --no-cache-dir -qU \\\n",
        "    torch torchvision\n",
        "pip check"
      ],
      "metadata": {
        "id": "4FVxjXy3_EDQ"
      },
      "id": "4FVxjXy3_EDQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e17b7ff-4f44-43c3-a175-068134bc627a",
      "metadata": {
        "id": "3e17b7ff-4f44-43c3-a175-068134bc627a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"models\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbb0ec20-24e8-494f-baf8-6dfd4c49f344",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "bbb0ec20-24e8-494f-baf8-6dfd4c49f344"
      },
      "source": [
        "### Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ea21ca8-2577-471a-9167-f0a35f9ccb99",
      "metadata": {
        "id": "2ea21ca8-2577-471a-9167-f0a35f9ccb99"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "import torchvision\n",
        "\n",
        "transform = torchvision.transforms.Compose(transforms=[\n",
        "    torchvision.transforms.Pad(padding=2),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "ds_train = torchvision.datasets.FashionMNIST(root='data', download=True, train=True,\n",
        "    transform=transform)\n",
        "dl_train = torch.utils.data.DataLoader(dataset=ds_train, shuffle=True, batch_size=64)\n",
        "\n",
        "ds_test = torchvision.datasets.FashionMNIST(root='data', download=True, train=False,\n",
        "    transform=transform)\n",
        "dl_test = torch.utils.data.DataLoader(dataset=ds_test, shuffle=False, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9635c71c-a0cc-4ad5-8261-3092759bf0d8",
      "metadata": {
        "id": "9635c71c-a0cc-4ad5-8261-3092759bf0d8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx_to_class = {v: k for k, v in ds_train.class_to_idx.items()}\n",
        "X, y = next(iter(dl_test))\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=[8, 2])\n",
        "for j in range(len(axes)):\n",
        "    image = X[j].squeeze()\n",
        "    label = idx_to_class[y[j].item()]\n",
        "    axes[j].imshow(X=image, cmap='binary')\n",
        "    axes[j].set_title(label=f\"{label}\")\n",
        "    axes[j].axis('off')\n",
        "fig.tight_layout()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778988d8-9af8-49eb-8030-d64710927cfe",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "778988d8-9af8-49eb-8030-d64710927cfe"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9368ef1-ead2-4027-beee-e7f6124b4bad",
      "metadata": {
        "id": "a9368ef1-ead2-4027-beee-e7f6124b4bad"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "class Sampling(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    This class will be used in the encoder for sampling in the latent space\n",
        "    \"\"\"\n",
        "    def forward(self, z_mean, z_log_var):\n",
        "        # get the shape of the tensor for the mean and log variance\n",
        "        batch, dim = z_mean.shape\n",
        "        # define a normal distribution of epsilon\n",
        "        epsilon_dist = torch.distributions.normal.Normal(loc=0., scale=1.)\n",
        "        # generate a normal random tensor (epsilon) with the same shape as z_mean\n",
        "        epsilon = epsilon_dist.sample(sample_shape=(batch, dim)).to(z_mean.device)\n",
        "        # apply the reparameterization trick to generate the samples in the latent space\n",
        "        return z_mean + torch.exp(input=0.5*z_log_var)*epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "defa4690-4b44-4060-80d7-130a10eab7ec",
      "metadata": {
        "id": "defa4690-4b44-4060-80d7-130a10eab7ec"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "class ConvBlock(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply convolution layers with relu activation function\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.block = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                kernel_size=(3, 3), padding=(1, 1), stride=(2, 2)),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Define the Encoder. Pass the input through the encoder to get the latent vector.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_size=(32, 32), embedding_dim=2):\n",
        "        super().__init__()\n",
        "        # define the convolutional layers for downsampling and feature extraction\n",
        "        self.features = torch.nn.Sequential(\n",
        "            ConvBlock(in_channels=1, out_channels=32),\n",
        "            ConvBlock(in_channels=32, out_channels=64),\n",
        "            ConvBlock(in_channels=64, out_channels=128)\n",
        "        )\n",
        "        # define a flatten layer\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        # define fully connected layers to transform the tensor into the embedding\n",
        "        # dimensions\n",
        "        feature_dim = (128, image_size[0]//(2**3), image_size[1]//(2**3))\n",
        "        self.fc_mean = torch.nn.Linear(out_features=embedding_dim,\n",
        "            in_features=feature_dim[0]*feature_dim[1]*feature_dim[2])\n",
        "        self.fc_log_var = torch.nn.Linear(out_features=embedding_dim,\n",
        "            in_features=feature_dim[0]*feature_dim[1]*feature_dim[2])\n",
        "        # initialize the sampling layer\n",
        "        self.sampling = Sampling()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        # flatten the tensor\n",
        "        x = self.flatten(x)\n",
        "        # get the mean and log variance of the latent space distribution\n",
        "        z_mean = self.fc_mean(x)\n",
        "        z_log_var = self.fc_log_var(x)\n",
        "        # sample a latent vector using the reparameterization trick\n",
        "        z = self.sampling(z_mean, z_log_var)\n",
        "        return z_mean, z_log_var, z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c847a3-0107-43dc-b153-2d5f1d61ccf0",
      "metadata": {
        "id": "b4c847a3-0107-43dc-b153-2d5f1d61ccf0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "class ConvTransposeBlock(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply transposed convolutional layers with relu activation function\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.block = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                kernel_size=(3, 3), padding=(1, 1), stride=(2, 2), output_padding=(1, 1)),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Define the Decoder. Pass the latent vector through the decoder to get the reconstructed\n",
        "    image.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_size=(32, 32), embedding_dim=2):\n",
        "        super().__init__()\n",
        "        # define a fully connected layer to transform the latent vector back to the\n",
        "        # shape before flattening\n",
        "        feature_dim = (128, image_size[0]//(2**3), image_size[1]//(2**3))\n",
        "        self.fc = torch.nn.Linear(in_features=embedding_dim,\n",
        "            out_features=feature_dim[0]*feature_dim[1]*feature_dim[2])\n",
        "        # define a reshape function to reshape the tensor back to its original shape\n",
        "        self.reshape = lambda x: x.view(-1, *feature_dim)\n",
        "        self.features = torch.nn.Sequential(\n",
        "            ConvTransposeBlock(in_channels=128, out_channels=64),\n",
        "            ConvTransposeBlock(in_channels=64, out_channels=32),\n",
        "            # apply the final transposed convolutional layer with a sigmoid activation to\n",
        "            # generate the final output\n",
        "            torch.nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=(3, 3),\n",
        "                padding=(1, 1), stride=(2, 2), output_padding=(1, 1)),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # pass the latent vector through the fully connected layer\n",
        "        x = self.fc(x)\n",
        "        # reshape the tensor\n",
        "        x = self.reshape(x)\n",
        "        x = self.features(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9417ec66-76c1-431d-988c-a9d074081c3c",
      "metadata": {
        "id": "9417ec66-76c1-431d-988c-a9d074081c3c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "class VAE(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Define the VAE class. Return the mean, log variance and the reconstructed image\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        # Initialize the encoder and decoder\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, x):\n",
        "        z_mean, z_log_var, z = self.encoder(x)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return z_mean, z_log_var, reconstruction\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# instantiate the encoder and decoder models\n",
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)\n",
        "# pass the encoder and decoder to VAE class\n",
        "model = VAE(encoder=encoder, decoder=decoder).to(device)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total model parameters: {total_params}\")\n",
        "\n",
        "print(\"x shape:\", X.shape)\n",
        "z_mean, z_log_var, reconstruction = model(x=X.to(device))\n",
        "print(\"z_mean shape:\", z_mean.shape)\n",
        "print(\"z_log_var shape:\", z_log_var.shape)\n",
        "print(\"reconstruction shape:\", reconstruction.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02499618-c980-458b-9046-5bdfdbd6955a",
      "metadata": {
        "id": "02499618-c980-458b-9046-5bdfdbd6955a"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a5fe7a8-d180-47b1-af0e-48f2f6aa0974",
      "metadata": {
        "id": "3a5fe7a8-d180-47b1-af0e-48f2f6aa0974"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(seed=42)\n",
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "class VAELoss:\n",
        "    def KLdiv_loss(self, mu, logvar):\n",
        "        kldiv_loss = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
        "        return kldiv_loss.mean()\n",
        "\n",
        "    def reconstruction_loss(self, x, x_pred):\n",
        "        bce_loss = torch.nn.BCELoss()\n",
        "        return bce_loss(input=x_pred, target=x)\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        mu, logvar, x_pred = input\n",
        "        recon_loss = self.reconstruction_loss(x=target, x_pred=x_pred)\n",
        "        kldiv_loss = self.KLdiv_loss(mu=mu, logvar=logvar)\n",
        "        return kldiv_loss + 500*recon_loss\n",
        "\n",
        "def train_step(model, dl_train, loss_fn, optimizer, device):\n",
        "    # set the model to train mode\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for x, _ in dl_train:\n",
        "        x = x.to(device)\n",
        "        pred = model(x=x)\n",
        "\n",
        "        loss = loss_fn(input=pred, target=x)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    return np.mean(losses)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_step(model, dl_test, loss_fn, device):\n",
        "    # set the model to eval mode\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for x, _ in dl_test:\n",
        "        x = x.to(device)\n",
        "        pred = model(x=x)\n",
        "\n",
        "        loss = loss_fn(input=pred, target=x)\n",
        "        losses.append(loss.item())\n",
        "    return np.mean(losses)\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = loss\n",
        "        elif loss < (self.best_loss - self.min_delta):\n",
        "            self.best_loss = loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "def plot_history(history):\n",
        "    df_history = pd.DataFrame(history)\n",
        "    df_history.index.name = 'epoch'\n",
        "    df_history.reset_index(inplace=True)\n",
        "\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    sns.lineplot(data=df_history, x='epoch', y='train_loss', label='train')\n",
        "    sns.lineplot(data=df_history, x='epoch', y='test_loss', label='test')\n",
        "    plt.yscale('log')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title(label='loss vs. epoch')\n",
        "    plt.xlabel(xlabel='epoch')\n",
        "    plt.ylabel(ylabel='loss (log scale)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6faa7f38-a7a3-45d3-ba39-7023122163c9",
      "metadata": {
        "id": "6faa7f38-a7a3-45d3-ba39-7023122163c9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "loss_fn = VAELoss()\n",
        "# instantiate optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(lr=0.001,\n",
        "    params=list(encoder.parameters()) + list(decoder.parameters()))\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "    mode='min', factor=0.1, patience=3)\n",
        "early_stopping = EarlyStopping(patience=10, min_delta=1e-6)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# instantiate the encoder and decoder models\n",
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)\n",
        "# pass the encoder and decoder to VAE class\n",
        "model = VAE(encoder=encoder, decoder=decoder).to(device)\n",
        "\n",
        "model_path = 'models/VAE.pth'\n",
        "history = {'train_loss': [], 'test_loss': []}\n",
        "# Initialize the best validation loss as infinity\n",
        "best_val_loss = float('inf')\n",
        "# start training by looping over the number of epochs\n",
        "num_epochs = 10\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_step(model=model, dl_train=dl_train, device=device,\n",
        "        loss_fn=loss_fn, optimizer=optimizer)\n",
        "    history['train_loss'].append(train_loss)\n",
        "\n",
        "    test_loss = test_step(model=model, dl_test=dl_test, device=device,\n",
        "        loss_fn=loss_fn)\n",
        "    history['test_loss'].append(test_loss)\n",
        "\n",
        "    scheduler.step(metrics=test_loss)\n",
        "\n",
        "    if test_loss < best_val_loss:\n",
        "        best_val_loss = test_loss\n",
        "        torch.save(obj=model.state_dict(), f=model_path)\n",
        "\n",
        "    early_stopping(loss=test_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        break\n",
        "\n",
        "end_time = time.time() - start_time\n",
        "print(\"Training finished in %.2fs\"%(end_time))\n",
        "plot_history(history=history)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}