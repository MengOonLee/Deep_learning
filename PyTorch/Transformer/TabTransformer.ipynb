{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "CSV_HEADERS = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
    "    'occupation', 'relationship', 'race', 'gender', 'capital_gain', 'capital_loss',\n",
    "    'hours_per_week', 'native_country', 'income_bracket']\n",
    "\n",
    "train_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "df_train = pd.read_csv(train_url, header=None, names=CSV_HEADERS)\n",
    "\n",
    "test_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "df_test = pd.read_csv(test_url, header=None, names=CSV_HEADERS, skiprows=1)\n",
    "df_val, df_test = model_selection.train_test_split(df_test, test_size=0.5, random_state=42,\n",
    "    stratify=df_test['income_bracket'])\n",
    "\n",
    "def load_data(df):\n",
    "    df = df.copy().drop(columns=['fnlwgt', 'education_num'])\\\n",
    "        .reset_index(drop=True)\n",
    "    \n",
    "    numeric_cols = ['capital_gain', 'capital_loss', 'hours_per_week']\n",
    "    X_num = df[numeric_cols].astype('float32')\n",
    "\n",
    "    categoric_cols = [c for c in df.columns if c not in numeric_cols]\n",
    "    X_cat = df[categoric_cols].astype(str).apply(lambda s: s.str.strip())\n",
    "    y = X_cat['income_bracket'].str.replace('.', '')\n",
    "    X_cat = X_cat.drop(columns=['income_bracket'])\n",
    "    \n",
    "    return X_num, X_cat, y\n",
    "\n",
    "X_num_train, X_cat_train, y_train = load_data(df=df_train)\n",
    "X_num_val, X_cat_val, y_val = load_data(df=df_val)\n",
    "X_num_test, X_cat_test, y_test = load_data(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], shape=(8141, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_num_train)\n",
    "\n",
    "encoder = preprocessing.OrdinalEncoder(unknown_value=-1,\n",
    "    handle_unknown='use_encoded_value')\n",
    "encoder.fit(X_cat_train)\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y_train)\n",
    "\n",
    "lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwyBuSuUBzy2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "class TabularDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_num, X_cat, y):\n",
    "        self.X_num = torch.tensor(data=X_num, dtype=torch.float32)\n",
    "        self.X_cat = torch.tensor(data=X_cat, dtype=torch.long)\n",
    "        self.y = torch.tensor(data=y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "class CensusDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_url, test_url, batch_size=256):\n",
    "        super().__init__()\n",
    "        self.train_url = train_url\n",
    "        self.test_url = test_url\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    \n",
    "\n",
    "    def _build_category_maps(self, train_cat):\n",
    "        maps = {}\n",
    "        for col in train_cat.columns:\n",
    "            unique_vals = sorted(train_cat[col].unique())\n",
    "            maps[col] = {val: i+1 for i, val in enumerate(unique_vals)}\n",
    "            maps[col]['__UNK__'] = 0\n",
    "        return maps\n",
    "\n",
    "    def _apply_category_maps(self, X_cat, maps):\n",
    "        X_cat = X_cat.copy().apply(\n",
    "            lambda c: c.map(maps[c.name]).fillna(0).astype(int))\n",
    "        return X_cat.values\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        self.cat_maps = self._build_category_maps(train_cat=X_cat_train)\n",
    "        X_cat_train = self._apply_category_maps(X_cat=X_cat_train,\n",
    "            maps=self.cat_maps)\n",
    "        X_cat_test = self._apply_category_maps(X_cat=X_cat_test,\n",
    "            maps=self.cat_maps)\n",
    "\n",
    "        self.mean = X_num_train.mean(axis=0)\n",
    "        self.std = X_num_train.std(axis=0)\n",
    "        self.num_features = X_num_train.shape[1]\n",
    "        self.cat_cardinalities = [len(self.cat_maps[c]) for c in self.cat_maps.keys()]\n",
    "\n",
    "        self.ds_train = TabularDataset(X_num=X_num_train, X_cat=X_cat_train, y=y_train)\n",
    "        ds_test = TabularDataset(X_num=X_num_test, X_cat=X_cat_test, y=y_test)\n",
    "        self.ds_val, self.ds_test = torch.utils.data.random_split(dataset=ds_test,\n",
    "            lengths=[0.5, 0.5], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(dataset=self.ds_train,\n",
    "            batch_size=self.batch_size, shuffle=True, num_workers=7)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(dataset=self.ds_val,\n",
    "            batch_size=self.batch_size, num_workers=7)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(dataset=self.ds_test,\n",
    "            batch_size=self.batch_size, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fc0EfoIhSMOJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "class Normalization(torch.nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super().__init__()\n",
    "        self.register_buffer('mean', torch.tensor(data=mean, dtype=torch.float32))\n",
    "        self.register_buffer('std', torch.tensor(data=std, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / self.std\n",
    "\n",
    "class ClassifyModel(pl.LightningModule):\n",
    "    def __init__(self, num_features, cat_cardinalities, mean, std):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalizer = Normalization(mean=mean, std=std)\n",
    "\n",
    "        self.emb_layers = torch.nn.ModuleList(modules=[\n",
    "            torch.nn.Embedding(num_embeddings=c+1, embedding_dim=min(8, (c+1)//2))\n",
    "            for c in cat_cardinalities\n",
    "        ])\n",
    "        emb_out_dim = sum(e.embedding_dim for e in self.emb_layers)\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=num_features + emb_out_dim, out_features=128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(in_features=128, out_features=64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(in_features=64, out_features=1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        x_num = self.normalizer(x_num)\n",
    "        x_emb = [emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)]\n",
    "        x_emb = torch.cat(tensors=x_emb, dim=1)\n",
    "        x = torch.cat(tensors=[x_num, x_emb], dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        preds = self(x_num=x_num, x_cat=x_cat).squeeze()\n",
    "        loss = self.criterion(preds, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        preds = self(x_num=x_num, x_cat=x_cat).squeeze()\n",
    "        loss = self.criterion(preds, y)\n",
    "        self.log('val_loss', loss)\n",
    "        acc = ((preds > 0.5).float()==y).float().mean()\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        preds = self(x_num, x_cat).squeeze()\n",
    "        acc = ((preds > 0.5).float()==y).float().mean()\n",
    "        self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1IPpBcxrycm"
   },
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    datamodule = CensusDataModule(train_url=train_url, test_url=test_url)\n",
    "    datamodule.setup()\n",
    "\n",
    "    model = ClassifyModel(\n",
    "        num_features=datamodule.num_features,\n",
    "        cat_cardinalities=datamodule.cat_cardinalities,\n",
    "        mean=datamodule.mean,\n",
    "        std=datamodule.std\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=3, accelerator='auto', devices=1)\n",
    "    trainer.fit(model=model, datamodule=datamodule)\n",
    "    trainer.test(model=model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbMvq4d9pTIow2y0AY9YRq",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
