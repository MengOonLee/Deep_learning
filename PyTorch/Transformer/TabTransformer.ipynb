{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_HEADERS = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
    "    'occupation', 'relationship', 'race', 'gender', 'capital_gain', 'capital_loss',\n",
    "    'hours_per_week', 'native_country', 'income_bracket']\n",
    "\n",
    "train_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "df_train = pd.read_csv(train_url, header=None, names=CSV_HEADERS)\n",
    "\n",
    "test_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "df_test = pd.read_csv(test_url, header=None, names=CSV_HEADERS, skiprows=1)\n",
    "\n",
    "def load_data(df):\n",
    "    df = df.copy().drop(columns=['fnlwgt', 'education_num'])\\\n",
    "        .reset_index(drop=True)\n",
    "    \n",
    "    numeric_cols = ['capital_gain', 'capital_loss', 'hours_per_week']\n",
    "    X_num = df[numeric_cols].astype('float32')\n",
    "\n",
    "    categoric_cols = [c for c in df.columns if c not in numeric_cols]\n",
    "    X_cat = df[categoric_cols].astype(str).apply(lambda s: s.str.strip())\n",
    "    y = X_cat['income_bracket'].str.replace('.', '')\n",
    "    X_cat = X_cat.drop(columns=['income_bracket'])\n",
    "    \n",
    "    return X_num, X_cat, y\n",
    "\n",
    "X_num_train, X_cat_train, y_train = load_data(df=df_train)\n",
    "X_num_test, X_cat_test, y_test = load_data(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "y_lb = preprocessing.LabelBinarizer()\n",
    "y_lb.fit(y=y_train)\n",
    "\n",
    "num_scaler = preprocessing.StandardScaler()\n",
    "num_scaler.fit(X=X_num_train)\n",
    "num_features = num_scaler.n_features_in_\n",
    "\n",
    "cat_encoder = preprocessing.OrdinalEncoder(unknown_value=-1,\n",
    "    handle_unknown='use_encoded_value')\n",
    "cat_encoder.fit(X=X_cat_train)\n",
    "cat_cardinalities = [len(c)+1 for c in cat_encoder.categories_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=42)\n",
    "\n",
    "class CensusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_num, X_cat, y, num_scaler, cat_encoder, y_lb):\n",
    "        X_num = num_scaler.transform(X_num)\n",
    "        self.X_num = torch.tensor(data=X_num, dtype=torch.float32)\n",
    "        \n",
    "        X_cat = cat_encoder.transform(X_cat) + 1\n",
    "        self.X_cat = torch.tensor(data=X_cat, dtype=torch.long)\n",
    "        \n",
    "        y = y_lb.transform(y).astype('int').squeeze()\n",
    "        self.y = torch.tensor(data=y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
    "\n",
    "ds_temp = CensusDataset(X_num=X_num_train, X_cat=X_cat_train, y=y_train,\n",
    "    num_scaler=num_scaler, cat_encoder=cat_encoder, y_lb=y_lb)\n",
    "ds_train, ds_val = torch.utils.data.random_split(dataset=ds_temp, lengths=[0.8, 0.2],\n",
    "    generator=torch.Generator().manual_seed(42))\n",
    "dl_train = torch.utils.data.DataLoader(dataset=ds_train, batch_size=256, shuffle=True)\n",
    "dl_val = torch.utils.data.DataLoader(dataset=ds_val, batch_size=256)\n",
    "\n",
    "ds_test = CensusDataset(X_num=X_num_test, X_cat=X_cat_test, y=y_test,\n",
    "    num_scaler=num_scaler, cat_encoder=cat_encoder, y_lb=y_lb)\n",
    "dl_test = torch.utils.data.DataLoader(dataset=ds_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 2084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=42)\n",
    "\n",
    "class CensusClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_features, cat_cardinalities):\n",
    "        super().__init__()\n",
    "        self.embedding_layers = torch.nn.ModuleList(modules=[\n",
    "            torch.nn.Embedding(num_embeddings=c,\n",
    "                embedding_dim=int(min(50, max(1, round(c**0.25)))))\n",
    "            for c in cat_cardinalities])\n",
    "        \n",
    "        in_features = num_features + sum(e.embedding_dim for e in self.embedding_layers)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=in_features, out_features=64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=64, out_features=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, X_num, X_cat):\n",
    "        X_emb = [emb(X_cat[:, i]) for i, emb in enumerate(self.embedding_layers)]\n",
    "        X_emb = torch.cat(tensors=X_emb, dim=1)\n",
    "        X = torch.cat(tensors=[X_num, X_emb], dim=1)\n",
    "        y = torch.nn.functional.sigmoid(self.fc(X))\n",
    "        return y\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type \\\n",
    "    if torch.accelerator.is_available() else 'cpu'\n",
    "\n",
    "model = CensusClassifier(num_features=num_features,\n",
    "    cat_cardinalities=cat_cardinalities).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print('Total parameters:', total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=42)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for X_num, X_cat, y in dataloader:\n",
    "        X_num, X_cat = X_num.to(device), X_cat.to(device)\n",
    "        y_pred = model(X_num=X_num, X_cat=X_cat)\n",
    "        loss = loss_fn(input=y_pred, target=y)\n",
    "        print(loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "train(dataloader=dl_train, model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "        \n",
    "# def test(dataloader, model, loss_fn):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for x_num, x_cat, y in dataloader:\n",
    "#             if torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbMvq4d9pTIow2y0AY9YRq",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
