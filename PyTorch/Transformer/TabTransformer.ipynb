{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMyjKJEW28dZ4px+WDL2GY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/PyTorch/Transformer/TabTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install -qU torch lightning"
      ],
      "metadata": {
        "id": "RGebV16U7pHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import lightning as L\n",
        "\n",
        "class TabularDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X_num, X_cat, y):\n",
        "        self.X_num = torch.tensor(data=X_num, dtype=torch.float32)\n",
        "        self.X_cat = torch.tensor(data=X_cat, dtype=torch.long)\n",
        "        self.y = torch.tensor(data=y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
        "\n",
        "class CensusDataModule(L.LightningDataModule):\n",
        "    def __init__(self, train_url, test_url, batch_size=256):\n",
        "        super().__init__()\n",
        "        self.train_url = train_url\n",
        "        self.test_url = test_url\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def _load_data(self, df):\n",
        "        df = df.copy().drop(columns=['fnlwgt', 'education_num']).dropna()\n",
        "        df['income_bracket'] = df['income_bracket'].astype(str)\\\n",
        "            .str.replace('.', '').str.strip()\n",
        "        y = df['income_bracket'].map({'<=50K': 0, '>50K': 1}).astype('float32')\n",
        "\n",
        "        NUMERIC_FEATURES = ['capital_gain', 'capital_loss', 'hours_per_week']\n",
        "        X_num = df[NUMERIC_FEATURES].astype('float32')\n",
        "        X_cat = df.drop(columns=NUMERIC_FEATURES + ['income_bracket'])\\\n",
        "            .astype(str).apply(lambda s: s.str.strip())\n",
        "        return X_num.values, X_cat, y.values\n",
        "\n",
        "    def _build_category_maps(self, train_cat):\n",
        "        maps = {}\n",
        "        for col in train_cat.columns:\n",
        "            unique_vals = sorted(train_cat[col].unique())\n",
        "            maps[col] = {val: i+1 for i, val in enumerate(unique_vals)}\n",
        "            maps[col]['__UNK__'] = 0\n",
        "        return maps\n",
        "\n",
        "    def _apply_category_maps(self, X_cat, maps):\n",
        "        X_cat = X_cat.copy().apply(\n",
        "            lambda c: c.map(maps[c.name]).fillna(0).astype(int))\n",
        "        return X_cat.values\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        CSV_HEADERS = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
        "            'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
        "            'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
        "            'income_bracket']\n",
        "        df_train = pd.read_csv(self.train_url, header=None,\n",
        "            names=CSV_HEADERS)\n",
        "        df_test = pd.read_csv(self.test_url, header=0,\n",
        "            names=CSV_HEADERS)\n",
        "\n",
        "        X_num_train, X_cat_train, y_train = self._load_data(df=df_train)\n",
        "        X_num_test, X_cat_test, y_test = self._load_data(df=df_test)\n",
        "\n",
        "        self.cat_maps = self._build_category_maps(train_cat=X_cat_train)\n",
        "        X_cat_train = self._apply_category_maps(X_cat=X_cat_train,\n",
        "            maps=self.cat_maps)\n",
        "        X_cat_test = self._apply_category_maps(X_cat=X_cat_test,\n",
        "            maps=self.cat_maps)\n",
        "\n",
        "        self.mean = X_num_train.mean(axis=0)\n",
        "        self.std = X_num_train.std(axis=0)\n",
        "        self.num_features = X_num_train.shape[1]\n",
        "        self.cat_cardinalities = [len(self.cat_maps[c]) for c in self.cat_maps.keys()]\n",
        "\n",
        "        self.ds_train = TabularDataset(X_num=X_num_train, X_cat=X_cat_train, y=y_train)\n",
        "        ds_test = TabularDataset(X_num=X_num_test, X_cat=X_cat_test, y=y_test)\n",
        "        self.ds_val, self.ds_test = torch.utils.data.random_split(dataset=ds_test,\n",
        "            lengths=[0.5, 0.5], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(dataset=self.ds_train,\n",
        "            batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(dataset=self.ds_val,\n",
        "            batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(dataset=self.ds_test,\n",
        "            batch_size=self.batch_size)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "    test_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
        "    datamodule = CensusDataModule(train_url=train_url, test_url=test_url)\n",
        "    datamodule.setup()"
      ],
      "metadata": {
        "id": "bwyBuSuUBzy2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import lightning as L\n",
        "\n",
        "class Normalization(torch.nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super().__init__()\n",
        "        self.register_buffer('mean', torch.tensor(data=mean, dtype=torch.float32))\n",
        "        self.register_buffer('std', torch.tensor(data=std, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (x - self.mean) / self.std\n",
        "\n",
        "class ClassifyModel(torch.nn.Module):\n",
        "    def __init__(self, cat_cardinalities):\n",
        "        super().__init__()\n",
        "        self.normalizer = Normalization(mean=mean, std=std)\n",
        "        self.emb_layers = torch.nn.ModuleList(modules=[\n",
        "            torch.nn.Embedding(num_embeddings=c, embedding_dim=min(4, (c+1)//2))\n",
        "            for c in cat_cardinalities\n",
        "        ])\n",
        "\n",
        "    def forward(self, x_num, x_cat):\n",
        "        x_num = self.normalizer(x_num)\n",
        "        x_emb = [emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)]\n",
        "\n",
        "\n",
        "        return x_num, x_emb\n",
        "\n",
        "model = ClassifyModel(cat_cardinalities=cat_cardinalities)\n",
        "x_num = torch.tensor(X_num_train[:10], dtype=torch.float32)\n",
        "x_emb = torch.tensor(X_cat_train[:10], dtype=torch.long)\n",
        "model(x_num, x_emb)"
      ],
      "metadata": {
        "id": "Fc0EfoIhSMOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X1IPpBcxrycm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVKlnMTa50Xp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}