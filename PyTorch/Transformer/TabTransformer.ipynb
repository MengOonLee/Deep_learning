{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcA8m7xsExjhfjB+QDP57p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/PyTorch/Transformer/TabTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6izs0S_H6sJr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_headers = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
        "    'occupation', 'relationship', 'race', 'gender', 'capital_gain', 'capital_loss',\n",
        "    'hours_per_week', 'native_country', 'income_bracket'\n",
        "]\n",
        "\n",
        "def create_X_y(df):\n",
        "    df = df.copy()\n",
        "    df.drop(columns=['fnlwgt', 'education_num'], inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df['income_bracket'] = df['income_bracket'].astype('str')\\\n",
        "        .str.replace('.', '').str.strip()\n",
        "    X, y = df.drop(columns=['income_bracket']), df['income_bracket']\n",
        "    y = y.map({'<=50K': 0, '>50K': 1}).astype('float32')\n",
        "\n",
        "    numeric_headers = ['capital_gain', 'capital_loss', 'hours_per_week']\n",
        "    X_num = X[numeric_headers].astype('float32')\n",
        "\n",
        "    categoric_headers = [n for n in X.columns if n not in numeric_headers]\n",
        "    for col in categoric_headers:\n",
        "        X[col] = X[col].astype('str').str.strip()\n",
        "    X_cat = X[categoric_headers]\n",
        "\n",
        "    return X_num.values, X_cat, y.values\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "df_train = pd.read_csv(url, header=None, names=csv_headers)\n",
        "X_num_train, X_cat_train, y_train = create_X_y(df=df_train)\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
        "df_test = pd.read_csv(url, header=0, names=csv_headers)\n",
        "X_num_test, X_cat_test, y_test = create_X_y(df=df_test)\n",
        "\n",
        "cat_maps = {}\n",
        "for col in X_cat_train.columns:\n",
        "    cat_maps[col] = {val: i+1 for i, val in\n",
        "        enumerate(sorted(X_cat_train[col].unique()))}\n",
        "    cat_maps[col]['__UNK__'] = 0\n",
        "    X_cat_train[col] = X_cat_train[col].map(cat_maps[col])\n",
        "    X_cat_test[col] = X_cat_test[col].map(cat_maps[col])\n",
        "X_cat_train, X_cat_test = X_cat_train.values, X_cat_test.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class TabularDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X_num, X_cat, y):\n",
        "        self.X_num = torch.tensor(data=X_num, dtype=torch.float32)\n",
        "        self.X_cat = torch.tensor(data=X_cat, dtype=torch.long)\n",
        "        self.y = torch.tensor(data=y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X_num[idx], self.X_cat[idx], self.y[idx]\n",
        "\n",
        "ds_train = TabularDataset(X_num=X_num_train, X_cat=X_cat_train, y=y_train)\n",
        "ds_test = TabularDataset(X_num=X_num_test, X_cat=X_cat_test, y=y_test)\n",
        "\n",
        "dl_train = torch.utils.data.DataLoader(dataset=ds_train,\n",
        "    batch_size=256, shuffle=True)\n",
        "dl_test = torch.utils.data.DataLoader(dataset=ds_test, batch_size=256)"
      ],
      "metadata": {
        "id": "QPFSPKBFXEp4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class Normalization(torch.nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super().__init__()\n",
        "        self.register_buffer('mean', torch.tensor(data=mean, dtype=torch.float32))\n",
        "        self.register_buffer('std', torch.tensor(data=std, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (x - self.mean) / self.std"
      ],
      "metadata": {
        "id": "Fc0EfoIhSMOJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "mean, std = X_num_train.mean(axis=0), X_num_train.std(axis=0)\n",
        "num_dim = X_num_train.shape[1]\n",
        "cat_cardinalities =  X_cat_train.max(axis=0) + 1\n",
        "\n",
        "class ClassifyModel(torch.nn.Module):\n",
        "    def __init__(self, cat_cardinalities):\n",
        "        super().__init__()\n",
        "        self.normalizer = Normalization(mean=mean, std=std)\n",
        "        self.emb_layers = torch.nn.ModuleList(modules=[\n",
        "            torch.nn.Embedding(num_embeddings=c, embedding_dim=min(4, (c+1)//2))\n",
        "            for c in cat_cardinalities\n",
        "        ])\n",
        "\n",
        "    def forward(self, x_num, x_cat):\n",
        "        x_num = self.normalizer(x_num)\n",
        "        x_emb = [emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)]\n",
        "\n",
        "\n",
        "        return x_num, x_emb\n",
        "\n",
        "model = ClassifyModel(cat_cardinalities=cat_cardinalities)\n",
        "x_num = torch.tensor(X_num_train[:10], dtype=torch.float32)\n",
        "x_emb = torch.tensor(X_cat_train[:10], dtype=torch.long)\n",
        "model(x_num, x_emb)"
      ],
      "metadata": {
        "id": "X1IPpBcxrycm",
        "outputId": "00854444-68f9-4cf9-8569-849f1223975d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1485, -0.2167, -0.0354],\n",
              "         [-0.1459, -0.2167, -2.2222],\n",
              "         [-0.1459, -0.2167, -0.0354],\n",
              "         [-0.1459, -0.2167, -0.0354],\n",
              "         [-0.1459, -0.2167, -0.0354],\n",
              "         [-0.1459, -0.2167, -0.0354],\n",
              "         [-0.1459, -0.2167, -1.9792],\n",
              "         [-0.1459, -0.2167,  0.3695],\n",
              "         [ 1.7611, -0.2167,  0.7745],\n",
              "         [ 0.5552, -0.2167, -0.0354]]),\n",
              " [tensor([[ 0.1893,  0.0246,  1.2913,  0.1899],\n",
              "          [-1.2577,  0.3759, -1.3739, -0.6427],\n",
              "          [-0.6679,  1.1394,  0.0518, -1.0582],\n",
              "          [ 0.7615, -0.6128,  0.5224, -1.1209],\n",
              "          [ 1.9621,  0.8056, -0.0843, -0.5087],\n",
              "          [-0.9374,  0.6213, -1.7214, -1.5217],\n",
              "          [-0.4241,  0.7210, -1.9187, -0.0584],\n",
              "          [ 1.8087, -0.4617,  1.1644,  0.9504],\n",
              "          [ 0.6953, -0.0394, -1.3335, -0.9625],\n",
              "          [ 0.0104, -0.0883,  1.0266, -0.0743]], grad_fn=<EmbeddingBackward0>),\n",
              "  tensor([[-1.7141,  0.7404,  0.4529, -0.0996],\n",
              "          [ 0.6384,  0.9471, -0.2653,  0.5266],\n",
              "          [-1.5983,  0.7023, -1.2764,  0.3120],\n",
              "          [-1.5983,  0.7023, -1.2764,  0.3120],\n",
              "          [-1.5983,  0.7023, -1.2764,  0.3120],\n",
              "          [-1.5983,  0.7023, -1.2764,  0.3120],\n",
              "          [-1.5983,  0.7023, -1.2764,  0.3120],\n",
              "          [ 0.6384,  0.9471, -0.2653,  0.5266],\n",
              "          [-1.5983,  0.7023, -1.2764,  0.3120],\n",
              "          [-1.5983,  0.7023, -1.2764,  0.3120]], grad_fn=<EmbeddingBackward0>),\n",
              "  tensor([[ 0.7516,  0.8146, -1.2132, -0.0243],\n",
              "          [ 0.7516,  0.8146, -1.2132, -0.0243],\n",
              "          [-0.3399,  0.2527,  0.9661,  0.0612],\n",
              "          [-0.0878,  0.7106,  1.2921,  0.4479],\n",
              "          [ 0.7516,  0.8146, -1.2132, -0.0243],\n",
              "          [ 0.7231,  0.7592,  0.1721,  0.2389],\n",
              "          [ 0.1731,  0.6606,  0.1970, -0.3833],\n",
              "          [-0.3399,  0.2527,  0.9661,  0.0612],\n",
              "          [ 0.7231,  0.7592,  0.1721,  0.2389],\n",
              "          [ 0.7516,  0.8146, -1.2132, -0.0243]], grad_fn=<EmbeddingBackward0>),\n",
              "  tensor([[-0.6626, -0.8042, -0.1772, -0.4585],\n",
              "          [ 1.8152, -0.0560, -0.2685,  0.0868],\n",
              "          [ 0.7107,  1.2827,  0.9700,  0.9968],\n",
              "          [ 1.8152, -0.0560, -0.2685,  0.0868],\n",
              "          [ 1.8152, -0.0560, -0.2685,  0.0868],\n",
              "          [ 1.8152, -0.0560, -0.2685,  0.0868],\n",
              "          [ 0.8770,  0.9855, -0.0359, -0.1424],\n",
              "          [ 1.8152, -0.0560, -0.2685,  0.0868],\n",
              "          [-0.6626, -0.8042, -0.1772, -0.4585],\n",
              "          [ 1.8152, -0.0560, -0.2685,  0.0868]], grad_fn=<EmbeddingBackward0>),\n",
              "  tensor([[-1.1788,  0.2663, -0.2279,  2.0245],\n",
              "          [ 1.4978, -0.3601, -0.9468,  2.0652],\n",
              "          [-0.3702, -0.3012, -0.1002, -0.5669],\n",
              "          [-0.3702, -0.3012, -0.1002, -0.5669],\n",
              "          [ 0.8771, -0.7251,  0.8638,  0.5335],\n",
              "          [ 1.4978, -0.3601, -0.9468,  2.0652],\n",
              "          [-0.1263,  0.5765, -0.4419, -0.5225],\n",
              "          [ 1.4978, -0.3601, -0.9468,  2.0652],\n",
              "          [ 0.8771, -0.7251,  0.8638,  0.5335],\n",
              "          [ 1.4978, -0.3601, -0.9468,  2.0652]], grad_fn=<EmbeddingBackward0>),\n",
              "  tensor([[-0.6152,  1.2001, -0.6400,  1.0422],\n",
              "          [-0.1725, -1.3652, -0.3236, -0.2830],\n",
              "          [-0.6152,  1.2001, -0.6400,  1.0422],\n",
              "          [-0.1725, -1.3652, -0.3236, -0.2830],\n",
              "          [ 0.1722,  0.8745,  0.1828,  0.1210],\n",
              "          [ 0.1722,  0.8745,  0.1828,  0.1210],\n",
              "          [-0.6152,  1.2001, -0.6400,  1.0422],\n",
              "          [-0.1725, -1.3652, -0.3236, -0.2830],\n",
              "          [-0.6152,  1.2001, -0.6400,  1.0422],\n",
              "          [-0.1725, -1.3652, -0.3236, -0.2830]], grad_fn=<EmbeddingBackward0>),\n",
              "  tensor([[-0.2264, -1.7589,  1.9392],\n",
              "          [-0.2264, -1.7589,  1.9392],\n",
              "          [-0.2264, -1.7589,  1.9392],\n",
              "          [-2.0507, -1.4597, -2.3467],\n",
              "          [-2.0507, -1.4597, -2.3467],\n",
              "          [-0.2264, -1.7589,  1.9392],\n",
              "          [-2.0507, -1.4597, -2.3467],\n",
              "          [-0.2264, -1.7589,  1.9392],\n",
              "          [-0.2264, -1.7589,  1.9392],\n",
              "          [-0.2264, -1.7589,  1.9392]], grad_fn=<EmbeddingBackward0>),\n",
              "  tensor([[ 1.4652,  0.5330],\n",
              "          [ 1.4652,  0.5330],\n",
              "          [ 1.4652,  0.5330],\n",
              "          [ 1.4652,  0.5330],\n",
              "          [ 0.2676, -1.5735],\n",
              "          [ 0.2676, -1.5735],\n",
              "          [ 0.2676, -1.5735],\n",
              "          [ 1.4652,  0.5330],\n",
              "          [ 0.2676, -1.5735],\n",
              "          [ 1.4652,  0.5330]], grad_fn=<EmbeddingBackward0>),\n",
              "  tensor([[-0.1474,  1.5507,  0.2781, -0.1063],\n",
              "          [-0.1474,  1.5507,  0.2781, -0.1063],\n",
              "          [-0.1474,  1.5507,  0.2781, -0.1063],\n",
              "          [-0.1474,  1.5507,  0.2781, -0.1063],\n",
              "          [ 0.5571,  0.2387, -1.7547, -1.1437],\n",
              "          [-0.1474,  1.5507,  0.2781, -0.1063],\n",
              "          [ 0.6189,  1.3464, -0.5349, -1.6492],\n",
              "          [-0.1474,  1.5507,  0.2781, -0.1063],\n",
              "          [-0.1474,  1.5507,  0.2781, -0.1063],\n",
              "          [-0.1474,  1.5507,  0.2781, -0.1063]], grad_fn=<EmbeddingBackward0>)])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVKlnMTa50Xp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}