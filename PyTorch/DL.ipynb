{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9652e7f",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/PyTorch/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9345dba2-8479-4fd3-968e-b65491f0560f",
   "metadata": {
    "id": "9345dba2-8479-4fd3-968e-b65491f0560f"
   },
   "source": [
    "# Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252bceaf-3fca-473a-9133-575bfbb61bd9",
   "metadata": {
    "id": "252bceaf-3fca-473a-9133-575bfbb61bd9"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed82204-3d43-4698-8031-226c73d6eeb0",
   "metadata": {
    "id": "3ed82204-3d43-4698-8031-226c73d6eeb0"
   },
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b1f38-ff5c-490e-bfa6-469efa637450",
   "metadata": {
    "id": "d14b1f38-ff5c-490e-bfa6-469efa637450",
    "outputId": "638845fc-764a-4efc-c58a-6e19b51d661c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "[[2 3 5]\n",
      " [1 2 9]]\n",
      "tensor([[0.5291, 1.0033],\n",
      "        [0.0919, 0.1745]], device='cuda:0')\n",
      "tensor([[0.1526, 0.4871],\n",
      "        [0.0434, 0.1184]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "a = torch.tensor([\n",
    "    [2, 3, 5],\n",
    "    [1, 2, 9]\n",
    "])\n",
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "print(a.shape)\n",
    "\n",
    "a = np.array([\n",
    "    [2, 3, 5],\n",
    "    [1, 2, 9]\n",
    "])\n",
    "a = torch.from_numpy(a)\n",
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "print(a.cpu().numpy())\n",
    "\n",
    "a = torch.rand(size=(2, 2))\n",
    "b = torch.rand(size=(2, 2))\n",
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "    b = b.cuda()\n",
    "\n",
    "# Dot product\n",
    "print(torch.matmul(input=a, other=b))\n",
    "# Element-wise multiplication\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a848a83-a1ff-475d-9aad-ffc9051fe26d",
   "metadata": {
    "id": "0a848a83-a1ff-475d-9aad-ffc9051fe26d",
    "outputId": "4ce94c99-2be4-4527-8d24-9996d06e9345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "# Create a matrix of ones with shape 3 by 3\n",
    "a = torch.ones(size=(3, 3))\n",
    "# Create an identity matrix with shape 3 by 3\n",
    "b = torch.eye(n=3)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "    b = b.cuda()\n",
    "\n",
    "# Matrix multiplication of a with b\n",
    "c = torch.matmul(input=a, other=b)\n",
    "print(c)\n",
    "\n",
    "# Element-wise multiplication of a with b\n",
    "c = a * b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb01ca7-38cc-4131-aa2e-60ae7ebbab08",
   "metadata": {
    "id": "ebb01ca7-38cc-4131-aa2e-60ae7ebbab08"
   },
   "source": [
    "### Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ab482-3f6f-4d4b-a752-544f542f64e8",
   "metadata": {
    "id": "3a5ab482-3f6f-4d4b-a752-544f542f64e8",
    "outputId": "bc9c9ebd-103c-4b11-f25f-da8dc972f3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(125.1406, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "# Initialize tensors x, y and z\n",
    "x = torch.rand(size=(1000, 1000))\n",
    "y = torch.rand(size=(1000, 1000))\n",
    "z = torch.rand(size=(1000, 1000))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = z.cuda()\n",
    "\n",
    "# Multiply tensors x and y\n",
    "q = torch.matmul(input=x, other=y)\n",
    "# Element-wise multiply tensors z with q\n",
    "f = z * q\n",
    "mean_f = torch.mean(input=f)\n",
    "print(mean_f)\n",
    "# Calculate the gradients\n",
    "mean_f.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f3a8b-907f-4b08-86df-9d593b62073a",
   "metadata": {
    "id": "757f3a8b-907f-4b08-86df-9d593b62073a"
   },
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbb533-cdd6-46f2-940b-eb3a9afcc171",
   "metadata": {
    "id": "d1fbb533-cdd6-46f2-940b-eb3a9afcc171",
    "outputId": "a91c0436-bf3c-4ac4-8a4e-443e2dd7ba77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of z is: tensor(1.)\n",
      "Gradient of y is: tensor(5.)\n",
      "Gradient of x is: tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "# Initialize x, y and z to values 4, -3 and 5\n",
    "x = torch.tensor(4., requires_grad=True)\n",
    "y = torch.tensor(-3., requires_grad=True)\n",
    "z = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "# Set q to sum of x and y\n",
    "q = x + y\n",
    "# Set f to product of q with z\n",
    "f = q * z\n",
    "# Compute the derivatives\n",
    "f.backward()\n",
    "\n",
    "# Print the gradients\n",
    "print(\"Gradient of z is:\", z.grad)\n",
    "print(\"Gradient of y is:\", y.grad)\n",
    "print(\"Gradient of x is:\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc466d9-85d0-43f4-9480-138f85c3f1d5",
   "metadata": {
    "id": "9bc466d9-85d0-43f4-9480-138f85c3f1d5"
   },
   "source": [
    "### Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb446b-a562-43fa-897d-ec326acbd18b",
   "metadata": {
    "id": "0aeb446b-a562-43fa-897d-ec326acbd18b",
    "outputId": "f5f67e15-7392-4b03-a973-ecc5ff2a7020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21105.2676, 19629.4141, 18506.6523, 19196.1504, 19759.8438, 19620.8242,\n",
      "        19557.7090, 21682.9746, 19894.4688, 19432.3047], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "input_layer = torch.rand(784)\n",
    "# Initialize the weights of the neural network\n",
    "weight_1 = torch.rand(size=(784, 200))\n",
    "weight_2 = torch.rand(size=(200, 10))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_layer = input_layer.cuda()\n",
    "    weight_1 = weight_1.cuda()\n",
    "    weight_2 = weight_2.cuda()\n",
    "\n",
    "# Multiply input_layer with weight_1\n",
    "hidden_1 = torch.matmul(input=input_layer, other=weight_1)\n",
    "# Multiply hidden_1 with weight_2\n",
    "output_layer = torch.matmul(input=hidden_1, other=weight_2)\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed57599-bb2f-4d86-a165-4e6436146bc3",
   "metadata": {
    "id": "eed57599-bb2f-4d86-a165-4e6436146bc3",
    "outputId": "515a4616-55df-476c-b3ba-39a003714394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1113, -0.0151,  0.1005,  0.2801,  0.2317, -0.1189, -0.3775,  0.0440,\n",
      "         0.3325, -0.1394], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features=784, out_features=200)\n",
    "        self.fc2 = torch.nn.Linear(in_features=200, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # use the instantiated layers and return x\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_layer = torch.rand(784)\n",
    "net = Net()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_layer = input_layer.cuda()\n",
    "    net = net.cuda()\n",
    "\n",
    "result = net(input_layer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1322644-b072-4849-9d52-c49ecbf0abdc",
   "metadata": {
    "id": "d1322644-b072-4849-9d52-c49ecbf0abdc"
   },
   "source": [
    "## Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff8318-aca1-453b-b263-e8ca3ec6a293",
   "metadata": {
    "id": "c1ff8318-aca1-453b-b263-e8ca3ec6a293"
   },
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e4756-a1fe-4b1d-a9f1-58bd7a970dc0",
   "metadata": {
    "id": "596e4756-a1fe-4b1d-a9f1-58bd7a970dc0",
    "outputId": "7b1f2c5e-b38f-48d1-bed1-5660c38715c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2653, 0.1311, 3.8219, 3.0032]], device='cuda:0')\n",
      "tensor([[0.2653, 0.1311, 3.8219, 3.0032]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "input_layer = torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]])\n",
    "weight_1 = torch.tensor([\n",
    "    [-0.1094, -0.8285,  0.0416, -1.1222],\n",
    "    [ 0.3327, -0.0461,  1.4473, -0.8070],\n",
    "    [ 0.0681, -0.7058, -1.8017,  0.5857],\n",
    "    [ 0.8764,  0.9618, -0.4505,  0.2888]\n",
    "])\n",
    "weight_2 = torch.tensor([\n",
    "    [ 0.6856, -1.7650,  1.6375, -1.5759],\n",
    "    [-0.1092, -0.1620,  0.1951, -0.1169],\n",
    "    [-0.5120,  1.1997,  0.8483, -0.2476],\n",
    "    [-0.3369,  0.5617, -0.6658,  0.2221]\n",
    "])\n",
    "weight_3 = torch.tensor([\n",
    "    [ 0.8824,  0.1268,  1.1951,  1.3061],\n",
    "    [-0.8753, -0.3277, -0.1454, -0.0167],\n",
    "    [ 0.3582,  0.3254, -1.8509, -1.4205],\n",
    "    [ 0.3786,  0.5999, -0.5665, -0.3975]\n",
    "])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_layer = input_layer.cuda()\n",
    "    weight_1 = weight_1.cuda()\n",
    "    weight_2 = weight_2.cuda()\n",
    "    weight_3 = weight_3.cuda()\n",
    "\n",
    "# Calculate the first and second hidden layer\n",
    "hidden_1 = torch.matmul(input=input_layer, other=weight_1)\n",
    "hidden_2 = torch.matmul(input=hidden_1, other=weight_2)\n",
    "\n",
    "# Calculate the output\n",
    "print(torch.matmul(input=hidden_2, other=weight_3))\n",
    "\n",
    "# Calculate weight_composed_1 and weight\n",
    "weight_composed_1 = torch.matmul(input=weight_1, other=weight_2)\n",
    "weight = torch.matmul(input=weight_composed_1, other=weight_3)\n",
    "\n",
    "# Multiply input_layer with weight\n",
    "print(torch.matmul(input_layer, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ab98e-aa3c-49eb-9f0e-aaaab8109407",
   "metadata": {
    "id": "698ab98e-aa3c-49eb-9f0e-aaaab8109407",
    "outputId": "1bcccd68-2d47-4e9c-d762-e6fc4e1fe861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2770, -0.0345, -0.1410, -0.0664]], device='cuda:0')\n",
      "tensor([[-0.2117, -0.4782,  4.0438,  3.0417]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "input_layer = torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]])\n",
    "weight_1 = torch.tensor([\n",
    "    [-0.1094, -0.8285,  0.0416, -1.1222],\n",
    "    [ 0.3327, -0.0461,  1.4473, -0.8070],\n",
    "    [ 0.0681, -0.7058, -1.8017,  0.5857],\n",
    "    [ 0.8764,  0.9618, -0.4505,  0.2888]\n",
    "])\n",
    "weight_2 = torch.tensor([\n",
    "    [ 0.6856, -1.7650,  1.6375, -1.5759],\n",
    "    [-0.1092, -0.1620,  0.1951, -0.1169],\n",
    "    [-0.5120,  1.1997,  0.8483, -0.2476],\n",
    "    [-0.3369,  0.5617, -0.6658,  0.2221]\n",
    "])\n",
    "weight_3 = torch.tensor([\n",
    "    [ 0.8824,  0.1268,  1.1951,  1.3061],\n",
    "    [-0.8753, -0.3277, -0.1454, -0.0167],\n",
    "    [ 0.3582,  0.3254, -1.8509, -1.4205],\n",
    "    [ 0.3786,  0.5999, -0.5665, -0.3975]\n",
    "])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_layer = input_layer.cuda()\n",
    "    weight_1 = weight_1.cuda()\n",
    "    weight_2 = weight_2.cuda()\n",
    "    weight_3 = weight_3.cuda()\n",
    "\n",
    "# Instantiate non-linearity\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "# Apply non-linearity on hidden_1 and hidden_2\n",
    "hidden_1_activated = relu(torch.matmul(\n",
    "    input=input_layer, other=weight_1\n",
    "))\n",
    "hidden_2_activated = relu(torch.matmul(\n",
    "    input=hidden_1_activated, other=weight_2\n",
    "))\n",
    "print(torch.matmul(input=hidden_2_activated, other=weight_3))\n",
    "\n",
    "# Apply non-linearity to the product of first two weights.\n",
    "weight_composed_1_activated = relu(torch.matmul(\n",
    "    input=weight_1, other=weight_2\n",
    "))\n",
    "# Multiply `weight_composed_1_activated` with `weight_3\n",
    "weight = torch.matmul(input=weight_composed_1_activated, other=weight_3)\n",
    "# Multiply input_layer with weight\n",
    "print(torch.matmul(input=input_layer, other=weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a4cbd-19b3-43b3-a22b-bcd236424cd6",
   "metadata": {
    "id": "269a4cbd-19b3-43b3-a22b-bcd236424cd6"
   },
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0cc59-11ad-4364-bf1e-306ea099d01f",
   "metadata": {
    "id": "48d0cc59-11ad-4364-bf1e-306ea099d01f",
    "outputId": "c5f63010-f940-469a-fb9d-8f93ec0ccc21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0117, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "# Initialize the scores and ground truth\n",
    "logits = torch.tensor([[-1.2, 0.12, 4.8]])\n",
    "ground_truth = torch.tensor([2])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logits = logits.cuda()\n",
    "    ground_truth = ground_truth.cuda()\n",
    "\n",
    "# Instantiate cross entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute and print the loss\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a59e05-5553-4ab4-a7e8-f185072bbb6c",
   "metadata": {
    "id": "f6a59e05-5553-4ab4-a7e8-f185072bbb6c"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02654a5-d7c9-4d59-a3c6-2cdd80039068",
   "metadata": {
    "id": "b02654a5-d7c9-4d59-a3c6-2cdd80039068",
    "outputId": "13d7a961-36aa-4cf3-defe-3dcfa4cbb613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
      "32 32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "import torchvision\n",
    "\n",
    "# Transform the data to torch tensors and normalize it\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=0.1307, std=0.3081)\n",
    "])\n",
    "\n",
    "# Prepare training set and testing set\n",
    "trainset = torchvision.datasets.MNIST(root='./data',\n",
    "    train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data',\n",
    "    train=False, download=True, transform=transform)\n",
    "\n",
    "# Prepare training loader and testing loader\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "    batch_size=32, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset,\n",
    "    batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Compute the shape of the training set and testing set\n",
    "trainset_shape = trainloader.dataset.data.shape\n",
    "testset_shape = testloader.dataset.data.shape\n",
    "# Print the computed shapes\n",
    "print(trainset_shape, testset_shape)\n",
    "\n",
    "# Compute the size of the minibatch for training set and testing set\n",
    "trainset_batchsize = trainloader.batch_size\n",
    "testset_batchsize = testloader.batch_size\n",
    "# Print sizes of the minibatch\n",
    "print(trainset_batchsize, testset_batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36166669-5f24-456e-8797-bd36507e18be",
   "metadata": {
    "id": "36166669-5f24-456e-8797-bd36507e18be"
   },
   "source": [
    "### Training neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66d826-59ff-498c-88a1-8a6a2bbfdf21",
   "metadata": {
    "id": "fc66d826-59ff-498c-88a1-8a6a2bbfdf21",
    "outputId": "2db605fb-662a-4d9b-ae7a-0363daca0a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 98 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "# Define the class Net\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "    \t# Define all the parameters of the net\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features=28 * 28 * 1, out_features=200)\n",
    "        self.fc2 = torch.nn.Linear(in_features=200, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \t# Do the forward pass\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the network, the Adam optimizer and Cross-Entropy loss function\n",
    "model = Net()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Loop over the dataset multiple times\n",
    "for epoch in range(10):\n",
    "    for data in trainloader:\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        inputs = inputs.view(-1, 28 * 28)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Complete a forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Compute the loss, gradients and change the weights\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Set the model in eval mode\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "for data in testloader:\n",
    "    inputs, labels = data\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "    # Put each image into a vector\n",
    "    inputs = inputs.view(-1, 28 * 28)\n",
    "    # Do the forward pass and get the predictions\n",
    "    outputs = model(inputs)\n",
    "    _, outputs = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (outputs==labels).sum().item()\n",
    "print('The testing set accuracy of the network is: %d %%'\n",
    "    %(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf9e33-6368-4f9c-b405-8fdf309be532",
   "metadata": {
    "id": "0cbf9e33-6368-4f9c-b405-8fdf309be532"
   },
   "source": [
    "## Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb281f25-135b-41a1-b20b-ea7c8461795c",
   "metadata": {
    "id": "eb281f25-135b-41a1-b20b-ea7c8461795c"
   },
   "source": [
    "### Convolution operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07140ea4-dfa2-4a18-910d-d429fabf8986",
   "metadata": {
    "id": "07140ea4-dfa2-4a18-910d-d429fabf8986",
    "outputId": "2f441d74-4c71-44a4-a78e-ef314d2133ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "# Create 10 random images of shape (1, 28, 28)\n",
    "images = torch.rand(size=(10, 1, 28, 28))\n",
    "\n",
    "# Build 6 conv. filters\n",
    "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6,\n",
    "    kernel_size=(3, 3), stride=1, padding=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    images = images.cuda()\n",
    "    conv_filters = conv_filters.cuda()\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = conv_filters(images)\n",
    "print(output_feature.shape)\n",
    "\n",
    "# Create 6 filters\n",
    "filters = torch.rand(size=(6, 1, 3, 3))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    filters = filters.cuda()\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = torch.nn.functional.conv2d(input=images,\n",
    "    weight=filters, stride=1, padding=1)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18456cc8-8c0a-47a4-8516-aeb156cc2bb6",
   "metadata": {
    "id": "18456cc8-8c0a-47a4-8516-aeb156cc2bb6"
   },
   "source": [
    "### Pooling operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18418e8a-49ca-4427-afa5-f345be193acb",
   "metadata": {
    "id": "18418e8a-49ca-4427-afa5-f345be193acb",
    "outputId": "1ec5ba97-7db4-4ffd-aa24-6b30d3737b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 1, 6, 6])\n",
      "tensor([[[[8., 5., 9.],\n",
      "          [9., 2., 6.],\n",
      "          [2., 9., 8.]]]], device='cuda:0')\n",
      "tensor([[[[8., 5., 9.],\n",
      "          [9., 2., 6.],\n",
      "          [2., 9., 8.]]]], device='cuda:0')\n",
      "tensor([[[[ 3.7500,  0.5000,  5.0000],\n",
      "          [ 3.5000, -1.0000,  3.7500],\n",
      "          [-0.2500,  4.2500,  0.5000]]]], device='cuda:0')\n",
      "tensor([[[[ 3.7500,  0.5000,  5.0000],\n",
      "          [ 3.5000, -1.0000,  3.7500],\n",
      "          [-0.2500,  4.2500,  0.5000]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "im = torch.tensor([[[\n",
    "    [ 8.,  1.,  2.,  5.,  3.,  1.],\n",
    "    [ 6.,  0.,  0., -5.,  7.,  9.],\n",
    "    [ 1.,  9., -1., -2.,  2.,  6.],\n",
    "    [ 0.,  4.,  2., -3.,  4.,  3.],\n",
    "    [ 2., -1.,  4., -1., -2.,  3.],\n",
    "    [ 2., -4.,  5.,  9., -7.,  8.]]]\n",
    "])\n",
    "if torch.cuda.is_available():\n",
    "    im = im.cuda()\n",
    "print(f\"Image size: {im.shape}\")\n",
    "# Build a pooling operator with size `2`.\n",
    "max_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
    "if torch.cuda.is_available():\n",
    "    max_pooling = max_pooling.cuda()\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = max_pooling(im)\n",
    "# print the results\n",
    "print(output_feature)\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = torch.nn.functional.max_pool2d(\n",
    "    input=im, kernel_size=(2, 2))\n",
    "# print the results\n",
    "print(output_feature_F)\n",
    "\n",
    "# Build a pooling operator with size `2`.\n",
    "avg_pooling = torch.nn.AvgPool2d(kernel_size=(2, 2))\n",
    "if torch.cuda.is_available():\n",
    "    avg_pooling = avg_pooling.cuda()\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = avg_pooling(im)\n",
    "# print the results\n",
    "print(output_feature)\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = torch.nn.functional.avg_pool2d(\n",
    "    input=im, kernel_size=(2, 2))\n",
    "# print the results\n",
    "print(output_feature_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1076214-00f1-411b-a4e5-6741b0b092cf",
   "metadata": {
    "id": "c1076214-00f1-411b-a4e5-6741b0b092cf"
   },
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf439cc3-d0cc-44be-8c7a-11a98dc33694",
   "metadata": {
    "id": "bf439cc3-d0cc-44be-8c7a-11a98dc33694"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=5,\n",
    "            kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=5, out_channels=10,\n",
    "            kernel_size=(3, 3), padding=1)\n",
    "        # Instantiate a max pooling layer\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = torch.nn.Linear(in_features=7*7*10,\n",
    "            out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        # Prepare the image for the fully connected layer\n",
    "        x = x.view(-1, 7 * 7 * 10)\n",
    "        # Apply the fully connected layer and return the result\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060790ea-5f0a-4ffe-b910-226ca8b23c3f",
   "metadata": {
    "id": "060790ea-5f0a-4ffe-b910-226ca8b23c3f"
   },
   "source": [
    "### Training Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29258db-4217-487f-8f9a-69558caf83cf",
   "metadata": {
    "id": "f29258db-4217-487f-8f9a-69558caf83cf",
    "outputId": "fb62806e-5ba2-4bd3-d306-7287bf371856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Finished training\n",
      "The testing set accuracy of the network is: 70%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
    "    train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "    batch_size=128, shuffle=True, num_workers=4)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',\n",
    "    train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset,\n",
    "    batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=32,\n",
    "            kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64,\n",
    "            kernel_size=(3, 3), padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=64, out_channels=128,\n",
    "            kernel_size=(3, 3), padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.fc = torch.nn.Linear(in_features=128*4*4,\n",
    "            out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128*4*4)\n",
    "        return self.fc(x)\n",
    "\n",
    "net = Net()\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=3e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for data in trainloader:\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the forward pass\n",
    "        outputs = net(inputs)\n",
    "        # Compute the loss function\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "print(\"Finished training\")\n",
    "\n",
    "correct, total = 0, 0\n",
    "net.eval()\n",
    "# Iterate over the data in the test_loader\n",
    "for data in testloader:\n",
    "    # Get the image and label from data\n",
    "    inputs, labels = data\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "    # Make a forward pass in the net with inputs\n",
    "    outputs = net(inputs)\n",
    "    # Argmax the results of the net\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "\n",
    "print(\"The testing set accuracy of the network is: %d%%\"\n",
    "    %(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e45d1-e2fb-4cdb-ab00-c3044ce4e487",
   "metadata": {
    "id": "3c6e45d1-e2fb-4cdb-ab00-c3044ce4e487"
   },
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46b460-d18d-4af7-a368-5a8f07251281",
   "metadata": {
    "id": "ad46b460-d18d-4af7-a368-5a8f07251281"
   },
   "source": [
    "### Sequential module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3b1f0a-6569-4e5e-a671-f33e334364c0",
   "metadata": {
    "id": "fe3b1f0a-6569-4e5e-a671-f33e334364c0",
    "outputId": "80d5c68e-c0e9-41f8-abdd-ce5b73988276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set accuracy of the network is: 98 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=0.1307, std=0.3081)\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data',\n",
    "    train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "    batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data',\n",
    "    train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset,\n",
    "    batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Declare all the layers for feature extraction\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=5,\n",
    "                kernel_size=(3, 3), padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(in_channels=5, out_channels=10,\n",
    "                kernel_size=(3, 3), padding=1),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(in_channels=10, out_channels=20,\n",
    "                kernel_size=(3, 3), padding=1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(in_channels=20, out_channels=40,\n",
    "                kernel_size=(3, 3), padding=1),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Declare all the layers for classification\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=7*7*40, out_features=1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(in_features=1024, out_features=2048),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(in_features=2048, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the feature extractor in the input\n",
    "        x = self.features(x)\n",
    "        # Squeeze the three spatial dimensions in one\n",
    "        x = x.view(-1, 7*7*40)\n",
    "        # Classify the images\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "for data in testloader:\n",
    "    inputs, labels = data\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "    outputs = model(inputs)\n",
    "    _, predicts = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicts==labels).sum().item()\n",
    "\n",
    "print(\"The test set accuracy of the network is: %d %%\"\n",
    "    %(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19b843-3c30-4157-9512-742e78cd967d",
   "metadata": {
    "id": "8b19b843-3c30-4157-9512-742e78cd967d"
   },
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aecf6c2-0253-4d56-b387-368c5aace1ca",
   "metadata": {
    "id": "1aecf6c2-0253-4d56-b387-368c5aace1ca"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "import torchvision\n",
    "\n",
    "# Shuffle the indices\n",
    "indices = np.arange(60000)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=0.1307, std=0.3081)\n",
    "])\n",
    "trainset = torchvision.datasets.MNIST(root='./data',\n",
    "    train=True, download=True, transform=transform)\n",
    "\n",
    "# Build the train loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "    batch_size=64, shuffle=False, num_workers=4,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n",
    "\n",
    "# Build the validation loader\n",
    "val_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "    batch_size=64, shuffle=False, num_workers=4,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(indices[55000:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776082f-40fb-4dfe-8d44-b4bf51fd5999",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2308784e-6388-4c8a-bef7-f39cbb4d5d11",
   "metadata": {
    "id": "2308784e-6388-4c8a-bef7-f39cbb4d5d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy: 98%\n",
      "The validation accuracy: 98%\n",
      "The validation accuracy: 98%\n",
      "The validation accuracy: 98%\n",
      "The validation accuracy: 98%\n",
      "The validation accuracy: 98%\n",
      "The validation accuracy: 98%\n",
      "The validation accuracy: 98%\n",
      "The validation accuracy: 98%\n",
      "The validation accuracy: 99%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Implement the sequential module for feature extraction\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=10,\n",
    "                kernel_size=(3, 3), stride=1, padding=1),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.BatchNorm2d(num_features=10),\n",
    "            torch.nn.Conv2d(in_channels=10, out_channels=20,\n",
    "                kernel_size=(3, 3), stride=1, padding=1),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.BatchNorm2d(num_features=20)\n",
    "        )\n",
    "        \n",
    "        # Implement the fully connected layer for classification\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=7*7*20, out_features=200),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(in_features=200, out_features=500),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(in_features=500, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "    \t# Do the forward pass\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 7*7*20)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Instantiate the network\n",
    "model = Net(num_classes=10)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "# Instantiate the cross-entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Instantiate the Adam optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "        lr=3e-4, weight_decay=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Set the net in evaluation mode\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "        _, predicts = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicts==labels).sum().item()\n",
    "    print(\"The validation accuracy: %d%%\" %(100*correct/total))\n",
    "    # Set the net in train mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8bf801-fe86-46a8-8cd8-eade666bf44e",
   "metadata": {
    "id": "eadb8c9e-5cf1-426c-9404-ff9c4593f96a"
   },
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb8572-9ca6-4cc9-8bd0-d90156588676",
   "metadata": {
    "id": "60bb8572-9ca6-4cc9-8bd0-d90156588676"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "# Instantiate the model\n",
    "model = Net()\n",
    "# Load the parameters from the old model\n",
    "model.load_state_dict(torch.load('my_net.pth'))\n",
    "# Freeze all the layers except the final one\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Change the number of out channels\n",
    "model.fc = torch.nn.Linear(in_features=7*7*512, out_features=26)\n",
    "# Train and evaluate the model\n",
    "model.train()\n",
    "train_net(model, optimizer, criterion)\n",
    "print(\"Accuracy of the net is:\", str(model.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253eb589-7b74-4b2e-9fa3-f57b6f6cfa64",
   "metadata": {
    "id": "253eb589-7b74-4b2e-9fa3-f57b6f6cfa64"
   },
   "outputs": [],
   "source": [
    "# Import the module\n",
    "import torch\n",
    "torch.manual_seed(seed=0)\n",
    "import torchvision\n",
    "\n",
    "# Download resnet18\n",
    "model = torchvision.models.resnet18(weights=\"DEFAULT\")\n",
    "# Freeze all the layers bar the last one\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Change the number of output units\n",
    "model.fc = torch.nn.Linear(in_features=512, out_features=7)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
