{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/PyTorch/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9345dba2-8479-4fd3-968e-b65491f0560f",
      "metadata": {
        "id": "9345dba2-8479-4fd3-968e-b65491f0560f"
      },
      "source": [
        "# Deep Learning with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install --no-cache-dir -qU \\\n",
        "    torchmetrics"
      ],
      "metadata": {
        "id": "c3sfUqaY4SOr"
      },
      "id": "c3sfUqaY4SOr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "252bceaf-3fca-473a-9133-575bfbb61bd9",
      "metadata": {
        "id": "252bceaf-3fca-473a-9133-575bfbb61bd9"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed82204-3d43-4698-8031-226c73d6eeb0",
      "metadata": {
        "id": "3ed82204-3d43-4698-8031-226c73d6eeb0"
      },
      "source": [
        "### Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d14b1f38-ff5c-490e-bfa6-469efa637450",
      "metadata": {
        "id": "d14b1f38-ff5c-490e-bfa6-469efa637450",
        "outputId": "8cf19d28-5081-4b30-9be6-6049545588fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "[[2 3 5]\n",
            " [1 2 9]]\n",
            "tensor([[0.5792, 1.2563],\n",
            "        [0.3956, 0.9914]], device='cuda:0')\n",
            "tensor([[0.3445, 0.5498],\n",
            "        [0.0982, 0.7613]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(seed=42)\n",
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "a = torch.tensor([\n",
        "    [2, 3, 5],\n",
        "    [1, 2, 9]\n",
        "])\n",
        "if torch.cuda.is_available():\n",
        "    a = a.cuda()\n",
        "print(a.shape)\n",
        "\n",
        "a = np.array([\n",
        "    [2, 3, 5],\n",
        "    [1, 2, 9]\n",
        "])\n",
        "a = torch.tensor(a)\n",
        "if torch.cuda.is_available():\n",
        "    a = a.cuda()\n",
        "print(a.cpu().numpy())\n",
        "\n",
        "a = torch.rand(size=(2, 2))\n",
        "b = torch.rand(size=(2, 2))\n",
        "if torch.cuda.is_available():\n",
        "    a = a.cuda()\n",
        "    b = b.cuda()\n",
        "\n",
        "# Dot product\n",
        "print(torch.matmul(input=a, other=b))\n",
        "# Element-wise multiplication\n",
        "print(a * b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a848a83-a1ff-475d-9aad-ffc9051fe26d",
      "metadata": {
        "id": "0a848a83-a1ff-475d-9aad-ffc9051fe26d",
        "outputId": "4ce94c99-2be4-4527-8d24-9996d06e9345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], device='cuda:0')\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "# Create a matrix of ones with shape 3 by 3\n",
        "a = torch.ones(size=(3, 3))\n",
        "# Create an identity matrix with shape 3 by 3\n",
        "b = torch.eye(n=3)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    a = a.cuda()\n",
        "    b = b.cuda()\n",
        "\n",
        "# Matrix multiplication of a with b\n",
        "c = torch.matmul(input=a, other=b)\n",
        "print(c)\n",
        "\n",
        "# Element-wise multiplication of a with b\n",
        "c = a * b\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb01ca7-38cc-4131-aa2e-60ae7ebbab08",
      "metadata": {
        "id": "ebb01ca7-38cc-4131-aa2e-60ae7ebbab08"
      },
      "source": [
        "### Forward propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a5ab482-3f6f-4d4b-a752-544f542f64e8",
      "metadata": {
        "id": "3a5ab482-3f6f-4d4b-a752-544f542f64e8",
        "outputId": "bc9c9ebd-103c-4b11-f25f-da8dc972f3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(125.1406, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "# Initialize tensors x, y and z\n",
        "x = torch.rand(size=(1000, 1000))\n",
        "y = torch.rand(size=(1000, 1000))\n",
        "z = torch.rand(size=(1000, 1000))\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    z = z.cuda()\n",
        "\n",
        "# Multiply tensors x and y\n",
        "q = torch.matmul(input=x, other=y)\n",
        "# Element-wise multiply tensors z with q\n",
        "f = z * q\n",
        "mean_f = torch.mean(input=f)\n",
        "print(mean_f)\n",
        "# Calculate the gradients\n",
        "mean_f.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "757f3a8b-907f-4b08-86df-9d593b62073a",
      "metadata": {
        "id": "757f3a8b-907f-4b08-86df-9d593b62073a"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fbb533-cdd6-46f2-940b-eb3a9afcc171",
      "metadata": {
        "id": "d1fbb533-cdd6-46f2-940b-eb3a9afcc171",
        "outputId": "a91c0436-bf3c-4ac4-8a4e-443e2dd7ba77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of z is: tensor(1.)\n",
            "Gradient of y is: tensor(5.)\n",
            "Gradient of x is: tensor(5.)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "# Initialize x, y and z to values 4, -3 and 5\n",
        "x = torch.tensor(4., requires_grad=True)\n",
        "y = torch.tensor(-3., requires_grad=True)\n",
        "z = torch.tensor(5., requires_grad=True)\n",
        "\n",
        "# Set q to sum of x and y\n",
        "q = x + y\n",
        "# Set f to product of q with z\n",
        "f = q * z\n",
        "# Compute the derivatives\n",
        "f.backward()\n",
        "\n",
        "# Print the gradients\n",
        "print(\"Gradient of z is:\", z.grad)\n",
        "print(\"Gradient of y is:\", y.grad)\n",
        "print(\"Gradient of x is:\", x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc466d9-85d0-43f4-9480-138f85c3f1d5",
      "metadata": {
        "id": "9bc466d9-85d0-43f4-9480-138f85c3f1d5"
      },
      "source": [
        "### Neural networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed57599-bb2f-4d86-a165-4e6436146bc3",
      "metadata": {
        "id": "eed57599-bb2f-4d86-a165-4e6436146bc3",
        "outputId": "515a4616-55df-476c-b3ba-39a003714394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: tensor([-0.1113, -0.0151,  0.1005,  0.2801,  0.2317, -0.1189, -0.3775,  0.0440,\n",
            "         0.3325, -0.1394], device='cuda:0', grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(in_features=784, out_features=200)\n",
        "        self.fc2 = torch.nn.Linear(in_features=200, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # use the instantiated layers and return x\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "input_layer = torch.rand(784)\n",
        "net = Net()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    input_layer = input_layer.cuda()\n",
        "    net = net.cuda()\n",
        "\n",
        "result = net(input_layer)\n",
        "print(\"Result:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1322644-b072-4849-9d52-c49ecbf0abdc",
      "metadata": {
        "id": "d1322644-b072-4849-9d52-c49ecbf0abdc"
      },
      "source": [
        "## Artificial Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1ff8318-aca1-453b-b263-e8ca3ec6a293",
      "metadata": {
        "id": "c1ff8318-aca1-453b-b263-e8ca3ec6a293"
      },
      "source": [
        "### Activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "698ab98e-aa3c-49eb-9f0e-aaaab8109407",
      "metadata": {
        "id": "698ab98e-aa3c-49eb-9f0e-aaaab8109407",
        "outputId": "d5a88a6f-3086-4e36-e64c-b5807526a4eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-5.0533,  7.3178, -4.4011, -3.3757]], device='cuda:0')\n",
            "tensor([[ 2.4246,  2.0822,  0.2086, -3.6637]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "input_layer = torch.tensor([[0.0401, -0.9005,  0.0397, -0.0876]])\n",
        "weight_1 = torch.randn(size=(4, 4))\n",
        "weight_2 = torch.randn(size=(4, 4))\n",
        "weight_3 = torch.randn(size=(4, 4))\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    input_layer = input_layer.cuda()\n",
        "    weight_1 = weight_1.cuda()\n",
        "    weight_2 = weight_2.cuda()\n",
        "    weight_3 = weight_3.cuda()\n",
        "\n",
        "# Instantiate non-linearity\n",
        "relu = torch.nn.ReLU()\n",
        "\n",
        "# Apply non-linearity on hidden_1 and hidden_2\n",
        "hidden_1_activated = relu(\n",
        "    torch.matmul(input=input_layer, other=weight_1)\n",
        ")\n",
        "hidden_2_activated = relu(\n",
        "    torch.matmul(input=hidden_1_activated, other=weight_2)\n",
        ")\n",
        "print(torch.matmul(input=hidden_2_activated, other=weight_3))\n",
        "\n",
        "# Apply non-linearity to the product of first two weights.\n",
        "weight_composed_1_activated = relu(\n",
        "    torch.matmul(input=weight_1, other=weight_2)\n",
        ")\n",
        "# Multiply `weight_composed_1_activated` with `weight_3\n",
        "weight = torch.matmul(input=weight_composed_1_activated, other=weight_3)\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(input=input_layer, other=weight))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "269a4cbd-19b3-43b3-a22b-bcd236424cd6",
      "metadata": {
        "id": "269a4cbd-19b3-43b3-a22b-bcd236424cd6"
      },
      "source": [
        "### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "48d0cc59-11ad-4364-bf1e-306ea099d01f",
      "metadata": {
        "id": "48d0cc59-11ad-4364-bf1e-306ea099d01f",
        "outputId": "d88a44df-ccdf-4e15-f7f1-26b9616152e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0117, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "# Initialize the scores and ground truth\n",
        "logits = torch.tensor([[-1.2, 0.12, 4.8]])\n",
        "ground_truth = torch.tensor([2])\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    logits = logits.cuda()\n",
        "    ground_truth = ground_truth.cuda()\n",
        "\n",
        "# Instantiate cross entropy loss\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Compute and print the loss\n",
        "loss = criterion(input=logits, target=ground_truth)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a59e05-5553-4ab4-a7e8-f185072bbb6c",
      "metadata": {
        "id": "f6a59e05-5553-4ab4-a7e8-f185072bbb6c"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc66d826-59ff-498c-88a1-8a6a2bbfdf21",
      "metadata": {
        "id": "fc66d826-59ff-498c-88a1-8a6a2bbfdf21",
        "outputId": "257db721-1384-4b3b-c67b-eb5e36e3bbb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([60000, 28, 28]) \n",
            "Test dataset shape: torch.Size([10000, 28, 28])\n",
            "Train dataset targets: tensor([5, 0, 4,  ..., 5, 6, 8]) \n",
            "Test dataset targets: tensor([7, 2, 1,  ..., 4, 5, 6])\n",
            "Train dataset batch size: 32 \n",
            "Test dataset batch size: 32\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "import torchvision\n",
        "import torchmetrics\n",
        "\n",
        "# Transform the data to torch tensors and normalize it\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=0.1307, std=0.3081)\n",
        "])\n",
        "# Prepare training set and testing set\n",
        "trainset = torchvision.datasets.MNIST(root='./data',\n",
        "    train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data',\n",
        "    train=False, download=True, transform=transform)\n",
        "\n",
        "# Prepare training loader and testing loader\n",
        "trainloader = torch.utils.data.DataLoader(dataset=trainset,\n",
        "    batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(dataset=testset,\n",
        "    batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Compute the shape of the training set and testing set\n",
        "trainset_shape = trainloader.dataset.data.shape\n",
        "testset_shape = testloader.dataset.data.shape\n",
        "# Print the computed shapes\n",
        "print(\"Train dataset shape:\", trainset_shape,\n",
        "    \"\\nTest dataset shape:\", testset_shape)\n",
        "\n",
        "# Compute the targets of the training set and testing set\n",
        "trainset_targets = trainloader.dataset.targets\n",
        "testset_targets = testloader.dataset.targets\n",
        "# Print the computed shapes\n",
        "print(\"Train dataset targets:\", trainset_targets,\n",
        "    \"\\nTest dataset targets:\", testset_targets)\n",
        "\n",
        "# Compute the size of the minibatch for training set and testing set\n",
        "trainset_batchsize = trainloader.batch_size\n",
        "testset_batchsize = testloader.batch_size\n",
        "# Print sizes of the minibatch\n",
        "print(\"Train dataset batch size:\", trainset_batchsize,\n",
        "    \"\\nTest dataset batch size:\", testset_batchsize)\n",
        "\n",
        "# Define the class Net\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "    \t# Define all the parameters of the net\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(in_features=28*28*1, out_features=200)\n",
        "        self.dropout = torch.nn.Dropout(p=0.3)\n",
        "        self.fc2 = torch.nn.Linear(in_features=200, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "    \t# Do the forward pass\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the network, the Adam optimizer and Cross-Entropy loss function\n",
        "model = Net()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),\n",
        "    lr=3e-4, weight_decay=1e-4)\n",
        "# Create accuracy metric\n",
        "acc = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    acc = acc.cuda()\n",
        "\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'valid_loss': [],\n",
        "    'valid_acc': []\n",
        "}\n",
        "\n",
        "# Loop over the dataset multiple times\n",
        "for epoch in range(10):\n",
        "    train_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        # Get the inputs\n",
        "        features, target = data\n",
        "        features = features.view(-1, 28*28)\n",
        "        if torch.cuda.is_available():\n",
        "            features = features.cuda()\n",
        "            target = target.cuda()\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Complete a forward pass\n",
        "        preds = model(features)\n",
        "        # Calculate accuracy over the batch\n",
        "        acc(preds=preds, target=target)\n",
        "        # Compute the loss, gradients and change the weights\n",
        "        loss = criterion(input=preds, target=target)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # Calculate the mean loss value\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    # Calculate accuracy over the whole epoch\n",
        "    train_acc = acc.compute().item()\n",
        "    # Reset the metric\n",
        "    acc.reset()\n",
        "\n",
        "    valid_loss = 0.0\n",
        "    # Set the model in eval mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            features, target = data\n",
        "            # Put each image into a vector\n",
        "            features = features.view(-1, 28*28)\n",
        "            if torch.cuda.is_available():\n",
        "                features = features.cuda()\n",
        "                target = target.cuda()\n",
        "            # Do the forward pass and get the predictions\n",
        "            preds = model(features)\n",
        "            # Calculate accuracy over the batch\n",
        "            acc(preds=preds, target=target)\n",
        "            # Compute the loss\n",
        "            loss = criterion(input=preds, target=target)\n",
        "            valid_loss += loss.item()\n",
        "    # Calculate the mean loss value\n",
        "    valid_loss = valid_loss / len(testloader)\n",
        "    # Calculate accuracy over the whole epoch\n",
        "    valid_acc = acc.compute().item()\n",
        "    # Reset the metric\n",
        "    acc.reset()\n",
        "    # Set the model back to training mode\n",
        "    model.train()\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['valid_loss'].append(valid_loss)\n",
        "    history['valid_acc'].append(valid_acc)\n",
        "\n",
        "df_history = pd.DataFrame(history)\n",
        "metrics = ['loss', 'acc']\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "for ax, metric in zip(axes, metrics):\n",
        "    sns.lineplot(ax=ax, data=df_history, label='train',\n",
        "        x=df_history.index+1, y=f'train_{metric}')\n",
        "    try:\n",
        "        sns.lineplot(ax=ax, data=df_history, label='valid',\n",
        "            x=df_history.index+1, y=f'valid_{metric}')\n",
        "    except Exception:\n",
        "        pass\n",
        "    ax.legend(loc='best')\n",
        "    ax.set_xlabel(xlabel='epoch')\n",
        "    ax.set_ylabel(ylabel=f'{metric}')\n",
        "    ax.set_title(label=f'{metric} vs. epoch')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cbf9e33-6368-4f9c-b405-8fdf309be532",
      "metadata": {
        "id": "0cbf9e33-6368-4f9c-b405-8fdf309be532"
      },
      "source": [
        "## Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb281f25-135b-41a1-b20b-ea7c8461795c",
      "metadata": {
        "id": "eb281f25-135b-41a1-b20b-ea7c8461795c"
      },
      "source": [
        "### Convolution operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07140ea4-dfa2-4a18-910d-d429fabf8986",
      "metadata": {
        "id": "07140ea4-dfa2-4a18-910d-d429fabf8986",
        "outputId": "2f441d74-4c71-44a4-a78e-ef314d2133ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 6, 28, 28])\n",
            "torch.Size([10, 6, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "# Create 10 random images of shape (1, 28, 28)\n",
        "images = torch.rand(size=(10, 1, 28, 28))\n",
        "\n",
        "# Build 6 conv. filters\n",
        "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6,\n",
        "    kernel_size=(3, 3), stride=1, padding=1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    images = images.cuda()\n",
        "    conv_filters = conv_filters.cuda()\n",
        "\n",
        "# Convolve the image with the filters\n",
        "output_feature = conv_filters(images)\n",
        "print(output_feature.shape)\n",
        "\n",
        "# Create 6 filters\n",
        "filters = torch.rand(size=(6, 1, 3, 3))\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    filters = filters.cuda()\n",
        "\n",
        "# Convolve the image with the filters\n",
        "output_feature = torch.nn.functional.conv2d(input=images,\n",
        "    weight=filters, stride=1, padding=1)\n",
        "print(output_feature.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18456cc8-8c0a-47a4-8516-aeb156cc2bb6",
      "metadata": {
        "id": "18456cc8-8c0a-47a4-8516-aeb156cc2bb6"
      },
      "source": [
        "### Pooling operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18418e8a-49ca-4427-afa5-f345be193acb",
      "metadata": {
        "id": "18418e8a-49ca-4427-afa5-f345be193acb",
        "outputId": "1ec5ba97-7db4-4ffd-aa24-6b30d3737b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image size: torch.Size([1, 1, 6, 6])\n",
            "tensor([[[[8., 5., 9.],\n",
            "          [9., 2., 6.],\n",
            "          [2., 9., 8.]]]], device='cuda:0')\n",
            "tensor([[[[8., 5., 9.],\n",
            "          [9., 2., 6.],\n",
            "          [2., 9., 8.]]]], device='cuda:0')\n",
            "tensor([[[[ 3.7500,  0.5000,  5.0000],\n",
            "          [ 3.5000, -1.0000,  3.7500],\n",
            "          [-0.2500,  4.2500,  0.5000]]]], device='cuda:0')\n",
            "tensor([[[[ 3.7500,  0.5000,  5.0000],\n",
            "          [ 3.5000, -1.0000,  3.7500],\n",
            "          [-0.2500,  4.2500,  0.5000]]]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=0)\n",
        "\n",
        "im = torch.tensor([[[\n",
        "    [ 8.,  1.,  2.,  5.,  3.,  1.],\n",
        "    [ 6.,  0.,  0., -5.,  7.,  9.],\n",
        "    [ 1.,  9., -1., -2.,  2.,  6.],\n",
        "    [ 0.,  4.,  2., -3.,  4.,  3.],\n",
        "    [ 2., -1.,  4., -1., -2.,  3.],\n",
        "    [ 2., -4.,  5.,  9., -7.,  8.]]]\n",
        "])\n",
        "if torch.cuda.is_available():\n",
        "    im = im.cuda()\n",
        "print(f\"Image size: {im.shape}\")\n",
        "# Build a pooling operator with size `2`.\n",
        "max_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "if torch.cuda.is_available():\n",
        "    max_pooling = max_pooling.cuda()\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = max_pooling(im)\n",
        "# print the results\n",
        "print(output_feature)\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = torch.nn.functional.max_pool2d(\n",
        "    input=im, kernel_size=(2, 2))\n",
        "# print the results\n",
        "print(output_feature_F)\n",
        "\n",
        "# Build a pooling operator with size `2`.\n",
        "avg_pooling = torch.nn.AvgPool2d(kernel_size=(2, 2))\n",
        "if torch.cuda.is_available():\n",
        "    avg_pooling = avg_pooling.cuda()\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = avg_pooling(im)\n",
        "# print the results\n",
        "print(output_feature)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = torch.nn.functional.avg_pool2d(\n",
        "    input=im, kernel_size=(2, 2))\n",
        "# print the results\n",
        "print(output_feature_F)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1076214-00f1-411b-a4e5-6741b0b092cf",
      "metadata": {
        "id": "c1076214-00f1-411b-a4e5-6741b0b092cf"
      },
      "source": [
        "### Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf439cc3-d0cc-44be-8c7a-11a98dc33694",
      "metadata": {
        "id": "bf439cc3-d0cc-44be-8c7a-11a98dc33694"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=0)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        # Instantiate the ReLU nonlinearity\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        # Instantiate two convolutional layers\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=5,\n",
        "            kernel_size=(3, 3), padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=5, out_channels=10,\n",
        "            kernel_size=(3, 3), padding=1)\n",
        "        # Instantiate a max pooling layer\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        # Instantiate a fully connected layer\n",
        "        self.fc = torch.nn.Linear(in_features=7*7*10,\n",
        "            out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply conv followd by relu, then in next line pool\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        # Apply conv followd by relu, then in next line pool\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        # Prepare the image for the fully connected layer\n",
        "        x = x.view(-1, 7 * 7 * 10)\n",
        "        # Apply the fully connected layer and return the result\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "060790ea-5f0a-4ffe-b910-226ca8b23c3f",
      "metadata": {
        "id": "060790ea-5f0a-4ffe-b910-226ca8b23c3f"
      },
      "source": [
        "### Training Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29258db-4217-487f-8f9a-69558caf83cf",
      "metadata": {
        "id": "f29258db-4217-487f-8f9a-69558caf83cf",
        "outputId": "fb62806e-5ba2-4bd3-d306-7287bf371856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Finished training\n",
            "The testing set accuracy of the network is: 70%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=0)\n",
        "import torchvision\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
        "    train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(dataset=trainset,\n",
        "    batch_size=128, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data',\n",
        "    train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(dataset=testset,\n",
        "    batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=32,\n",
        "            kernel_size=(3, 3), padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64,\n",
        "            kernel_size=(3, 3), padding=1)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=64, out_channels=128,\n",
        "            kernel_size=(3, 3), padding=1)\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        self.fc = torch.nn.Linear(in_features=128*4*4,\n",
        "            out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.nn.functional.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128*4*4)\n",
        "        return self.fc(x)\n",
        "\n",
        "net = Net()\n",
        "if torch.cuda.is_available():\n",
        "    net = net.cuda()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=net.parameters(), lr=3e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for data in trainloader:\n",
        "        # Get the inputs\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Compute the forward pass\n",
        "        outputs = net(inputs)\n",
        "        # Compute the loss function\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Compute the gradients\n",
        "        loss.backward()\n",
        "        # Update the weights\n",
        "        optimizer.step()\n",
        "print(\"Finished training\")\n",
        "\n",
        "correct, total = 0, 0\n",
        "net.eval()\n",
        "# Iterate over the data in the test_loader\n",
        "for data in testloader:\n",
        "    # Get the image and label from data\n",
        "    inputs, labels = data\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "    # Make a forward pass in the net with inputs\n",
        "    outputs = net(inputs)\n",
        "    # Argmax the results of the net\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "print(\"The testing set accuracy of the network is: %d%%\"\n",
        "    %(100*correct/total))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c6e45d1-e2fb-4cdb-ab00-c3044ce4e487",
      "metadata": {
        "id": "3c6e45d1-e2fb-4cdb-ab00-c3044ce4e487"
      },
      "source": [
        "## Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad46b460-d18d-4af7-a368-5a8f07251281",
      "metadata": {
        "id": "ad46b460-d18d-4af7-a368-5a8f07251281"
      },
      "source": [
        "### Sequential module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3b1f0a-6569-4e5e-a671-f33e334364c0",
      "metadata": {
        "id": "fe3b1f0a-6569-4e5e-a671-f33e334364c0",
        "outputId": "80d5c68e-c0e9-41f8-abdd-ce5b73988276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The test set accuracy of the network is: 99 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=0)\n",
        "import torchvision\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=0.1307, std=0.3081)\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data',\n",
        "    train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(dataset=trainset,\n",
        "    batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data',\n",
        "    train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(dataset=testset,\n",
        "    batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Declare all the layers for feature extraction\n",
        "        self.features = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=1, out_channels=5,\n",
        "                kernel_size=(3, 3), padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=5, out_channels=10,\n",
        "                kernel_size=(3, 3), padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=10, out_channels=20,\n",
        "                kernel_size=(3, 3), padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=20, out_channels=40,\n",
        "                kernel_size=(3, 3), padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # Declare all the layers for classification\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=7*7*40, out_features=1024),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(in_features=1024, out_features=2048),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(in_features=2048, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply the feature extractor in the input\n",
        "        x = self.features(x)\n",
        "        # Squeeze the three spatial dimensions in one\n",
        "        x = x.view(-1, 7*7*40)\n",
        "        # Classify the images\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    for data in trainloader:\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "for data in testloader:\n",
        "    inputs, labels = data\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "    outputs = model(inputs)\n",
        "    _, predicts = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicts==labels).sum().item()\n",
        "\n",
        "print(\"The test set accuracy of the network is: %d %%\"\n",
        "    %(100*correct/total))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b19b843-3c30-4157-9512-742e78cd967d",
      "metadata": {
        "id": "8b19b843-3c30-4157-9512-742e78cd967d"
      },
      "source": [
        "### Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aecf6c2-0253-4d56-b387-368c5aace1ca",
      "metadata": {
        "id": "1aecf6c2-0253-4d56-b387-368c5aace1ca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(seed=0)\n",
        "import torch\n",
        "torch.manual_seed(seed=0)\n",
        "import torchvision\n",
        "\n",
        "# Shuffle the indices\n",
        "indices = np.arange(60000)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=0.1307, std=0.3081)\n",
        "])\n",
        "trainset = torchvision.datasets.MNIST(root='./data',\n",
        "    train=True, download=True, transform=transform)\n",
        "\n",
        "# Build the train loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
        "    batch_size=64, shuffle=False, num_workers=4,\n",
        "    sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n",
        "\n",
        "# Build the validation loader\n",
        "val_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
        "    batch_size=64, shuffle=False, num_workers=4,\n",
        "    sampler=torch.utils.data.SubsetRandomSampler(indices[55000:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b776082f-40fb-4dfe-8d44-b4bf51fd5999",
      "metadata": {
        "id": "b776082f-40fb-4dfe-8d44-b4bf51fd5999"
      },
      "source": [
        "### Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2308784e-6388-4c8a-bef7-f39cbb4d5d11",
      "metadata": {
        "id": "2308784e-6388-4c8a-bef7-f39cbb4d5d11",
        "outputId": "a066b575-2c3a-48f5-ef25-9f35ba819d5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The validation accuracy: 98%\n",
            "The validation accuracy: 98%\n",
            "The validation accuracy: 98%\n",
            "The validation accuracy: 98%\n",
            "The validation accuracy: 98%\n",
            "The validation accuracy: 99%\n",
            "The validation accuracy: 98%\n",
            "The validation accuracy: 98%\n",
            "The validation accuracy: 98%\n",
            "The validation accuracy: 99%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=0)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Implement the sequential module for feature extraction\n",
        "        self.features = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=1, out_channels=10,\n",
        "                kernel_size=(3, 3), stride=1, padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.BatchNorm2d(num_features=10),\n",
        "            torch.nn.Conv2d(in_channels=10, out_channels=20,\n",
        "                kernel_size=(3, 3), stride=1, padding=1),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.BatchNorm2d(num_features=20)\n",
        "        )\n",
        "\n",
        "        # Implement the fully connected layer for classification\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=7*7*20, out_features=200),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Dropout(p=0.5),\n",
        "            torch.nn.Linear(in_features=200, out_features=500),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(in_features=500, out_features=num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "    \t# Do the forward pass\n",
        "        x = self.features(x)\n",
        "        x = x.view(-1, 7*7*20)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Instantiate the network\n",
        "model = Net(num_classes=10)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Instantiate the cross-entropy loss\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# Instantiate the Adam optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),\n",
        "    lr=3e-4, weight_decay=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for data in train_loader:\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Set the net in evaluation mode\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for data in val_loader:\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        outputs = model(inputs)\n",
        "        _, predicts = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicts==labels).sum().item()\n",
        "    print(\"The validation accuracy: %d%%\" %(100*correct/total))\n",
        "    # Set the net in train mode\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c8bf801-fe86-46a8-8cd8-eade666bf44e",
      "metadata": {
        "id": "7c8bf801-fe86-46a8-8cd8-eade666bf44e"
      },
      "source": [
        "### Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60bb8572-9ca6-4cc9-8bd0-d90156588676",
      "metadata": {
        "id": "60bb8572-9ca6-4cc9-8bd0-d90156588676"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(seed=0)\n",
        "\n",
        "# Instantiate the model\n",
        "model = Net()\n",
        "# Load the parameters from the old model\n",
        "model.load_state_dict(torch.load('my_net.pth'))\n",
        "# Freeze all the layers except the final one\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# Change the number of out channels\n",
        "model.fc = torch.nn.Linear(in_features=7*7*512, out_features=26)\n",
        "# Train and evaluate the model\n",
        "model.train()\n",
        "train_net(model, optimizer, criterion)\n",
        "print(\"Accuracy of the net is:\", str(model.eval()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "253eb589-7b74-4b2e-9fa3-f57b6f6cfa64",
      "metadata": {
        "id": "253eb589-7b74-4b2e-9fa3-f57b6f6cfa64"
      },
      "outputs": [],
      "source": [
        "# Import the module\n",
        "import torch\n",
        "torch.manual_seed(seed=0)\n",
        "import torchvision\n",
        "\n",
        "# Download resnet18\n",
        "model = torchvision.models.resnet18(weights=\"DEFAULT\")\n",
        "# Freeze all the layers bar the last one\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Change the number of output units\n",
        "model.fc = torch.nn.Linear(in_features=512, out_features=7)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}