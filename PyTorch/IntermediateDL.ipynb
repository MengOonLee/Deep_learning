{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163d916-33b5-4da2-b3c9-82296384fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        super().__init__()\n",
    "        # Load data to pandas DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Convert data to a NumPy array and assign to self.data\n",
    "        self.data = df.to_numpy()\n",
    "        \n",
    "    # Implement __len__ to return the number of data samples\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.data[idx, :-1]\n",
    "        # Assign last data column to label\n",
    "        label = self.data[idx, -1]\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692717cf-1cf6-49a4-9631-56db7dc2e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the WaterDataset\n",
    "dataset_train = WaterDataset(\"water_train.csv\")\n",
    "\n",
    "# Create a DataLoader based on dataset_train\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Get a batch of features and labels\n",
    "features, labels = next(iter(dataloader_train))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a207b8-e591-4c3c-a966-616c7574e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Define the three linear layers\n",
    "        self.fc1 = nn.Linear(9, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass x through linear layers adding activations\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a946d61-6a4f-4f01-8554-a0b0093bddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Define the SGD optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "train_model(\n",
    "    optimizer=optimizer,\n",
    "    net=net,\n",
    "    num_epochs=10,\n",
    ")\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Define the RMSprop optimizer\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.001)\n",
    "\n",
    "train_model(\n",
    "    optimizer=optimizer,\n",
    "    net=net,\n",
    "    num_epochs=10,\n",
    ")\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Define the Adam optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_model(\n",
    "    optimizer=optimizer,\n",
    "    net=net,\n",
    "    num_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940028c-07c7-4cbc-b17b-26b2b106b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Set up binary accuracy metric\n",
    "acc = Accuracy(task=\"binary\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for features, labels in dataloader_test:\n",
    "        # Get predicted probabilities for test data batch\n",
    "        outputs = net(features)\n",
    "        preds = (outputs >= 0.5).float()\n",
    "        acc(preds, labels.view(-1, 1))\n",
    "\n",
    "# Compute total test accuracy\n",
    "test_accuracy = acc.compute()\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32307b4f-9627-401b-8dc4-888a5ab2b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        \n",
    "        # Apply He initialization\n",
    "        init.kaiming_uniform_(self.fc1.weight)\n",
    "        init.kaiming_uniform_(self.fc2.weight)\n",
    "        init.kaiming_uniform_(self.fc3.weight, nonlinearity=\"sigmoid\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Update ReLU activation to ELU\n",
    "        x = nn.functional.elu(self.fc1(x))\n",
    "        x = nn.functional.elu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e22409-dc5f-429f-95c3-104aa7391e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        # Add two batch normalization layers\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(8)\n",
    "        \n",
    "        init.kaiming_uniform_(self.fc1.weight)\n",
    "        init.kaiming_uniform_(self.fc2.weight)\n",
    "        init.kaiming_uniform_(self.fc3.weight, nonlinearity=\"sigmoid\") \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.functional.elu(x)\n",
    "\n",
    "        # Pass x through the second set of layers\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = nn.functional.elu(x)\n",
    "\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0caa772-73aa-4d19-bb4a-d2584410ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "# Create Dataset using ImageFolder\n",
    "dataset_train = ImageFolder(\n",
    "    \"clouds_train\",\n",
    "    transform=train_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812cb29-264a-40b3-9432-1087ace16846",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    # Add horizontal flip and rotation\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "  \"clouds_train\",\n",
    "  transform=train_transforms,\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "  dataset_train, shuffle=True, batch_size=1\n",
    ")\n",
    "\n",
    "image, label = next(iter(dataloader_train))\n",
    "# Reshape the image tensor\n",
    "image = image.squeeze().permute(1, 2, 0)\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eed006-e9b5-4842-9571-d140e1facc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Define feature extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        # Define classifier\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        # Pass input through feature extractor and classifier\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3323e38-7504-4ea8-896c-3e573630c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64, 64)),\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "  \"clouds_train\",\n",
    "  transform=train_transforms,\n",
    ")\n",
    "dataloader_train = DataLoader(\n",
    "  dataset_train, shuffle=True, batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c674aa7-0543-466e-8f92-d2e73b563045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "net = Net(num_classes=7)\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    # Iterate over training batches\n",
    "    for images, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader_train)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfb3c3-055b-46ac-bbb6-ac755685a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d254a-bf6c-4d82-8be4-a9572a997951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=None)\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=None)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute().mean()\n",
    "recall = metric_recall.compute().mean()\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6566f0-fae3-4a00-b1e5-e25761eb6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define precision metric\n",
    "metric_precision = Precision(\n",
    "    task=\"multiclass\", num_classes=7, average=None\n",
    ")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "precision = metric_precision.compute()\n",
    "\n",
    "# Get precision per class\n",
    "precision_per_class = {\n",
    "    k: precision[v].item()\n",
    "    for k, v \n",
    "    in dataset_test.class_to_idx.items()\n",
    "}\n",
    "print(precision_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82550c0d-600f-4ba3-ac7e-f7c38dcb3e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(df, seq_length):\n",
    "    xs, ys = [], []\n",
    "    # Iterate over data indices\n",
    "    for i in range(len(df) - seq_length):\n",
    "      \t# Define inputs\n",
    "        x = df.iloc[i:(i+seq_length), 1]\n",
    "        # Define target\n",
    "        y = df.iloc[i+seq_length, 1]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f3310-851a-438f-98da-c5cb7b1d6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Use create_sequences to create inputs and targets\n",
    "X_train, y_train = create_sequences(train_data, 24*4)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Create TensorDataset\n",
    "dataset_train = TensorDataset(\n",
    "    torch.from_numpy(X_train).float(),\n",
    "    torch.from_numpy(y_train).float(),\n",
    ")\n",
    "print(len(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf2314-abef-4c41-89ed-bd14d1ea56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define RNN layer\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize first hidden state with zeros\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        # Pass x and h0 through recurrent layer\n",
    "        out, _ = self.rnn(x, h0)  \n",
    "        # Pass recurrent layer's last output through linear layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde0014-e4dc-49a6-aa28-98193da50d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        # Define lstm layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        # Initialize long-term memory\n",
    "        c0 = torch.zeros(2, x.size(0), 32)\n",
    "        # Pass all inputs to lstm layer\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46face0f-c2f4-4f2f-ac0e-b360e5586034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define RNN layer\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        out, _ = self.gru(x, h0)  \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8473e8c-e3d7-4a20-b605-f34b9525b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "# Set up MSE loss\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "  net.parameters(), lr=0.0001\n",
    ")\n",
    "\n",
    "for epoch in range(3):\n",
    "    for seqs, labels in dataloader_train:\n",
    "        # Reshape model inputs\n",
    "        seqs = seqs.view(16, 96, 1)\n",
    "        # Get model outputs\n",
    "        outputs = net(seqs)\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede6f8fc-fe95-4f65-acdc-a9676ab69c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MSE metric\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for seqs, labels in dataloader_test:\n",
    "        seqs = seqs.view(32, 96, 1)\n",
    "        # Pass seqs to net and squeeze the result\n",
    "        outputs = net(seqs).squeeze()\n",
    "        mse(outputs, labels)\n",
    "\n",
    "# Compute final metric value\n",
    "test_mse = mse.compute()\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb0268-e908-4b73-ae11-b35ae016a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotDataset(Dataset):\n",
    "    def __init__(self, transform, samples):\n",
    "\t\t# Assign transform and samples to class attributes\n",
    "        self.transform = transform\n",
    "        self.samples = samples\n",
    "                    \n",
    "    def __len__(self):\n",
    "\t\t# Return number of samples\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      \t# Unpack the sample at index idx\n",
    "        img_path, alphabet, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        # Transform the image \n",
    "        img_transformed = self.transform(img)\n",
    "        return img_transformed, alphabet, label\n",
    "\n",
    "dataset_train = OmniglotDataset(\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((64, 64)),\n",
    "    ]),\n",
    "    samples=samples,\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, shuffle=True, batch_size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f9b48-c6ed-4be2-9099-72e79efbc370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Define sub-networks as sequential models\n",
    "        self.image_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*32*32, 128)\n",
    "        )\n",
    "        self.alphabet_layer = nn.Sequential(\n",
    "            nn.Linear(30, 8),\n",
    "            nn.ELU(), \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 8, 964), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x_image, x_alphabet):\n",
    "\t\t# Pass the x_image and x_alphabet through appropriate layers\n",
    "        x_image = self.image_layer(x_image)\n",
    "        x_alphabet = self.alphabet_layer(x_alphabet)\n",
    "        # Concatenate x_image and x_alphabet\n",
    "        x = torch.cat((x_image, x_alphabet), dim=1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73126aeb-960e-45fa-8eaa-0642a0b03c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sample at index 100\n",
    "print(samples[100])\n",
    "\n",
    "# Create dataset_train\n",
    "dataset_train = OmniglotDataset(\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "      \ttransforms.Resize((64, 64)),\n",
    "    ]),\n",
    "    samples=samples,\n",
    ")\n",
    "\n",
    "# Create dataloader_train\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, shuffle=True, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1e2fa-6286-4b71-a1f9-04f7cd4e2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.image_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*32*32, 128)\n",
    "        )\n",
    "        # Define the two classifier layers\n",
    "        self.classifier_alpha = nn.Linear(128, 30)\n",
    "        self.classifier_char = nn.Linear(128, 964)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3369f-67f8-4040-80fc-a520acd8c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for images, labels_alpha, labels_char in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs_alpha, outputs_char = net(images)\n",
    "        # Compute alphabet classification loss\n",
    "        loss_alpha = criterion(outputs_alpha, labels_alpha)\n",
    "        # Compute character classification loss\n",
    "        loss_char = criterion(outputs_char, labels_char)\n",
    "        # Compute total loss\n",
    "        loss = loss_alpha + loss_char\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf627e-7b79-4bfa-9a5b-553520c6a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    # Define accuracy metrics\n",
    "    acc_alpha = Accuracy(task=\"multiclass\", num_classes=30)\n",
    "    acc_char = Accuracy(task=\"multiclass\", num_classes=964)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels_alpha, labels_char in dataloader_test:\n",
    "            # Obtain model outputs\n",
    "            outputs_alpha, outputs_char = model(images)\n",
    "            _, pred_alpha = torch.max(outputs_alpha, 1)\n",
    "            _, pred_char = torch.max(outputs_char, 1)\n",
    "\t\t\t# Update both accuracy metrics\n",
    "            acc_alpha(pred_alpha, labels_alpha)\n",
    "            acc_char(pred_char, labels_char)\n",
    "    \n",
    "    print(f\"Alphabet: {acc_alpha.compute()}\")\n",
    "    print(f\"Character: {acc_char.compute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
