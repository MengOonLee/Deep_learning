{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Sampling.ipynb",
      "authorship_tag": "ABX9TyPxuZ8E8UAAowaU8EQ7TOlK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MengOonLee/Deep_learning/blob/master/Diffusion/Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 1, Sampling"
      ],
      "metadata": {
        "id": "MSwZH6BX53Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile diffusion_utilities.py\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class ResidualConvBlock(torch.nn.Module):\n"
      ],
      "metadata": {
        "id": "T9JKdwZw6gpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Things Up"
      ],
      "metadata": {
        "id": "9VcZYaOO7HeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "import torch\n",
        "\n",
        "# diffusion hyperparameters\n",
        "timesteps = 500\n",
        "beta1 = 1e-4\n",
        "beta2 = 0.02\n",
        "\n",
        "# network hyperparameters\n",
        "device = torch.device(device=\"cuda:0\" if torch.cuda.is_available()\n",
        "    else torch.device('cpu'))\n",
        "n_feat = 64 # 64 hidden dimension feature\n",
        "n_cfeat = 5 # context vector is of size 5\n",
        "height = 16 # 16x16 image\n",
        "save_dir= './weights/'"
      ],
      "metadata": {
        "id": "pY5rCIfX6BLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# construct DDPM noise schedule\n",
        "b_t = beta1 + (beta2 - beta1) * torch.linspace(\n",
        "    start=0, end=1, steps=timesteps + 1, device=device)\n",
        "a_t = 1 - b_t\n",
        "ab_t = torch.cumsum(input=a_t.log(), dim=0).exp()\n",
        "ab_t[0] = 1"
      ],
      "metadata": {
        "id": "jil9tMm38KZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct model\n",
        "import torch\n",
        "\n",
        "class ContextUnet(torch.nn.Module):\n",
        "    # cfeat - context features\n",
        "    def __init__(self, in_channels, n_feat=256, n_cfeat=10, height=28):\n",
        "        super(ContextUnet, self).__init__()\n",
        "\n",
        "        # number of input channels, number of intermediate feature maps\n",
        "        # and number of classes\n",
        "        self.in_channels = in_channels\n",
        "        self.n_feat = n_feat\n",
        "        self.n_cfeat = n_cfeat\n",
        "        # assume h == w. must be devisible by 4, so 28, 24, 20, 16...\n",
        "        self.h = height\n",
        "\n",
        "        # Initialize the initial convolutional layer\n",
        "        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=True)\n",
        "\n",
        "        # Initialize the down-sampling path of the U-Net with two levels\n",
        "        self.down1 = UnetDown(n_feat, n_feat)\n",
        "        self.down2 = UnetDown(n_feat, 2 * n_feat)\n",
        "\n",
        "nn_model = ContextUnet(in_channels=3, n_feat=n_feat, n_cfeat=n_cfeat,\n",
        "    height=height).to(device)"
      ],
      "metadata": {
        "id": "duKvUBifNGfE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}