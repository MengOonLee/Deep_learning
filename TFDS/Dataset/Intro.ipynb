{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB_xWPLAO0sV"
   },
   "source": [
    "# TFDS Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To7phQPNO0sY"
   },
   "source": [
    "In this notebook we will take a look at the simple Hello World scenario of TensorFlow Datasets (TFDS). We'll use TFDS to perform the extract, transform, and load processes for the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xH42FxIbO0sZ"
   },
   "source": [
    "## Setup\n",
    "\n",
    "We'll start by importing TensorFlow, TensorFlow Datasets, and Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qkngr8bGO0sZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No broken requirements found.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install --no-cache-dir -qU pip wheel\n",
    "pip install --no-cache-dir -qU numpy pandas matplotlib seaborn scikit-learn\n",
    "pip install --no-cache-dir -qU tensorflow tensorflow-datasets\n",
    "pip check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TTBSvHcSLBzc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Using TensorFlow Version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font='DejaVu Sans')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Zyae8k2O0sa"
   },
   "source": [
    "## Extract - Transform - Load (ETL)\n",
    "\n",
    "Now we'll run the **ETL** code. First, to perform the **Extract** process we use `tfts.load`. This handles everything from downloading the raw data to parsing and splitting it, giving us a dataset. Next, we perform the **Transform** process. In this simple example, our transform process will just consist of shuffling the dataset. Finally, we **Load** one record by using the `take(1)` method. In this case, each record consists of an image and its corresponding label. After loading the record we proceed to plot the image and print its corresponding label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a tf.data.Dataset by downloading and extracting\n",
    "# Extract\n",
    "dataset = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
    "# Transform\n",
    "dataset = dataset.shuffle(NUM_SAMPLES) # buffer size\n",
    "dataset = dataset.repeat(NUM_EPOCHS)\n",
    "dataset = dataset.map(lambda x: ...)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "# Load\n",
    "iterator = dataset.take(10) # To fetch 10 samples from the dataset\n",
    "for data in iterator:\n",
    "    # Acess data and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract_reasoning', 'accentdb', 'aeslc', 'aflw2k3d', 'ag_news_subset', 'ai2_arc', 'ai2_arc_with_ir', 'amazon_us_reviews', 'anli', 'answer_equivalence']\n"
     ]
    }
   ],
   "source": [
    "print(tfds.list_builders()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "# Construct a tf.data.Dataset from MNIST\n",
    "dataset = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
    "# Inspecting shapes and datatypes\n",
    "print(dataset)\n",
    "# Checking if the dataset is an instance of tf.data.Dataset\n",
    "assert isinstance(dataset, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='/home/meng/tensorflow_datasets/mnist/3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n",
      "Data dir:  /home/meng/tensorflow_datasets/mnist/3.0.1\n",
      "Image features:  Image(shape=(28, 28, 1), dtype=uint8)\n",
      "Label features:  ClassLabel(shape=(), dtype=int64, num_classes=10)\n",
      "Number of training examples  60000\n",
      "Number of test examples  10000\n"
     ]
    }
   ],
   "source": [
    "mnist, info = tfds.load(name=\"mnist\", with_info=True)\n",
    "print(info)\n",
    "print(\"Data dir: \", info.data_dir)\n",
    "print(\"Image features: \", info.features['image'])\n",
    "print(\"Label features: \", info.features['label'])\n",
    "print(\"Number of training examples \", info.splits['train'].num_examples)\n",
    "print(\"Number of test examples \", info.splits['test'].num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1) ()\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load(name=\"mnist\", as_supervised=True)\n",
    "# Inspecting shapes of a batch\n",
    "for image, label in dataset['train'].take(1):\n",
    "    print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bw9EmV8LO0sb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 272,
       "width": 250
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXTRACT\n",
    "dataset = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
    "\n",
    "# TRANSFORM\n",
    "dataset.shuffle(100)\n",
    "\n",
    "# LOAD\n",
    "for data in dataset.take(1):\n",
    "    image = data[\"image\"].numpy().squeeze()\n",
    "    label = data[\"label\"].numpy()\n",
    "    \n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DatasetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick dataset\n",
    "mnist_builder = tfds.builder(name=\"mnist\")\n",
    "# Download\n",
    "mnist_builder.download_and_prepare()\n",
    "# Extract dataset\n",
    "mnist_builder.as_dataset(split=tfds.Split.TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFDS in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    tfds.as_numpy(dataset=tfds.load(name=\"fashion_mnist\",\n",
    "        split=['train', 'test'], batch_size=1, as_supervised=True)\n",
    "    )\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu()),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax())\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_labels, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "C3_W1_Lab_1_tfds_hello_world.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
